{
    "hostname": "pattykube",
    "timestamp": 1772131733686099625,
    "check_metadata": {
        "container": [
            {
                "config.hash": "container",
                "config.provider": "file",
                "config.source": "/etc/datadog-agent/conf.d/container.d/conf.yaml.default[0]",
                "init_config": "",
                "instance_config": "{}"
            }
        ],
        "container_image": [
            {
                "config.hash": "container_image",
                "config.provider": "file",
                "config.source": "/etc/datadog-agent/conf.d/container_image.d/conf.yaml.default[0]",
                "init_config": "",
                "instance_config": "{}"
            }
        ],
        "container_lifecycle": [
            {
                "config.hash": "container_lifecycle",
                "config.provider": "file",
                "config.source": "/etc/datadog-agent/conf.d/container_lifecycle.d/conf.yaml.default[0]",
                "init_config": "",
                "instance_config": "{}"
            }
        ],
        "coredns": [
            {
                "config.hash": "coredns:261a1c6bd37a42d5",
                "config.provider": "file",
                "config.source": "/etc/datadog-agent/conf.d/coredns.d/auto_conf.yaml[0]",
                "init_config": "",
                "instance_config": "prometheus_url: http://10.244.0.27:9153/metrics\ntags:\n  - dns-pod:10.244.0.27\n  - docker_image:registry.k8s.io/coredns/coredns:v1.13.1\n  - image_id:********@sha256:9b9128672209474da07c91439bf15ed704ae05ad918dd6454e5b6ae14e35fee6\n  - image_name:registry.k8s.io/coredns/coredns\n  - image_tag:v1.13.1\n  - kube_container_name:coredns\n  - kube_deployment:coredns\n  - kube_namespace:kube-system\n  - kube_ownerref_kind:replicaset\n  - kube_ownerref_name:coredns-7d764666f9\n  - kube_priority_class:system-cluster-critical\n  - kube_qos:Burstable\n  - kube_replica_set:coredns-7d764666f9\n  - kube_service:kube-dns\n  - pod_name:coredns-7d764666f9-m99c8\n  - pod_phase:running\n  - short_image:coredns"
            }
        ],
        "cpu": [
            {
                "config.hash": "cpu",
                "config.provider": "file",
                "config.source": "/etc/datadog-agent/conf.d/cpu.d/conf.yaml.default[0]",
                "init_config": "",
                "instance_config": "{}"
            }
        ],
        "datadog_cluster_agent": [
            {
                "config.hash": "datadog_cluster_agent:4721a7f1f2b8b38f",
                "config.provider": "file",
                "config.source": "/etc/datadog-agent/conf.d/datadog_cluster_agent.d/auto_conf.yaml[0]",
                "init_config": "",
                "instance_config": "prometheus_url: http://10.244.0.66:5000/metrics\ntags:\n  - docker_image:datadoghq.azurecr.io/cluster-agent:7.75.4\n  - git.commit.sha:\"***********************************75d38\"\n  - git.repository_url:https://github.com/DataDog/datadog-agent\n  - image_id:********@sha256:9407202820adf2adc6b55d9db02b370b3a9311ff1cce178d41e3c39ea609d59e\n  - image_name:gcr.io/datadoghq/cluster-agent\n  - image_tag:7.75.4\n  - kube_app_component:cluster-agent\n  - kube_app_instance:datadog-cluster-agent\n  - kube_app_managed_by:Helm\n  - kube_app_name:datadog\n  - kube_app_part_of:default-datadog\n  - kube_container_name:cluster-agent\n  - kube_deployment:datadog-cluster-agent\n  - kube_namespace:default\n  - kube_ownerref_kind:replicaset\n  - kube_ownerref_name:datadog-cluster-agent-6445697f5b\n  - kube_qos:BestEffort\n  - kube_replica_set:datadog-cluster-agent-6445697f5b\n  - kube_service:datadog-cluster-agent\n  - kube_service:datadog-cluster-agent-admission-controller\n  - pod_name:datadog-cluster-agent-6445697f5b-287lr\n  - pod_phase:running\n  - short_image:cluster-agent"
            }
        ],
        "discovery": [
            {
                "config.hash": "discovery",
                "config.provider": "file",
                "config.source": "/etc/datadog-agent/conf.d/discovery.d/conf.yaml.default[0]",
                "init_config": "",
                "instance_config": "{}"
            }
        ],
        "disk": [
            {
                "config.hash": "disk",
                "config.provider": "file",
                "config.source": "/etc/datadog-agent/conf.d/disk.d/conf.yaml.default[0]",
                "init_config": "",
                "instance_config": "use_mount: false"
            }
        ],
        "docker": [
            {
                "config.hash": "docker",
                "config.provider": "file",
                "config.source": "/etc/datadog-agent/conf.d/docker.d/conf.yaml.default[0]",
                "init_config": "",
                "instance_config": "collected_event_types:\n  - oom\n  - kill"
            }
        ],
        "file_handle": [
            {
                "config.hash": "file_handle",
                "config.provider": "file",
                "config.source": "/etc/datadog-agent/conf.d/file_handle.d/conf.yaml.default[0]",
                "init_config": "",
                "instance_config": "{}"
            }
        ],
        "io": [
            {
                "config.hash": "io",
                "config.provider": "file",
                "config.source": "/etc/datadog-agent/conf.d/io.d/conf.yaml.default[0]",
                "init_config": "",
                "instance_config": "{}"
            }
        ],
        "kube_apiserver_metrics": [
            {
                "config.hash": "kube_apiserver_metrics:11675b2537f1d4d2",
                "config.provider": "file",
                "config.source": "/etc/datadog-agent/conf.d/kube_apiserver_metrics.d/auto_conf.yaml[0]",
                "init_config": "",
                "instance_config": "bearer_token_auth: tls_only\npossible_prometheus_urls:\n  - https://172.17.0.2:6443/metrics\n  - https://172.17.0.2:8443/metrics\ntags:\n  - apiserver:172.17.0.2\n  - docker_image:registry.k8s.io/kube-apiserver:v1.35.0\n  - image_id:********@sha256:32f98b308862e1cf98c900927d84630fb86a836a480f02752a779eb85c1489f3\n  - image_name:registry.k8s.io/kube-apiserver\n  - image_tag:v1.35.0\n  - kube_container_name:kube-apiserver\n  - kube_namespace:kube-system\n  - kube_priority_class:system-node-critical\n  - kube_qos:Burstable\n  - pod_name:kube-apiserver-pattykube\n  - pod_phase:running\n  - short_image:kube-apiserver"
            }
        ],
        "kubelet": [
            {
                "config.hash": "kubelet",
                "config.provider": "file",
                "config.source": "/etc/datadog-agent/conf.d/kubelet.d/conf.yaml.default[0]",
                "init_config": "",
                "instance_config": "min_collection_interval: 20"
            }
        ],
        "load": [
            {
                "config.hash": "load",
                "config.provider": "file",
                "config.source": "/etc/datadog-agent/conf.d/load.d/conf.yaml.default[0]",
                "init_config": "",
                "instance_config": "{}"
            }
        ],
        "memory": [
            {
                "config.hash": "memory",
                "config.provider": "file",
                "config.source": "/etc/datadog-agent/conf.d/memory.d/conf.yaml.default[0]",
                "init_config": "",
                "instance_config": "{}"
            }
        ],
        "network": [
            {
                "config.hash": "network",
                "config.provider": "file",
                "config.source": "/etc/datadog-agent/conf.d/network.d/conf.yaml.default[0]",
                "init_config": "",
                "instance_config": "{}"
            }
        ],
        "ntp": [
            {
                "config.hash": "ntp:3c427a42a70bbf8",
                "config.provider": "file",
                "config.source": "/etc/datadog-agent/conf.d/ntp.d/conf.yaml.default[0]",
                "init_config": "",
                "instance_config": "{}"
            }
        ],
        "orchestrator_kubelet_config": [
            {
                "config.hash": "orchestrator_kubelet_config:45ec97f32309a951",
                "config.provider": "file",
                "config.source": "/etc/datadog-agent/conf.d/orchestrator_kubelet_config.d/conf.yaml.default[0]",
                "init_config": "",
                "instance_config": "{}"
            }
        ],
        "orchestrator_pod": [
            {
                "config.hash": "orchestrator_pod:888ebc42a3817b00",
                "config.provider": "file",
                "config.source": "/etc/datadog-agent/conf.d/orchestrator_pod.d/conf.yaml.default[0]",
                "init_config": "",
                "instance_config": "{}"
            }
        ],
        "redisdb": [
            {
                "config.hash": "redisdb:6549f812315df5f4",
                "config.provider": "file",
                "config.source": "/etc/datadog-agent/conf.d/redisdb.d/auto_conf.yaml[0]",
                "init_config": "",
                "instance_config": "host: 10.244.0.41\nport: 6379\ntags:\n  - docker_image:redis:latest\n  - image_id:********@sha256:5cb00b0f236e286254ce9f3eea989b00bb69d04fb9b6c9a9d0b07e588e49f44e\n  - image_name:redis\n  - image_tag:latest\n  - kube_container_name:redis\n  - kube_deployment:redis-deployment\n  - kube_namespace:default\n  - kube_ownerref_kind:replicaset\n  - kube_ownerref_name:redis-deployment-56479df6fc\n  - kube_qos:Burstable\n  - kube_replica_set:redis-deployment-56479df6fc\n  - pod_name:redis-deployment-56479df6fc-jv4z9\n  - pod_phase:running\n  - short_image:redis",
                "version.major": "8",
                "version.minor": "6",
                "version.patch": "1",
                "version.raw": "8.6.1",
                "version.scheme": "semver"
            }
        ],
        "telemetry": [
            {
                "config.hash": "telemetry",
                "config.provider": "file",
                "config.source": "/etc/datadog-agent/conf.d/telemetry.d/conf.yaml.default[0]",
                "init_config": "",
                "instance_config": "{}"
            }
        ],
        "uptime": [
            {
                "config.hash": "uptime",
                "config.provider": "file",
                "config.source": "/etc/datadog-agent/conf.d/uptime.d/conf.yaml.default[0]",
                "init_config": "",
                "instance_config": "{}"
            }
        ]
    },
    "logs_metadata": {
        "container_collect_all": [
            {
                "config": "{\"type\":\"docker\"}",
                "integration_name": "container_collect_all",
                "integration_source": "container:docker://a5174fe929ef3485b415c04fefdda3b4aa5a83ba03fc780f7bdc87e4ed854a4e",
                "integration_source_index": 0,
                "service": "",
                "source": "",
                "state": {
                    "error": "",
                    "status": "success"
                },
                "tags": []
            },
            {
                "config": "{\"type\":\"docker\"}",
                "integration_name": "container_collect_all",
                "integration_source": "container:docker://76d2e35e241b39b3e519cdf449bfef9c32859e6efbb627ad4425ab1ad89fbf9b",
                "integration_source_index": 0,
                "service": "",
                "source": "",
                "state": {
                    "error": "",
                    "status": "success"
                },
                "tags": []
            },
            {
                "config": "{\"type\":\"docker\"}",
                "integration_name": "container_collect_all",
                "integration_source": "container:docker://e742cbc43cf9a75ada6bf121167886e06c01ac0c8dfa1b654d44cdb5265eca9a",
                "integration_source_index": 0,
                "service": "",
                "source": "",
                "state": {
                    "error": "",
                    "status": "success"
                },
                "tags": []
            },
            {
                "config": "{\"type\":\"docker\"}",
                "integration_name": "container_collect_all",
                "integration_source": "container:docker://167074306ee212e32d29c4f3bbeaa08daeaa05a3c446f0879244ba8a0e4a8412",
                "integration_source_index": 0,
                "service": "",
                "source": "",
                "state": {
                    "error": "",
                    "status": "success"
                },
                "tags": []
            },
            {
                "config": "{\"type\":\"docker\"}",
                "integration_name": "container_collect_all",
                "integration_source": "container:docker://92b3356af012922cb509ef6e397f6ccee6550dea16b3c0867a11ea31316b1530",
                "integration_source_index": 0,
                "service": "",
                "source": "",
                "state": {
                    "error": "",
                    "status": "success"
                },
                "tags": []
            },
            {
                "config": "{\"type\":\"docker\"}",
                "integration_name": "container_collect_all",
                "integration_source": "container:docker://6bd4a07cd10ab204a17f1ba6f804cc152e71be0aaa15c4c95ee1de110f37cf49",
                "integration_source_index": 0,
                "service": "",
                "source": "",
                "state": {
                    "error": "",
                    "status": "success"
                },
                "tags": []
            },
            {
                "config": "{\"type\":\"docker\"}",
                "integration_name": "container_collect_all",
                "integration_source": "container:docker://0be18888ad8e491cd0b2e9ca9aed8c80d39ca82fb115e8b334a95299a037bbd7",
                "integration_source_index": 0,
                "service": "",
                "source": "",
                "state": {
                    "error": "",
                    "status": "success"
                },
                "tags": []
            },
            {
                "config": "{\"type\":\"docker\"}",
                "integration_name": "container_collect_all",
                "integration_source": "container:docker://ce8933cc7cbf0353f4c90881114da5bfed41620dd4f508f10727e6ed24b0088b",
                "integration_source_index": 0,
                "service": "",
                "source": "",
                "state": {
                    "error": "",
                    "status": "success"
                },
                "tags": []
            },
            {
                "config": "{\"type\":\"docker\"}",
                "integration_name": "container_collect_all",
                "integration_source": "container:docker://06bff94baba197cfb5095fdc57882a08921516ea1ff00f83739f30242c5089df",
                "integration_source_index": 0,
                "service": "",
                "source": "",
                "state": {
                    "error": "",
                    "status": "success"
                },
                "tags": []
            },
            {
                "config": "{\"type\":\"docker\"}",
                "integration_name": "container_collect_all",
                "integration_source": "container:docker://cba24559722b7c7c7e19a2eedf3d42984c99964bae5019468a51ac791c873cea",
                "integration_source_index": 0,
                "service": "",
                "source": "",
                "state": {
                    "error": "",
                    "status": "success"
                },
                "tags": []
            },
            {
                "config": "{\"type\":\"docker\"}",
                "integration_name": "container_collect_all",
                "integration_source": "container:docker://bfe490a19a9899c258ead6d159808472b2cd6e31ccfda6171e1f8a0fc61f0be3",
                "integration_source_index": 0,
                "service": "",
                "source": "",
                "state": {
                    "error": "",
                    "status": "success"
                },
                "tags": []
            },
            {
                "config": "{\"type\":\"docker\"}",
                "integration_name": "container_collect_all",
                "integration_source": "container:docker://3ad202e411ec8c9a6bc9719a791f74de8a7ccee4b7a98e0fd4edf277ef8054b2",
                "integration_source_index": 0,
                "service": "",
                "source": "",
                "state": {
                    "error": "",
                    "status": "success"
                },
                "tags": []
            },
            {
                "config": "{\"type\":\"docker\"}",
                "integration_name": "container_collect_all",
                "integration_source": "container:docker://0bd7e1a6afb1f5bd193ee56f9762cc8d237d55a595392f3f439025a673ff237b",
                "integration_source_index": 0,
                "service": "",
                "source": "",
                "state": {
                    "error": "",
                    "status": "success"
                },
                "tags": []
            },
            {
                "config": "{\"type\":\"docker\"}",
                "integration_name": "container_collect_all",
                "integration_source": "container:docker://38c6f8ace85e9f4ac5eb7aeda57a927214daf0032ee005c12f8b7bddca16aaf3",
                "integration_source_index": 0,
                "service": "",
                "source": "",
                "state": {
                    "error": "",
                    "status": "success"
                },
                "tags": []
            },
            {
                "config": "{\"type\":\"docker\"}",
                "integration_name": "container_collect_all",
                "integration_source": "container:docker://8e67107272384206fe3b447b3e87f74136ed39d71c93d7ab6d4afecef0fe6610",
                "integration_source_index": 0,
                "service": "",
                "source": "",
                "state": {
                    "error": "",
                    "status": "success"
                },
                "tags": []
            },
            {
                "config": "{\"type\":\"docker\"}",
                "integration_name": "container_collect_all",
                "integration_source": "container:docker://090527ec762d391fe1fe3c6bfd6cb8063f641ce8abd74a34ad1f12bb6405b49e",
                "integration_source_index": 0,
                "service": "",
                "source": "",
                "state": {
                    "error": "",
                    "status": "success"
                },
                "tags": []
            },
            {
                "config": "{\"type\":\"docker\"}",
                "integration_name": "container_collect_all",
                "integration_source": "container:docker://76d178d18d134e93cc02837fc4dd8bc1c869c8d125f69f588289e863e4b05dac",
                "integration_source_index": 0,
                "service": "",
                "source": "",
                "state": {
                    "error": "",
                    "status": "success"
                },
                "tags": []
            },
            {
                "config": "{\"type\":\"docker\"}",
                "integration_name": "container_collect_all",
                "integration_source": "container:docker://5684eab595ecf8c3e9f1baedbba4b4f17adaf7fff7e5582e1aa44ae413ffc211",
                "integration_source_index": 0,
                "service": "",
                "source": "",
                "state": {
                    "error": "",
                    "status": "success"
                },
                "tags": []
            },
            {
                "config": "{\"type\":\"docker\"}",
                "integration_name": "container_collect_all",
                "integration_source": "container:docker://4840c015c792563e3a0f53ce0f9924ccef5db4ad4b6c4075e9ab2d478113c4a6",
                "integration_source_index": 0,
                "service": "",
                "source": "",
                "state": {
                    "error": "",
                    "status": "pending"
                },
                "tags": []
            }
        ],
        "default/datadog-cluster-agent-6445697f5b-287lr/cluster-agent": [
            {
                "config": "{\"type\":\"file\",\"path\":\"/var/log/pods/default_datadog-cluster-agent-6445697f5b-287lr_ef4cb795-56e7-45c1-a8cd-a98809edd5d9/cluster-agent/*.log\",\"service\":\"cluster-agent\",\"source\":\"cluster-agent\"}",
                "integration_name": "",
                "integration_source": "",
                "integration_source_index": 0,
                "service": "cluster-agent",
                "source": "cluster-agent",
                "state": {
                    "error": "",
                    "status": "success"
                },
                "tags": []
            }
        ],
        "default/datadog-cluster-agent-6445697f5b-287lr/init-volume": [
            {
                "config": "{\"type\":\"file\",\"path\":\"/var/log/pods/default_datadog-cluster-agent-6445697f5b-287lr_ef4cb795-56e7-45c1-a8cd-a98809edd5d9/init-volume/*.log\",\"start_position\":\"beginning\",\"service\":\"cluster-agent\",\"source\":\"cluster-agent\"}",
                "integration_name": "",
                "integration_source": "",
                "integration_source_index": 0,
                "service": "cluster-agent",
                "source": "cluster-agent",
                "state": {
                    "error": "",
                    "status": "success"
                },
                "tags": []
            }
        ],
        "default/datadog-gkwbc/agent": [
            {
                "config": "{\"type\":\"file\",\"path\":\"/var/log/pods/default_datadog-gkwbc_3611c5d8-6624-4102-88df-04a77237846b/agent/*.log\",\"start_position\":\"beginning\",\"service\":\"agent\",\"source\":\"agent\"}",
                "integration_name": "",
                "integration_source": "",
                "integration_source_index": 0,
                "service": "agent",
                "source": "agent",
                "state": {
                    "error": "",
                    "status": "success"
                },
                "tags": []
            }
        ],
        "default/datadog-gkwbc/init-config": [
            {
                "config": "{\"type\":\"file\",\"path\":\"/var/log/pods/default_datadog-gkwbc_3611c5d8-6624-4102-88df-04a77237846b/init-config/*.log\",\"start_position\":\"beginning\",\"service\":\"agent\",\"source\":\"agent\"}",
                "integration_name": "",
                "integration_source": "",
                "integration_source_index": 0,
                "service": "agent",
                "source": "agent",
                "state": {
                    "error": "",
                    "status": "success"
                },
                "tags": []
            }
        ],
        "default/datadog-gkwbc/init-volume": [
            {
                "config": "{\"type\":\"file\",\"path\":\"/var/log/pods/default_datadog-gkwbc_3611c5d8-6624-4102-88df-04a77237846b/init-volume/*.log\",\"start_position\":\"beginning\",\"service\":\"agent\",\"source\":\"agent\"}",
                "integration_name": "",
                "integration_source": "",
                "integration_source_index": 0,
                "service": "agent",
                "source": "agent",
                "state": {
                    "error": "",
                    "status": "success"
                },
                "tags": []
            }
        ],
        "default/datadog-gkwbc/process-agent": [
            {
                "config": "{\"type\":\"file\",\"path\":\"/var/log/pods/default_datadog-gkwbc_3611c5d8-6624-4102-88df-04a77237846b/process-agent/*.log\",\"start_position\":\"beginning\",\"service\":\"agent\",\"source\":\"agent\"}",
                "integration_name": "",
                "integration_source": "",
                "integration_source_index": 0,
                "service": "agent",
                "source": "agent",
                "state": {
                    "error": "",
                    "status": "success"
                },
                "tags": []
            }
        ],
        "default/datadog-gkwbc/seccomp-setup": [
            {
                "config": "{\"type\":\"file\",\"path\":\"/var/log/pods/default_datadog-gkwbc_3611c5d8-6624-4102-88df-04a77237846b/seccomp-setup/*.log\",\"start_position\":\"beginning\",\"service\":\"agent\",\"source\":\"agent\"}",
                "integration_name": "",
                "integration_source": "",
                "integration_source_index": 0,
                "service": "agent",
                "source": "agent",
                "state": {
                    "error": "",
                    "status": "success"
                },
                "tags": []
            }
        ],
        "default/datadog-gkwbc/system-probe": [
            {
                "config": "{\"type\":\"file\",\"path\":\"/var/log/pods/default_datadog-gkwbc_3611c5d8-6624-4102-88df-04a77237846b/system-probe/*.log\",\"start_position\":\"beginning\",\"service\":\"agent\",\"source\":\"agent\"}",
                "integration_name": "",
                "integration_source": "",
                "integration_source_index": 0,
                "service": "agent",
                "source": "agent",
                "state": {
                    "error": "",
                    "status": "success"
                },
                "tags": []
            }
        ],
        "default/datadog-gkwbc/trace-agent": [
            {
                "config": "{\"type\":\"file\",\"path\":\"/var/log/pods/default_datadog-gkwbc_3611c5d8-6624-4102-88df-04a77237846b/trace-agent/*.log\",\"start_position\":\"beginning\",\"service\":\"agent\",\"source\":\"agent\"}",
                "integration_name": "",
                "integration_source": "",
                "integration_source_index": 0,
                "service": "agent",
                "source": "agent",
                "state": {
                    "error": "",
                    "status": "success"
                },
                "tags": []
            }
        ],
        "default/prometheus-567d6b54b4-4tmwm/prometheus": [
            {
                "config": "{\"type\":\"file\",\"path\":\"/var/log/pods/default_prometheus-567d6b54b4-4tmwm_44965510-7773-47df-879e-df5b4cded201/prometheus/*.log\",\"start_position\":\"beginning\",\"service\":\"prometheus\",\"source\":\"prometheus\"}",
                "integration_name": "",
                "integration_source": "",
                "integration_source_index": 0,
                "service": "prometheus",
                "source": "prometheus",
                "state": {
                    "error": "",
                    "status": "success"
                },
                "tags": []
            }
        ],
        "default/redis-deployment-56479df6fc-jv4z9/redis": [
            {
                "config": "{\"type\":\"file\",\"path\":\"/var/log/pods/default_redis-deployment-56479df6fc-jv4z9_2d70b2fb-8270-4751-8176-e3852186231a/redis/*.log\",\"start_position\":\"beginning\",\"service\":\"redis\",\"source\":\"redis\"}",
                "integration_name": "",
                "integration_source": "",
                "integration_source_index": 0,
                "service": "redis",
                "source": "redis",
                "state": {
                    "error": "",
                    "status": "success"
                },
                "tags": []
            }
        ],
        "default/tomcat/tomcat": [
            {
                "config": "{\"type\":\"file\",\"path\":\"/var/log/pods/default_tomcat_eedac68d-ae54-4193-82d3-5845a2f59356/tomcat/*.log\",\"start_position\":\"beginning\",\"service\":\"tomcat\",\"source\":\"tomcat\"}",
                "integration_name": "",
                "integration_source": "",
                "integration_source_index": 0,
                "service": "tomcat",
                "source": "tomcat",
                "state": {
                    "error": "",
                    "status": "success"
                },
                "tags": []
            }
        ],
        "kube-system/coredns-7d764666f9-m99c8/coredns": [
            {
                "config": "{\"type\":\"file\",\"path\":\"/var/log/pods/kube-system_coredns-7d764666f9-m99c8_2595af7c-adbe-4e87-984c-759876340e8a/coredns/*.log\",\"start_position\":\"beginning\",\"service\":\"coredns\",\"source\":\"coredns\"}",
                "integration_name": "",
                "integration_source": "",
                "integration_source_index": 0,
                "service": "coredns",
                "source": "coredns",
                "state": {
                    "error": "",
                    "status": "success"
                },
                "tags": []
            }
        ],
        "kube-system/etcd-pattykube/etcd": [
            {
                "config": "{\"type\":\"file\",\"path\":\"/var/log/pods/kube-system_etcd-pattykube_54027e52158f0d328dd5b7459b430812/etcd/*.log\",\"start_position\":\"beginning\",\"service\":\"etcd\",\"source\":\"etcd\"}",
                "integration_name": "",
                "integration_source": "",
                "integration_source_index": 0,
                "service": "etcd",
                "source": "etcd",
                "state": {
                    "error": "",
                    "status": "success"
                },
                "tags": []
            }
        ],
        "kube-system/kube-apiserver-pattykube/kube-apiserver": [
            {
                "config": "{\"type\":\"file\",\"path\":\"/var/log/pods/kube-system_kube-apiserver-pattykube_7418e5e3a827586a02748ea0e6ae94d9/kube-apiserver/*.log\",\"start_position\":\"beginning\",\"service\":\"kube-apiserver\",\"source\":\"kube-apiserver\"}",
                "integration_name": "",
                "integration_source": "",
                "integration_source_index": 0,
                "service": "kube-apiserver",
                "source": "kube-apiserver",
                "state": {
                    "error": "",
                    "status": "success"
                },
                "tags": []
            }
        ],
        "kube-system/kube-controller-manager-pattykube/kube-controller-manager": [
            {
                "config": "{\"type\":\"file\",\"path\":\"/var/log/pods/kube-system_kube-controller-manager-pattykube_9bd1c70cf7e25111cd9189ce6a29e306/kube-controller-manager/*.log\",\"start_position\":\"beginning\",\"service\":\"kube-controller-manager\",\"source\":\"kube-controller-manager\"}",
                "integration_name": "",
                "integration_source": "",
                "integration_source_index": 0,
                "service": "kube-controller-manager",
                "source": "kube-controller-manager",
                "state": {
                    "error": "",
                    "status": "success"
                },
                "tags": []
            }
        ],
        "kube-system/kube-proxy-r4f7x/kube-proxy": [
            {
                "config": "{\"type\":\"file\",\"path\":\"/var/log/pods/kube-system_kube-proxy-r4f7x_72150617-7154-43b9-b149-1890f64e1f1d/kube-proxy/*.log\",\"start_position\":\"beginning\",\"service\":\"kube-proxy\",\"source\":\"kube-proxy\"}",
                "integration_name": "",
                "integration_source": "",
                "integration_source_index": 0,
                "service": "kube-proxy",
                "source": "kube-proxy",
                "state": {
                    "error": "",
                    "status": "success"
                },
                "tags": []
            }
        ],
        "kube-system/kube-scheduler-pattykube/kube-scheduler": [
            {
                "config": "{\"type\":\"file\",\"path\":\"/var/log/pods/kube-system_kube-scheduler-pattykube_29a4db6f284853a1e9d61c9937943484/kube-scheduler/*.log\",\"start_position\":\"beginning\",\"service\":\"kube-scheduler\",\"source\":\"kube-scheduler\"}",
                "integration_name": "",
                "integration_source": "",
                "integration_source_index": 0,
                "service": "kube-scheduler",
                "source": "kube-scheduler",
                "state": {
                    "error": "",
                    "status": "success"
                },
                "tags": []
            }
        ],
        "kube-system/storage-provisioner/storage-provisioner": [
            {
                "config": "{\"type\":\"file\",\"path\":\"/var/log/pods/kube-system_storage-provisioner_4c1acc23-7cec-4b96-af4f-a8d4056e04b3/storage-provisioner/*.log\",\"start_position\":\"beginning\",\"service\":\"storage-provisioner\",\"source\":\"storage-provisioner\"}",
                "integration_name": "",
                "integration_source": "",
                "integration_source_index": 0,
                "service": "storage-provisioner",
                "source": "storage-provisioner",
                "state": {
                    "error": "",
                    "status": "success"
                },
                "tags": []
            }
        ]
    },
    "files_metadata": {
        "/etc/datadog-agent/conf.d/activemq.d/metrics.yaml": {
            "hash": "15617a78877a30b8a308306c34439d93cc033ad41ee3c866e2fc76c40a562f6b",
            "raw_config": "cel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\njmx_metrics:\n  - include:\n      attribute:\n        AverageEnqueueTime:\n          alias: activemq.queue.avg_enqueue_time\n          metric_type: gauge\n        ConsumerCount:\n          alias: activemq.queue.consumer_count\n          metric_type: gauge\n        DequeueCount:\n          alias: activemq.queue.dequeue_count\n          metric_type: counter\n        DispatchCount:\n          alias: activemq.queue.dispatch_count\n          metric_type: counter\n        EnqueueCount:\n          alias: activemq.queue.enqueue_count\n          metric_type: counter\n        ExpiredCount:\n          alias: activemq.queue.expired_count\n          metric_type: counter\n        InFlightCount:\n          alias: activemq.queue.in_flight_count\n          metric_type: counter\n        MaxEnqueueTime:\n          alias: activemq.queue.max_enqueue_time\n          metric_type: gauge\n        MemoryPercentUsage:\n          alias: activemq.queue.memory_pct\n          metric_type: gauge\n        MinEnqueueTime:\n          alias: activemq.queue.min_enqueue_time\n          metric_type: gauge\n        ProducerCount:\n          alias: activemq.queue.producer_count\n          metric_type: gauge\n        QueueSize:\n          alias: activemq.queue.size\n          metric_type: gauge\n      destinationType: Queue\n      domain: org.apache.activemq\n  - include:\n      attribute:\n        MemoryPercentUsage:\n          alias: activemq.broker.memory_pct\n          metric_type: gauge\n        StorePercentUsage:\n          alias: activemq.broker.store_pct\n          metric_type: gauge\n        TempPercentUsage:\n          alias: activemq.broker.temp_pct\n          metric_type: gauge\n      domain: org.apache.activemq\n      type: Broker\n  - include:\n      attribute:\n        AddressMemoryUsage:\n          alias: activemq.artemis.address_memory_usage\n          metric_type: gauge\n        AddressMemoryUsagePercentage:\n          alias: activemq.artemis.address_memory_usage_pct\n          metric_type: gauge\n        ConnectionCount:\n          alias: activemq.artemis.connection_count\n          metric_type: counter\n        DiskStoreUsage:\n          alias: activemq.artemis.disk_store_usage_pct\n          metric_type: gauge\n        MaxDiskUsage:\n          alias: activemq.artemis.max_disk_usage\n          metric_type: gauge\n        TotalConnectionCount:\n          alias: activemq.artemis.total_connection_count\n          metric_type: monotonic_count\n        TotalConsumerCount:\n          alias: activemq.artemis.total_consumer_count\n          metric_type: monotonic_count\n        TotalMessageCount:\n          alias: activemq.artemis.total_message_count\n          metric_type: monotonic_count\n        TotalMessagesAcknowledged:\n          alias: activemq.artemis.total_messages_acknowledged\n          metric_type: monotonic_count\n        TotalMessagesAdded:\n          alias: activemq.artemis.total_messages_added\n          metric_type: monotonic_count\n      domain: org.apache.activemq.artemis\n  - include:\n      attribute:\n        AddressSize:\n          alias: activemq.artemis.address.size\n          metric_type: gauge\n        NumberOfBytesPerPage:\n          alias: activemq.artemis.address.bytes_per_page\n          metric_type: gauge\n        NumberOfMessages:\n          alias: activemq.artemis.address.number_of_messages\n          metric_type: monotonic_count\n        NumberOfPages:\n          alias: activemq.artemis.address.pages_count\n          metric_type: counter\n        RoutedMessageCount:\n          alias: activemq.artemis.address.routed_messages\n          metric_type: monotonic_count\n        UnRoutedMessageCount:\n          alias: activemq.artemis.address.unrouted_messages\n          metric_type: monotonic_count\n      component: addresses\n      domain: org.apache.activemq.artemis\n  - include:\n      attribute:\n        ConsumerCount:\n          alias: activemq.artemis.queue.consumer_count\n          metric_type: gauge\n        MaxConsumers:\n          alias: activemq.artemis.queue.max_consumers\n          metric_type: gauge\n        MessageCount:\n          alias: activemq.artemis.queue.message_count\n          metric_type: gauge\n        MessagesAcknowledged:\n          alias: activemq.artemis.queue.messages_acknowledged\n          metric_type: monotonic_count\n        MessagesAdded:\n          alias: activemq.artemis.queue.messages_added\n          metric_type: monotonic_count\n        MessagesExpired:\n          alias: activemq.artemis.queue.messages_expired\n          metric_type: monotonic_count\n        MessagesKilled:\n          alias: activemq.artemis.queue.messages_killed\n          metric_type: monotonic_count\n      domain: org.apache.activemq.artemis\n      subcomponent: queues"
        },
        "/etc/datadog-agent/conf.d/apache.d/auto_conf.yaml": {
            "hash": "47410d31cf60257963bea720836ab172d8557a1e31d3c744986d0eff16cb0b03",
            "raw_config": "ad_identifiers:\n  - httpd\ncel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\ninstances:\n  - apache_status_url: http://%%host%%/server-status?auto"
        },
        "/etc/datadog-agent/conf.d/cassandra.d/metrics.yaml": {
            "hash": "13a4c37d1171d7ebbcb530083e3633bb92f83ca3c37a93970b29de77797ba58e",
            "raw_config": "cel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\njmx_metrics:\n  - include:\n      attribute:\n        - 75thPercentile\n        - 95thPercentile\n        - OneMinuteRate\n      domain: org.apache.cassandra.metrics\n      name:\n        - Latency\n      type: ClientRequest\n  - include:\n      attribute:\n        - OneMinuteRate\n      domain: org.apache.cassandra.metrics\n      name:\n        - Dropped\n      type: DroppedMessage\n  - include:\n      domain: org.apache.cassandra.metrics\n      name:\n        - PendingTasks\n        - CurrentlyBlockedTasks\n        - TotalBlockedTasks\n      path:\n        - request\n      scope:\n        - MutationStage\n        - CounterMutationStage\n        - ReadStage\n        - ViewMutationStage\n      type: ThreadPools\n  - include:\n      domain: org.apache.cassandra.metrics\n      name:\n        - PendingTasks\n        - CurrentlyBlockedTasks\n        - TotalBlockedTasks\n      path:\n        - internal\n      scope:\n        - MemtableFlushWriter\n        - HintsDispatcher\n        - MemtablePostFlush\n        - MigrationStage\n        - MiscStage\n        - SecondaryIndexManagement\n      type: ThreadPools\n  - include:\n      domain: org.apache.cassandra.metrics\n      name:\n        - Load\n        - Exceptions\n      type: Storage\n  - exclude:\n      keyspace:\n        - system\n        - system_auth\n        - system_distributed\n        - system_schema\n        - system_traces\n    include:\n      attribute:\n        - 75thPercentile\n        - 95thPercentile\n        - 99thPercentile\n        - OneMinuteRate\n      bean_regex:\n        - .*keyspace=.*\n      domain: org.apache.cassandra.metrics\n      name:\n        - ReadLatency\n        - WriteLatency\n      type: Table\n  - exclude:\n      keyspace:\n        - system\n        - system_auth\n        - system_distributed\n        - system_schema\n        - system_traces\n    include:\n      attribute:\n        - 75thPercentile\n        - 95thPercentile\n        - OneMinuteRate\n      bean_regex:\n        - .*keyspace=.*\n      domain: org.apache.cassandra.metrics\n      name:\n        - RangeLatency\n        - CasPrepareLatency\n        - CasProposeLatency\n        - CasCommitLatency\n        - ViewLockAcquireTime\n        - ViewReadTime\n      type: Table\n  - exclude:\n      keyspace:\n        - system\n        - system_auth\n        - system_distributed\n        - system_schema\n        - system_traces\n    include:\n      attribute:\n        - 75thPercentile\n        - 95thPercentile\n      bean_regex:\n        - .*keyspace=.*\n      domain: org.apache.cassandra.metrics\n      name:\n        - SSTablesPerReadHistogram\n        - TombstoneScannedHistogram\n        - WaitingOnFreeMemtableSpace\n      type: Table\n  - exclude:\n      keyspace:\n        - system\n        - system_auth\n        - system_distributed\n        - system_schema\n        - system_traces\n    include:\n      attribute:\n        - Min\n        - 75thPercentile\n        - 95thPercentile\n      bean_regex:\n        - .*keyspace=.*\n      domain: org.apache.cassandra.metrics\n      name:\n        - ColUpdateTimeDeltaHistogram\n      type: Table\n  - exclude:\n      keyspace:\n        - system\n        - system_auth\n        - system_distributed\n        - system_schema\n        - system_traces\n    include:\n      attribute:\n        - Value\n      bean_regex:\n        - .*keyspace=.*\n      domain: org.apache.cassandra.metrics\n      name:\n        - BloomFilterFalseRatio\n        - CompressionRatio\n        - KeyCacheHitRate\n        - LiveSSTableCount\n        - MaxPartitionSize\n        - MeanPartitionSize\n        - MeanRowSize\n        - MaxRowSize\n        - PendingCompactions\n        - SnapshotsSize\n      type: Table\n  - exclude:\n      keyspace:\n        - system\n        - system_auth\n        - system_distributed\n        - system_schema\n        - system_traces\n    include:\n      attribute:\n        - Count\n      bean_regex:\n        - .*keyspace=.*\n      domain: org.apache.cassandra.metrics\n      name:\n        - CompactionBytesWritten\n        - BytesFlushed\n        - PendingFlushes\n        - LiveDiskSpaceUsed\n        - TotalDiskSpaceUsed\n        - RowCacheHitOutOfRange\n        - RowCacheHit\n        - RowCacheMiss\n      type: Table\n  - include:\n      attribute:\n        - Count\n      domain: org.apache.cassandra.metrics\n      name:\n        - HitRate\n      scope: KeyCache\n      type: Cache\n  - include:\n      attribute:\n        - Value\n      domain: org.apache.cassandra.metrics\n      name:\n        - PendingTasks\n        - TotalCommitLogSize\n      type: CommitLog\n  - include:\n      domain: org.apache.cassandra.metrics\n      name:\n        - ActiveTasks\n      path: request\n      type: ThreadPools\n  - include:\n      attribute:\n        - Count\n        - OneMinuteRate\n      domain: org.apache.cassandra.metrics\n      name:\n        - Timeouts\n      scope:\n        - Read\n        - Write\n      type: ClientRequest\n  - include:\n      attribute:\n        DroppableTombstoneRatio:\n          alias: cassandra.db.droppable_tombstone_ratio\n      domain: org.apache.cassandra.db\n      type: Tables\n  - include:\n      attribute:\n        - DownEndpointCount\n        - UpEndpointCount\n      domain: org.apache.cassandra.net\n      type: FailureDetector\n  - include:\n      attribute:\n        CollectionCount:\n          alias: jmx.gc.minor_collection_count\n          metric_type: counter\n        CollectionTime:\n          alias: jmx.gc.minor_collection_time\n          metric_type: counter\n      domain: java.lang\n      name: Copy\n      type: GarbageCollector\n  - include:\n      attribute:\n        CollectionCount:\n          alias: jmx.gc.minor_collection_count\n          metric_type: counter\n        CollectionTime:\n          alias: jmx.gc.minor_collection_time\n          metric_type: counter\n      domain: java.lang\n      name: PS Scavenge\n      type: GarbageCollector\n  - include:\n      attribute:\n        CollectionCount:\n          alias: jmx.gc.minor_collection_count\n          metric_type: counter\n        CollectionTime:\n          alias: jmx.gc.minor_collection_time\n          metric_type: counter\n      domain: java.lang\n      name: ParNew\n      type: GarbageCollector\n  - include:\n      attribute:\n        CollectionCount:\n          alias: jmx.gc.minor_collection_count\n          metric_type: counter\n        CollectionTime:\n          alias: jmx.gc.minor_collection_time\n          metric_type: counter\n      domain: java.lang\n      name: G1 Young Generation\n      type: GarbageCollector\n  - include:\n      attribute:\n        CollectionCount:\n          alias: jmx.gc.major_collection_count\n          metric_type: counter\n        CollectionTime:\n          alias: jmx.gc.major_collection_time\n          metric_type: counter\n      domain: java.lang\n      name: MarkSweepCompact\n      type: GarbageCollector\n  - include:\n      attribute:\n        CollectionCount:\n          alias: jmx.gc.major_collection_count\n          metric_type: counter\n        CollectionTime:\n          alias: jmx.gc.major_collection_time\n          metric_type: counter\n      domain: java.lang\n      name: PS MarkSweep\n      type: GarbageCollector\n  - include:\n      attribute:\n        CollectionCount:\n          alias: jmx.gc.major_collection_count\n          metric_type: counter\n        CollectionTime:\n          alias: jmx.gc.major_collection_time\n          metric_type: counter\n      domain: java.lang\n      name: ConcurrentMarkSweep\n      type: GarbageCollector\n  - include:\n      attribute:\n        CollectionCount:\n          alias: jmx.gc.major_collection_count\n          metric_type: counter\n        CollectionTime:\n          alias: jmx.gc.major_collection_time\n          metric_type: counter\n      domain: java.lang\n      name: G1 Mixed Generation\n      type: GarbageCollector\n  - exclude:\n      keyspace:\n        - system\n        - system_auth\n        - system_distributed\n        - system_schema\n        - system_traces\n    include:\n      attribute:\n        - 75thPercentile\n        - 95thPercentile\n        - 99thPercentile\n        - OneMinuteRate\n      bean_regex:\n        - .*keyspace=.*\n      domain: org.apache.cassandra.metrics\n      name:\n        - ReadLatency\n        - WriteLatency\n      type: ColumnFamily\n  - exclude:\n      keyspace:\n        - system\n        - system_auth\n        - system_distributed\n        - system_schema\n        - system_traces\n    include:\n      attribute:\n        - 75thPercentile\n        - 95thPercentile\n        - OneMinuteRate\n      bean_regex:\n        - .*keyspace=.*\n      domain: org.apache.cassandra.metrics\n      name:\n        - RangeLatency\n        - CasPrepareLatency\n        - CasProposeLatency\n        - CasCommitLatency\n        - ViewLockAcquireTime\n        - ViewReadTime\n      type: ColumnFamily\n  - exclude:\n      keyspace:\n        - system\n        - system_auth\n        - system_distributed\n        - system_schema\n        - system_traces\n    include:\n      attribute:\n        - 75thPercentile\n        - 95thPercentile\n      bean_regex:\n        - .*keyspace=.*\n      domain: org.apache.cassandra.metrics\n      name:\n        - SSTablesPerReadHistogram\n        - TombstoneScannedHistogram\n        - WaitingOnFreeMemtableSpace\n      type: ColumnFamily\n  - exclude:\n      keyspace:\n        - system\n        - system_auth\n        - system_distributed\n        - system_schema\n        - system_traces\n    include:\n      attribute:\n        - Min\n        - 75thPercentile\n        - 95thPercentile\n      bean_regex:\n        - .*keyspace=.*\n      domain: org.apache.cassandra.metrics\n      name:\n        - ColUpdateTimeDeltaHistogram\n      type: ColumnFamily\n  - exclude:\n      keyspace:\n        - system\n        - system_auth\n        - system_distributed\n        - system_schema\n        - system_traces\n    include:\n      attribute:\n        - Value\n      bean_regex:\n        - .*keyspace=.*\n      domain: org.apache.cassandra.metrics\n      name:\n        - BloomFilterFalseRatio\n        - CompressionRatio\n        - KeyCacheHitRate\n        - LiveSSTableCount\n        - MaxPartitionSize\n        - MeanPartitionSize\n        - MeanRowSize\n        - MaxRowSize\n        - PendingCompactions\n        - SnapshotsSize\n      type: ColumnFamily\n  - exclude:\n      keyspace:\n        - system\n        - system_auth\n        - system_distributed\n        - system_schema\n        - system_traces\n    include:\n      attribute:\n        - Count\n      bean_regex:\n        - .*keyspace=.*\n      domain: org.apache.cassandra.metrics\n      name:\n        - PendingFlushes\n        - LiveDiskSpaceUsed\n        - TotalDiskSpaceUsed\n        - RowCacheHitOutOfRange\n        - RowCacheHit\n        - RowCacheMiss\n      type: ColumnFamily\n  - include:\n      attribute:\n        DroppableTombstoneRatio:\n          alias: cassandra.db.droppable_tombstone_ratio\n      domain: org.apache.cassandra.db\n      type: ColumnFamilies"
        },
        "/etc/datadog-agent/conf.d/cert_manager.d/auto_conf.yaml": {
            "hash": "2b97aa1f906b670e91a87109ea6696fa589e8a903d1b074b0c4e41999d033a88",
            "raw_config": "ad_identifiers:\n  - cert-manager-controller\ncel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\ninstances:\n  - openmetrics_endpoint: http://%%host%%:9402/metrics"
        },
        "/etc/datadog-agent/conf.d/cilium.d/auto_conf.yaml": {
            "hash": "70e5d7baf1aba79e39c0aff4ccd7660908e5c13378f37cc366dbe197fc3df4ac",
            "raw_config": "ad_identifiers:\n  - cilium-agent\n  - cilium\ncel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\ninstances:\n  - agent_endpoint: http://%%host%%:9962/metrics\n    tags:\n      - cilium-pod:%%host%%"
        },
        "/etc/datadog-agent/conf.d/confluent_platform.d/metrics.yaml": {
            "hash": "c55aa25c17e3791e53bca3a8fc6b3de272a833977d3d8f3f65f2c734be227e55",
            "raw_config": "cel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\njmx_metrics:\n  - include:\n      attribute:\n        Value:\n          alias: confluent.$domain.$type.$name\n          metric_type: gauge\n      bean:\n        - kafka.network:type=RequestChannel,name=RequestQueueSize\n        - kafka.network:type=SocketServer,name=NetworkProcessorAvgIdlePercent\n        - kafka.server:type=DelayedOperationPurgatory,name=PurgatorySize,delayedOperation=Fetch\n        - kafka.server:type=DelayedOperationPurgatory,name=PurgatorySize,delayedOperation=Produce\n        - kafka.server:type=ReplicaFetcherManager,name=MaxLag,clientId=Replica\n        - kafka.server:type=ReplicaManager,name=LeaderCount\n        - kafka.server:type=ReplicaManager,name=PartitionCount\n        - kafka.server:type=ReplicaManager,name=UnderMinIsrPartitionCount\n        - kafka.server:type=ReplicaManager,name=UnderReplicatedPartitions\n        - kafka.server:type=Produce,name=DelayQueueSize\n  - include:\n      attribute:\n        Value:\n          alias: confluent.$domain.$name\n          metric_type: gauge\n      bean:\n        - kafka.controller:type=KafkaController,name=OfflinePartitionsCount\n        - kafka.controller:type=KafkaController,name=ActiveControllerCount\n      domain: kafka.controller\n  - include:\n      attribute:\n        Value:\n          alias: confluent.$domain.fetcher_lag.$name\n          metric_type: gauge\n      bean_regex:\n        - kafka\\.server:type=FetcherLagMetrics,name=ConsumerLag,.*\n      domain: kafka.server\n  - include:\n      attribute:\n        MeanRate:\n          alias: confluent.$domain.broker_topic_metrics.$name\n          metric_type: gauge\n      bean_regex:\n        - kafka\\.server:type=BrokerTopicMetrics,name=BytesInPerSec,topic=.*\n        - kafka\\.server:type=BrokerTopicMetrics,name=BytesOutPerSec,topic=.*\n        - kafka\\.server:type=BrokerTopicMetrics,name=MessagesInPerSec,topic=.*\n        - kafka\\.server:type=BrokerTopicMetrics,name=MessagesOutPerSec,topic=.*\n        - kafka\\.server:type=BrokerTopicMetrics,name=ProduceMessageConversionsPerSec,topic=.*\n        - kafka\\.server:type=BrokerTopicMetrics,name=FetchMessageConversionsPerSec,topic=.*\n      domain: kafka.server\n      tags:\n        topic: $0\n  - include:\n      attribute:\n        Value:\n          alias: confluent.$domain.$type.$name\n          metric_type: gauge\n      bean_regex:\n        - kafka\\.cluster:type=Partition,name=UnderMinIsr,.*\n      domain: kafka.cluster\n  - include:\n      attribute:\n        Count:\n          alias: confluent.$domain.topic.$name.rate\n          metric_type: rate\n      bean:\n        - kafka.server:type=BrokerTopicMetrics,name=BytesInPerSec\n        - kafka.server:type=BrokerTopicMetrics,name=BytesOutPerSec\n        - kafka.server:type=BrokerTopicMetrics,name=BytesRejectedPerSec\n        - kafka.server:type=BrokerTopicMetrics,name=FailedFetchRequestsPerSec\n        - kafka.server:type=BrokerTopicMetrics,name=FailedProduceRequestsPerSec\n        - kafka.server:type=BrokerTopicMetrics,name=MessagesInPerSec\n        - kafka.server:type=BrokerTopicMetrics,name=TotalFetchRequestsPerSec\n        - kafka.server:type=BrokerTopicMetrics,name=TotalProduceRequestsPerSec\n      domain: kafka.server\n  - include:\n      attribute:\n        Count:\n          alias: confluent.$domain.$type.$name.rate\n          metric_type: rate\n      bean:\n        - kafka.server:type=ReplicaManager,name=IsrExpandsPerSec\n        - kafka.server:type=ReplicaManager,name=IsrShrinksPerSec\n      domain: kafka.server\n  - include:\n      attribute:\n        Count:\n          alias: confluent.$domain.request_handler_pool.avg_idle_percent.rate\n          metric_type: rate\n        OneMinuteRate:\n          alias: confluent.$domain.request_handler_pool.avg_idle_percent\n          metric_type: gauge\n      bean:\n        - kafka.server:type=KafkaRequestHandlerPool,name=RequestHandlerAvgIdlePercent\n      domain: kafka.server\n  - include:\n      attribute:\n        Count:\n          alias: confluent.$domain.session.$name.rate\n          metric_type: rate\n      bean:\n        - kafka.server:type=SessionExpireListener,name=ZooKeeperDisconnectsPerSec\n        - kafka.server:type=SessionExpireListener,name=ZooKeeperExpiresPerSec\n        - kafka.server:type=SessionExpireListener,name=ZooKeeperSyncConnectsPerSec\n        - kafka.server:type=SessionExpireListener,name=ZooKeeperAuthFailuresPerSec\n        - kafka.server:type=SessionExpireListener,name=ZooKeeperReadOnlyConnectsPerSec\n        - kafka.server:type=SessionExpireListener,name=ZooKeeperSaslAuthenticationsPerSec\n      domain: kafka.server\n  - include:\n      attribute:\n        Count:\n          alias: confluent.$domain.session.$name\n          metric_type: gauge\n      bean:\n        - kafka.server:type=ZooKeeperClientMetrics,name=ZooKeeperRequestLatencyMs\n      domain: kafka.server\n  - include:\n      attribute:\n        Count:\n          alias: confluent.$domain.request.$name.rate\n          metric_type: rate\n      bean_regex:\n        - kafka.network:type=RequestMetrics,name=RequestsPerSec,request=(.*)\n      domain: kafka.network\n      tags:\n        request: $0\n  - include:\n      attribute:\n        Value:\n          alias: confluent.$domain.$name\n          metric_type: gauge\n      bean:\n        - kafka.controller:type=KafkaController,name=PreferredReplicaImbalanceCount\n        - kafka.controller:type=KafkaController,name=GlobalUnderMinIsrPartitionCount\n        - kafka.controller:type=KafkaController,name=GlobalTopicCount\n        - kafka.controller:type=KafkaController,name=GlobalPartitionCount\n      domain: kafka.controller\n  - include:\n      attribute:\n        Count:\n          alias: confluent.$domain.$name.rate\n          metric_type: rate\n        Mean:\n          alias: confluent.$domain.$name.avg\n          metric_type: gauge\n      bean:\n        - kafka.controller:type=ControllerStats,name=UncleanLeaderElectionsPerSec\n        - kafka.controller:type=ControllerStats,name=LeaderElectionRateAndTimeMs\n      domain: kafka.controller\n  - include:\n      attribute:\n        Value:\n          alias: confluent.$domain.size\n          metric_type: gauge\n      bean_regex:\n        - kafka\\.log:type=Log,name=Size(?:,topic=)([-.\\w]+)(?:,partition=)([0-9]+)\n      domain: kafka.log\n      tags:\n        partition: $1\n        topic: $0\n  - include:\n      attribute:\n        Count:\n          alias: confluent.$domain.$name.rate\n          metric_type: rate\n        Mean:\n          alias: confluent.$domain.$name.avg\n          metric_type: gauge\n      bean_regex:\n        - kafka\\.log:type=LogFlushStats,name=LogFlushRateAndTimeMs\n      domain: kafka.log\n  - include:\n      attribute:\n        50thPercentile:\n          alias: confluent.$domain.request.$name.50percentile\n          metric_type: gauge\n        75thPercentile:\n          alias: confluent.$domain.request.$name.75percentile\n          metric_type: gauge\n        95thPercentile:\n          alias: confluent.$domain.request.$name.95percentile\n          metric_type: gauge\n        98thPercentile:\n          alias: confluent.$domain.request.$name.98percentile\n          metric_type: gauge\n        99thPercentile:\n          alias: confluent.$domain.request.$name.99percentile\n          metric_type: gauge\n        999thPercentile:\n          alias: confluent.$domain.request.$name.999percentile\n          metric_type: gauge\n        Count:\n          alias: confluent.$domain.request.$name.rate\n          metric_type: rate\n        Mean:\n          alias: confluent.$domain.request.$name.avg\n          metric_type: gauge\n      bean_regex:\n        - kafka\\.network:type=RequestMetrics,name=TotalTimeMs,request=(Produce|FetchConsumer|FetchFollower).*\n        - kafka\\.network:type=RequestMetrics,name=RequestQueueTimeMs,request=(Produce|FetchConsumer|FetchFollower).*\n        - kafka\\.network:type=RequestMetrics,name=LocalTimeMs,request=(Produce|FetchConsumer|FetchFollower).*\n        - kafka\\.network:type=RequestMetrics,name=RemoteTimeMs,request=(Produce|FetchConsumer|FetchFollower).*\n        - kafka\\.network:type=RequestMetrics,name=ResponseQueueTimeMs,request=(Produce|FetchConsumer|FetchFollower).*\n        - kafka\\.network:type=RequestMetrics,name=ResponseSendTimeMs,request=(Produce|FetchConsumer|FetchFollower).*\n      domain: kafka.network\n  - include:\n      attribute:\n        batch-size-avg:\n          alias: confluent.$domain.$attribute\n          metric_type: gauge\n        batch-size-max:\n          alias: confluent.$domain.$attribute\n          metric_type: gauge\n        bufferpool-wait-time-total:\n          alias: confluent.$domain.$attribute\n          metric_type: gauge\n        connection-close-rate:\n          alias: confluent.$domain.$attribute\n          metric_type: gauge\n        connection-count:\n          alias: confluent.$domain.$attribute\n          metric_type: gauge\n        connection-creation-rate:\n          alias: confluent.$domain.$attribute\n          metric_type: gauge\n        incoming-byte-rate:\n          alias: confluent.$domain.$attribute\n          metric_type: gauge\n        io-ratio:\n          alias: confluent.$domain.$attribute\n          metric_type: gauge\n        io-time-ns-avg:\n          alias: confluent.$domain.$attribute\n          metric_type: gauge\n        io-wait-ratio:\n          alias: confluent.$domain.$attribute\n          metric_type: gauge\n        io-wait-time-ns-avg:\n          alias: confluent.$domain.$attribute\n          metric_type: gauge\n        network-io-rate:\n          alias: confluent.$domain.$attribute\n          metric_type: gauge\n        outgoing-byte-rate:\n          alias: confluent.$domain.$attribute\n          metric_type: gauge\n        produce-throttle-time-avg:\n          alias: confluent.$domain.$attribute\n          metric_type: gauge\n        produce-throttle-time-max:\n          alias: confluent.$domain.$attribute\n          metric_type: gauge\n        record-error-rate:\n          alias: confluent.$domain.$attribute\n          metric_type: gauge\n        record-retry-rate:\n          alias: confluent.$domain.$attribute\n          metric_type: gauge\n        request-latency-avg:\n          alias: confluent.$domain.$attribute\n          metric_type: gauge\n        request-rate:\n          alias: confluent.$domain.$attribute\n          metric_type: gauge\n        response-rate:\n          alias: confluent.$domain.$attribute\n          metric_type: gauge\n        select-rate:\n          alias: confluent.$domain.$attribute\n          metric_type: gauge\n        waiting-threads:\n          alias: confluent.$domain.$attribute\n          metric_type: gauge\n      bean_regex: kafka\\.producer:type=producer-metrics,client-id=.*\n      domain: kafka.producer\n  - include:\n      attribute:\n        incoming-byte-rate:\n          alias: confluent.$domain.node.$attribute\n          metric_type: gauge\n        outgoing-byte-rate:\n          alias: confluent.$domain.node.$attribute\n          metric_type: gauge\n        request-rate:\n          alias: confluent.$domain.node.$attribute\n          metric_type: gauge\n        request-size-avg:\n          alias: confluent.$domain.node.$attribute\n          metric_type: gauge\n        request-size-max:\n          alias: confluent.$domain.node.$attribute\n          metric_type: gauge\n        response-rate:\n          alias: confluent.$domain.node.$attribute\n          metric_type: gauge\n      bean_regex: kafka\\.producer:type=producer-node-metrics,client-id=.*,node-id=.*\n      domain: kafka.producer\n  - include:\n      attribute:\n        byte-rate:\n          alias: confluent.$domain.topic.$attribute\n          metric_type: gauge\n        compression-rate:\n          alias: confluent.$domain.topic.$attribute\n          metric_type: gauge\n        record-error-rate:\n          alias: confluent.$domain.topic.$attribute\n          metric_type: gauge\n        record-retry-rate:\n          alias: confluent.$domain.topic.$attribute\n          metric_type: gauge\n        record-send-rate:\n          alias: confluent.$domain.topic.$attribute\n          metric_type: gauge\n      bean_regex: kafka\\.producer:type=producer-topic-metrics,client-id=.*,topic=.*\n      domain: kafka.producer\n  - include:\n      attribute:\n        bytes-consumed-rate:\n          alias: confluent.$domain.$attribute\n          metric_type: gauge\n        connection-count:\n          alias: confluent.$domain.$attribute\n          metric_type: gauge\n        fetch-rate:\n          alias: confluent.$domain.$attribute\n          metric_type: gauge\n        fetch-size-avg:\n          alias: confluent.$domain.$attribute\n          metric_type: gauge\n        fetch-size-max:\n          alias: confluent.$domain.$attribute\n          metric_type: gauge\n        fetch-throttle-time-avg:\n          alias: confluent.$domain.$attribute\n          metric_type: gauge\n        fetch-throttle-time-max:\n          alias: confluent.$domain.$attribute\n          metric_type: gauge\n        io-ratio:\n          alias: confluent.$domain.$attribute\n          metric_type: gauge\n        io-wait-ratio:\n          alias: confluent.$domain.$attribute\n          metric_type: gauge\n        network-io-rate:\n          alias: confluent.$domain.$attribute\n          metric_type: gauge\n        records-lag-max:\n          alias: confluent.$domain.$attribute\n          metric_type: gauge\n        request-latency-avg:\n          alias: confluent.$domain.$attribute\n          metric_type: gauge\n        request-rate:\n          alias: confluent.$domain.$attribute\n          metric_type: gauge\n        response-rate:\n          alias: confluent.$domain.$attribute\n          metric_type: gauge\n      bean_regex: kafka\\.consumer:type=consumer-metrics,client-id=.*\n      domain: kafka.consumer\n  - include:\n      attribute:\n        bytes-consumed-rate:\n          alias: confluent.$domain.fetch.$attribute\n          metric_type: gauge\n        fetch-latency-avg:\n          alias: confluent.$domain.fetch.$attribute\n          metric_type: gauge\n        fetch-latency-max:\n          alias: confluent.$domain.fetch.$attribute\n          metric_type: gauge\n        fetch-rate:\n          alias: confluent.$domain.fetch.$attribute\n          metric_type: gauge\n        fetch-size-avg:\n          alias: confluent.$domain.fetch.$attribute\n          metric_type: gauge\n        fetch-size-max:\n          alias: confluent.$domain.fetch.$attribute\n          metric_type: gauge\n        fetch-throttle-time-avg:\n          alias: confluent.$domain.fetch.$attribute\n          metric_type: gauge\n        fetch-throttle-time-max:\n          alias: confluent.$domain.fetch.$attribute\n          metric_type: gauge\n        records-consumed-rate:\n          alias: confluent.$domain.fetch.$attribute\n          metric_type: gauge\n        records-lag-max:\n          alias: confluent.$domain.fetch.$attribute\n          metric_type: gauge\n        records-per-request-avg:\n          alias: confluent.$domain.fetch.$attribute\n          metric_type: gauge\n      bean_regex: kafka\\.consumer:type=consumer-fetch-manager-metrics,client-id=([-.\\w]+)$\n      domain: kafka.consumer\n  - include:\n      attribute:\n        bytes-consumed-rate:\n          alias: confluent.$domain.fetch_topic.$attribute\n          metric_type: gauge\n        fetch-size-avg:\n          alias: confluent.$domain.fetch_topic.$attribute\n          metric_type: gauge\n        fetch-size-max:\n          alias: confluent.$domain.fetch_topic.$attribute\n          metric_type: gauge\n        records-consumed-rate:\n          alias: confluent.$domain.fetch_topic.$attribute\n          metric_type: gauge\n        records-per-request-avg:\n          alias: confluent.$domain.fetch_topic.$attribute\n          metric_type: gauge\n      bean_regex: kafka\\.consumer:type=consumer-fetch-manager-metrics,client-id=.*,topic=.*\n      domain: kafka.consumer\n  - include:\n      attribute:\n        assigned-partitions:\n          alias: confluent.$domain.group.$attribute\n          metric_type: gauge\n        commit-latency-avg:\n          alias: confluent.$domain.group.$attribute\n          metric_type: gauge\n        commit-latency-max:\n          alias: confluent.$domain.group.$attribute\n          metric_type: gauge\n        commit-rate:\n          alias: confluent.$domain.group.$attribute\n          metric_type: gauge\n        heartbeat-rate:\n          alias: confluent.$domain.group.$attribute\n          metric_type: gauge\n        heartbeat-response-time-max:\n          alias: confluent.$domain.group.$attribute\n          metric_type: gauge\n        join-rate:\n          alias: confluent.$domain.group.$attribute\n          metric_type: gauge\n        join-time-avg:\n          alias: confluent.$domain.group.$attribute\n          metric_type: gauge\n        join-time-max:\n          alias: confluent.$domain.group.$attribute\n          metric_type: gauge\n        last-heartbeat-seconds-ago:\n          alias: confluent.$domain.group.$attribute\n          metric_type: gauge\n        sync-rate:\n          alias: confluent.$domain.group.$attribute\n          metric_type: gauge\n        sync-time-avg:\n          alias: confluent.$domain.group.$attribute\n          metric_type: gauge\n        sync-time-max:\n          alias: confluent.$domain.group.$attribute\n          metric_type: gauge\n      bean_regex: kafka\\.consumer:type=consumer-coordinator-metrics,client-id=([-.\\w]+)$\n      domain: kafka.consumer\n  - include:\n      attribute:\n        connector-count:\n          alias: confluent.$domain.worker.$attribute\n          metric_type: gauge\n        connector-startup-attempts-total:\n          alias: confluent.$domain.worker.$attribute\n          metric_type: gauge\n        connector-startup-failure-percentage:\n          alias: confluent.$domain.worker.$attribute\n          metric_type: gauge\n        connector-startup-failure-total:\n          alias: confluent.$domain.worker.$attribute\n          metric_type: gauge\n        connector-startup-success-percentage:\n          alias: confluent.$domain.worker.$attribute\n          metric_type: gauge\n        connector-startup-success-total:\n          alias: confluent.$domain.worker.$attribute\n          metric_type: gauge\n        task-count:\n          alias: confluent.$domain.worker.$attribute\n          metric_type: gauge\n        task-startup-attempts-total:\n          alias: confluent.$domain.worker.$attribute\n          metric_type: gauge\n        task-startup-failure-percentage:\n          alias: confluent.$domain.worker.$attribute\n          metric_type: gauge\n        task-startup-failure-total:\n          alias: confluent.$domain.worker.$attribute\n          metric_type: gauge\n        task-startup-success-percentage:\n          alias: confluent.$domain.worker.$attribute\n          metric_type: gauge\n        task-startup-success-total:\n          alias: confluent.$domain.worker.$attribute\n          metric_type: gauge\n      bean: kafka.connect:type=connect-worker-metrics\n      domain: kafka.connect\n  - include:\n      attribute:\n        failed-authentication-rate:\n          alias: confluent.$domain.connect_metrics.failed_authentication_rate\n        failed-authentication-total:\n          alias: confluent.$domain.connect_metrics.failed_authentication_total\n        incoming-byte-rate:\n          alias: confluent.$domain.connect_metrics.incoming_byte_rate\n        outgoing-byte-rate:\n          alias: confluent.$domain.connect_metrics.outgoing_byte_rate\n        successful-authentication-rate:\n          alias: confluent.$domain.connect_metrics.successful_authentication_rate\n        successful-authentication-total:\n          alias: confluent.$domain.connect_metrics.successful_authentication_total\n      bean_regex:\n        - kafka\\.connect:type=connect-metrics,client-id=.*\n      domain: kafka.connect\n  - include:\n      attribute:\n        status:\n          alias: confluent.$domain.connector_metrics.status\n          metric_type: gauge\n          values:\n            destroyed: 4\n            failed: 3\n            paused: 2\n            running: 1\n            unassigned: 0\n      bean_regex:\n        - kafka\\.connect:type=connector-metrics,connector=.*\n      domain: kafka.connect\n      tags:\n        connector: $0\n  - include:\n      attribute:\n        connector-destroyed-task-count:\n          alias: confluent.$domain.worker.$attribute\n          metric_type: gauge\n        connector-failed-task-count:\n          alias: confluent.$domain.worker.$attribute\n          metric_type: gauge\n        connector-paused-task-count:\n          alias: confluent.$domain.worker.$attribute\n          metric_type: gauge\n        connector-running-task-count:\n          alias: confluent.$domain.worker.$attribute\n          metric_type: gauge\n        connector-total-task-count:\n          alias: confluent.$domain.worker.$attribute\n          metric_type: gauge\n        connector-unassigned-task-count:\n          alias: confluent.$domain.worker.$attribute\n          metric_type: gauge\n      bean_regex:\n        - kafka\\.connect:type=connect-worker-metrics,connector=.*\n        - kafka\\.connect:type=connector-metrics,connector=.*\n      domain: kafka.connect\n  - include:\n      attribute:\n        completed-rebalances-total:\n          alias: confluent.$domain.worker_rebalance.$attribute\n          metric_type: gauge\n        epoch:\n          alias: confluent.$domain.worker_rebalance.$attribute\n          metric_type: gauge\n        rebalance-avg-time-ms:\n          alias: confluent.$domain.worker_rebalance.$attribute\n          metric_type: gauge\n        rebalance-max-time-ms:\n          alias: confluent.$domain.worker_rebalance.$attribute\n          metric_type: gauge\n        rebalancing:\n          alias: confluent.$domain.worker_rebalance.$attribute\n          metric_type: gauge\n        time-since-last-rebalance-ms:\n          alias: confluent.$domain.worker_rebalance.$attribute\n          metric_type: gauge\n      bean: kafka.connect:type=connect-worker-rebalance-metrics\n      domain: kafka.connect\n  - include:\n      attribute:\n        batch-size-avg:\n          alias: confluent.$domain.connector_task.$attribute\n          metric_type: gauge\n        batch-size-max:\n          alias: confluent.$domain.connector_task.$attribute\n          metric_type: gauge\n        offset-commit-avg-time-ms:\n          alias: confluent.$domain.connector_task.$attribute\n          metric_type: gauge\n        offset-commit-failure-percentage:\n          alias: confluent.$domain.connector_task.$attribute\n          metric_type: gauge\n        offset-commit-max-time-ms:\n          alias: confluent.$domain.connector_task.$attribute\n          metric_type: gauge\n        offset-commit-success-percentage:\n          alias: confluent.$domain.connector_task.$attribute\n          metric_type: gauge\n        pause-ratio:\n          alias: confluent.$domain.connector_task.$attribute\n          metric_type: gauge\n        running-ratio:\n          alias: confluent.$domain.connector_task.$attribute\n          metric_type: gauge\n      bean_regex: kafka\\.connect:type=connector-task-metrics,connector=.*,task=.*\n      domain: kafka.connect\n  - include:\n      attribute:\n        offset-commit-completion-rate:\n          alias: confluent.$domain.sink_task.$attribute\n          metric_type: gauge\n        offset-commit-completion-total:\n          alias: confluent.$domain.sink_task.$attribute\n          metric_type: gauge\n        offset-commit-seq-no:\n          alias: confluent.$domain.sink_task.$attribute\n          metric_type: gauge\n        offset-commit-skip-rate:\n          alias: confluent.$domain.sink_task.$attribute\n          metric_type: gauge\n        offset-commit-skip-total:\n          alias: confluent.$domain.sink_task.$attribute\n          metric_type: gauge\n        partition-count:\n          alias: confluent.$domain.sink_task.$attribute\n          metric_type: gauge\n        put-batch-avg-time-ms:\n          alias: confluent.$domain.sink_task.$attribute\n          metric_type: gauge\n        put-batch-max-time-ms:\n          alias: confluent.$domain.sink_task.$attribute\n          metric_type: gauge\n        sink-record-active-count:\n          alias: confluent.$domain.sink_task.$attribute\n          metric_type: gauge\n        sink-record-active-count-avg:\n          alias: confluent.$domain.sink_task.$attribute\n          metric_type: gauge\n        sink-record-active-count-max:\n          alias: confluent.$domain.sink_task.$attribute\n          metric_type: gauge\n        sink-record-lag-max:\n          alias: confluent.$domain.sink_task.$attribute\n          metric_type: gauge\n        sink-record-read-rate:\n          alias: confluent.$domain.sink_task.$attribute\n          metric_type: gauge\n        sink-record-read-total:\n          alias: confluent.$domain.sink_task.$attribute\n          metric_type: gauge\n        sink-record-send-rate:\n          alias: confluent.$domain.sink_task.$attribute\n          metric_type: gauge\n        sink-record-send-total:\n          alias: confluent.$domain.sink_task.$attribute\n          metric_type: gauge\n      bean_regex: kafka\\.connect:type=sink-task-metrics,connector=.*,task=.*\n      domain: kafka.connect\n  - include:\n      attribute:\n        poll-batch-avg-time-ms:\n          alias: confluent.$domain.source_task.$attribute\n          metric_type: gauge\n        poll-batch-max-time-ms:\n          alias: confluent.$domain.source_task.$attribute\n          metric_type: gauge\n        source-record-active-count:\n          alias: confluent.$domain.source_task.$attribute\n          metric_type: gauge\n        source-record-active-count-avg:\n          alias: confluent.$domain.source_task.$attribute\n          metric_type: gauge\n        source-record-active-count-max:\n          alias: confluent.$domain.source_task.$attribute\n          metric_type: gauge\n        source-record-poll-rate:\n          alias: confluent.$domain.source_task.$attribute\n          metric_type: gauge\n        source-record-poll-total:\n          alias: confluent.$domain.source_task.$attribute\n          metric_type: gauge\n        source-record-write-rate:\n          alias: confluent.$domain.source_task.$attribute\n          metric_type: gauge\n        source-record-write-total:\n          alias: confluent.$domain.source_task.$attribute\n          metric_type: gauge\n      bean_regex: kafka\\.connect:type=source-task-metrics,connector=.*,task=.*\n      domain: kafka.connect\n  - include:\n      attribute:\n        deadletterqueue-produce-failures:\n          alias: confluent.$domain.task_error.$attribute\n          metric_type: gauge\n        deadletterqueue-produce-requests:\n          alias: confluent.$domain.task_error.$attribute\n          metric_type: gauge\n        last-error-timestamp:\n          alias: confluent.$domain.task_error.$attribute\n          metric_type: gauge\n        total-errors-logged:\n          alias: confluent.$domain.task_error.$attribute\n          metric_type: gauge\n        total-record-errors:\n          alias: confluent.$domain.task_error.$attribute\n          metric_type: gauge\n        total-record-failures:\n          alias: confluent.$domain.task_error.$attribute\n          metric_type: gauge\n        total-records-skipped:\n          alias: confluent.$domain.task_error.$attribute\n          metric_type: gauge\n        total-retries:\n          alias: confluent.$domain.task_error.$attribute\n          metric_type: gauge\n      bean_regex: kafka\\.connect:type=task-error-metrics,connector=.*,task=.*\n      domain: kafka.connect\n  - include:\n      attribute:\n        connections-active:\n          alias: confluent.$domain.jetty.$attribute\n          metric_type: gauge\n        connections-closed-rate:\n          alias: confluent.$domain.jetty.$attribute\n          metric_type: gauge\n        connections-opened-rate:\n          alias: confluent.$domain.jetty.$attribute\n          metric_type: gauge\n      bean:\n        - kafka.rest:type=jetty-metrics\n        - kafka.schema.registry:type=jetty-metrics\n  - include:\n      attribute:\n        avro-schemas-created:\n          alias: confluent.$domain.avro_schemas_created\n          metric_type: gauge\n        avro-schemas-deleted:\n          alias: confluent.$domain.avro_schemas_deleted\n          metric_type: gauge\n        json-schemas-created:\n          alias: confluent.$domain.json_schemas_created\n          metric_type: gauge\n        json-schemas-deleted:\n          alias: confluent.$domain.json_schemas_deleted\n          metric_type: gauge\n        protobuf-schemas-created:\n          alias: confluent.$domain.protobuf_schemas_created\n          metric_type: gauge\n        protobuf-schemas-deleted:\n          alias: confluent.$domain.protobuf_schemas_deleted\n          metric_type: gauge\n        registered-count:\n          alias: confluent.$domain.registered_count\n          metric_type: gauge\n      bean:\n        - kafka.schema.registry:type=avro-schemas-created\n        - kafka.schema.registry:type=json-schemas-created\n        - kafka.schema.registry:type=protobuf-schemas-created\n        - kafka.schema.registry:type=avro-schemas-deleted\n        - kafka.schema.registry:type=json-schemas-deleted\n        - kafka.schema.registry:type=protobuf-schemas-deleted\n        - kafka.schema.registry:type=registered-count\n      domain: kafka.schema.registry\n  - include:\n      attribute:\n        brokers.list.request-error-rate:\n          alias: confluent.$domain.jersey.$attribute\n          metric_type: gauge\n        consumer.assign+v2.request-error-rate:\n          alias: confluent.$domain.jersey.$attribute\n          metric_type: gauge\n        consumer.assignment+v2.request-error-rate:\n          alias: confluent.$domain.jersey.$attribute\n          metric_type: gauge\n        consumer.commit-offsets+v2.request-error-rate:\n          alias: confluent.$domain.jersey.$attribute\n          metric_type: gauge\n        consumer.commit.request-error-rate:\n          alias: confluent.$domain.jersey.$attribute\n          metric_type: gauge\n        consumer.committed-offsets+v2.request-error-rate:\n          alias: confluent.$domain.jersey.$attribute\n          metric_type: gauge\n        consumer.create+v2.request-error-rate:\n          alias: confluent.$domain.jersey.$attribute\n          metric_type: gauge\n        consumer.create.request-error-rate:\n          alias: confluent.$domain.jersey.$attribute\n          metric_type: gauge\n        consumer.delete+v2.request-error-rate:\n          alias: confluent.$domain.jersey.$attribute\n          metric_type: gauge\n        consumer.delete.request-error-rate:\n          alias: confluent.$domain.jersey.$attribute\n          metric_type: gauge\n        consumer.records.read-avro+v2.request-error-rate:\n          alias: confluent.$domain.jersey.$attribute\n          metric_type: gauge\n        consumer.records.read-binary+v2.request-error-rate:\n          alias: confluent.$domain.jersey.$attribute\n          metric_type: gauge\n        consumer.records.read-json+v2.request-error-rate:\n          alias: confluent.$domain.jersey.$attribute\n          metric_type: gauge\n        consumer.records.read-jsonschema+v2.request-error-rate:\n          alias: confluent.$domain.jersey.$attribute\n          metric_type: gauge\n        consumer.records.read-protobuf+v2.request-error-rate:\n          alias: confluent.$domain.jersey.$attribute\n          metric_type: gauge\n        consumer.seek-to-beginning+v2.request-error-rate:\n          alias: confluent.$domain.jersey.$attribute\n          metric_type: gauge\n        consumer.seek-to-end+v2.request-error-rate:\n          alias: confluent.$domain.jersey.$attribute\n          metric_type: gauge\n        consumer.seek-to-offset+v2.request-error-rate:\n          alias: confluent.$domain.jersey.$attribute\n          metric_type: gauge\n        consumer.subscribe+v2.request-error-rate:\n          alias: confluent.$domain.jersey.$attribute\n          metric_type: gauge\n        consumer.subscription+v2.request-error-rate:\n          alias: confluent.$domain.jersey.$attribute\n          metric_type: gauge\n        consumer.topic.read-avro.request-error-rate:\n          alias: confluent.$domain.jersey.$attribute\n          metric_type: gauge\n        consumer.topic.read-binary.request-error-rate:\n          alias: confluent.$domain.jersey.$attribute\n          metric_type: gauge\n        consumer.topic.read-json.request-error-rate:\n          alias: confluent.$domain.jersey.$attribute\n          metric_type: gauge\n        consumer.unsubscribe+v2.request-error-rate:\n          alias: confluent.$domain.jersey.$attribute\n          metric_type: gauge\n        partition.consume-avro.request-error-rate:\n          alias: confluent.$domain.jersey.$attribute\n          metric_type: gauge\n        partition.consume-binary.request-error-rate:\n          alias: confluent.$domain.jersey.$attribute\n          metric_type: gauge\n        partition.consume-json.request-error-rate:\n          alias: confluent.$domain.jersey.$attribute\n          metric_type: gauge\n        partition.get+v2.request-error-rate:\n          alias: confluent.$domain.jersey.$attribute\n          metric_type: gauge\n        partition.get.request-error-rate:\n          alias: confluent.$domain.jersey.$attribute\n          metric_type: gauge\n        partition.produce-avro+v2.request-error-rate:\n          alias: confluent.$domain.jersey.$attribute\n          metric_type: gauge\n        partition.produce-avro.request-error-rate:\n          alias: confluent.$domain.jersey.$attribute\n          metric_type: gauge\n        partition.produce-binary+v2.request-error-rate:\n          alias: confluent.$domain.jersey.$attribute\n          metric_type: gauge\n        partition.produce-binary.request-error-rate:\n          alias: confluent.$domain.jersey.$attribute\n          metric_type: gauge\n        partition.produce-json+v2.request-error-rate:\n          alias: confluent.$domain.jersey.$attribute\n          metric_type: gauge\n        partition.produce-json.request-error-rate:\n          alias: confluent.$domain.jersey.$attribute\n          metric_type: gauge\n        partition.produce-jsonschema+v2.request-error-rate:\n          alias: confluent.$domain.jersey.$attribute\n          metric_type: gauge\n        partition.produce-protobuf+v2.request-error-rate:\n          alias: confluent.$domain.jersey.$attribute\n          metric_type: gauge\n        partitions.list+v2.request-error-rate:\n          alias: confluent.$domain.jersey.$attribute\n          metric_type: gauge\n        partitions.list.request-error-rate:\n          alias: confluent.$domain.jersey.$attribute\n          metric_type: gauge\n        request-error-rate:\n          alias: confluent.$domain.jersey.$attribute\n          metric_type: gauge\n        root.get+v2.request-error-rate:\n          alias: confluent.$domain.jersey.$attribute\n          metric_type: gauge\n        root.get.request-error-rate:\n          alias: confluent.$domain.jersey.$attribute\n          metric_type: gauge\n        root.post+v2.request-error-rate:\n          alias: confluent.$domain.jersey.$attribute\n          metric_type: gauge\n        root.post.request-error-rate:\n          alias: confluent.$domain.jersey.$attribute\n          metric_type: gauge\n        topic.get+v2.request-error-rate:\n          alias: confluent.$domain.jersey.$attribute\n          metric_type: gauge\n        topic.get.request-error-rate:\n          alias: confluent.$domain.jersey.$attribute\n          metric_type: gauge\n        topic.produce-avro.request-error-rate:\n          alias: confluent.$domain.jersey.$attribute\n          metric_type: gauge\n        topic.produce-binary.request-error-rate:\n          alias: confluent.$domain.jersey.$attribute\n          metric_type: gauge\n        topic.produce-json.request-error-rate:\n          alias: confluent.$domain.jersey.$attribute\n          metric_type: gauge\n        topics.list+v2.request-error-rate:\n          alias: confluent.$domain.jersey.$attribute\n          metric_type: gauge\n        topics.list.request-error-rate:\n          alias: confluent.$domain.jersey.$attribute\n          metric_type: gauge\n      bean:\n        - kafka.rest:type=jersey-metrics\n        - kafka.schema.registry:type=jersey-metrics\n  - include:\n      attribute:\n        master-slave-role:\n          alias: confluent.$domain.$type.$attribute\n          metric_type: gauge\n      bean: kafka.schema.registry:type=master-slave-role\n      domain: kafka.schema.registry\n  - include:\n      attribute:\n        confluent-replicator-task-topic-partition-latency:\n          alias: $domain.task.topic_partition_latency\n          metric_type: gauge\n        confluent-replicator-task-topic-partition-message-lag:\n          alias: $domain.task.topic_partition_message_lag\n          metric_type: gauge\n        confluent-replicator-task-topic-partition-throughput:\n          alias: $domain.task.topic_partition_throughput\n          metric_type: gauge\n      bean_regex: confluent\\.replicator:type=confluent-replicator-task-metrics,confluent-replicator-task=(.*),confluent-replicator-task-topic-partition=(.*)\n      domain: confluent.replicator\n      tags:\n        partition: $2\n        task: $1\n  - include:\n      attribute:\n        bytes-consumed-total:\n          alias: confluent.ksql.query_stats.$attribute\n          metric_type: gauge\n        error-rate:\n          alias: confluent.ksql.query_stats.$attribute\n          metric_type: gauge\n        messages-consumed-avg:\n          alias: confluent.ksql.query_stats.$attribute\n          metric_type: gauge\n        messages-consumed-max:\n          alias: confluent.ksql.query_stats.$attribute\n          metric_type: gauge\n        messages-consumed-min:\n          alias: confluent.ksql.query_stats.$attribute\n          metric_type: gauge\n        messages-consumed-per-sec:\n          alias: confluent.ksql.query_stats.$attribute\n          metric_type: gauge\n        messages-consumed-total:\n          alias: confluent.ksql.query_stats.$attribute\n          metric_type: gauge\n        messages-produced-per-sec:\n          alias: confluent.ksql.query_stats.$attribute\n          metric_type: gauge\n        num-active-queries:\n          alias: confluent.ksql.query_stats.$attribute\n          metric_type: gauge\n        num-idle-queries:\n          alias: confluent.ksql.query_stats.$attribute\n          metric_type: gauge\n        num-persistent-queries:\n          alias: confluent.ksql.query_stats.$attribute\n          metric_type: gauge\n      bean: io.confluent.ksql.metrics:type=_confluent-ksql-default_ksql-engine-query-stats\n      domain: io.confluent.ksql.metrics\n  - include:\n      attribute:\n        CREATED-queries:\n          alias: confluent.ksql.query_stats.$attribute\n          metric_type: gauge\n        ERROR-queries:\n          alias: confluent.ksql.query_stats.$attribute\n          metric_type: gauge\n        NOT_RUNNING-queries:\n          alias: confluent.ksql.query_stats.$attribute\n          metric_type: gauge\n        PENDING_SHUTDOWN-queries:\n          alias: confluent.ksql.query_stats.$attribute\n          metric_type: gauge\n        REBALANCING-queries:\n          alias: confluent.ksql.query_stats.$attribute\n          metric_type: gauge\n        RUNNING-queries:\n          alias: confluent.ksql.query_stats.$attribute\n          metric_type: gauge\n        bytes-consumed-total:\n          alias: confluent.ksql.query_stats.$attribute\n          metric_type: gauge\n        error-rate:\n          alias: confluent.ksql.query_stats.$attribute\n          metric_type: gauge\n        messages-consumed-avg:\n          alias: confluent.ksql.query_stats.$attribute\n          metric_type: gauge\n        messages-consumed-max:\n          alias: confluent.ksql.query_stats.$attribute\n          metric_type: gauge\n        messages-consumed-min:\n          alias: confluent.ksql.query_stats.$attribute\n          metric_type: gauge\n        messages-consumed-per-sec:\n          alias: confluent.ksql.query_stats.$attribute\n          metric_type: gauge\n        messages-consumed-total:\n          alias: confluent.ksql.query_stats.$attribute\n          metric_type: gauge\n        messages-produced-per-sec:\n          alias: confluent.ksql.query_stats.$attribute\n          metric_type: gauge\n        num-active-queries:\n          alias: confluent.ksql.query_stats.$attribute\n          metric_type: gauge\n        num-idle-queries:\n          alias: confluent.ksql.query_stats.$attribute\n          metric_type: gauge\n        num-persistent-queries:\n          alias: confluent.ksql.query_stats.$attribute\n          metric_type: gauge\n      bean_regex:\n        - io\\.confluent\\.ksql\\.metrics:type=_confluent-ksql-engine-query-stats,ksql_service_id=(.*)\n      domain: io.confluent.ksql.metrics\n      tags:\n        ksql_service_id: $0\n  - include:\n      attribute:\n        messages-per-sec:\n          alias: confluent.ksql.producer_metrics.$attribute\n          metric_type: gauge\n        total-messages:\n          alias: confluent.ksql.producer_metrics.$attribute\n          metric_type: gauge\n      bean: io.confluent.ksql.metrics:type=producer-metrics\n      domain: io.confluent.ksql.metrics\n  - include:\n      attribute:\n        consumer-messages-per-sec:\n          alias: confluent.ksql.consumer_metrics.$attribute\n          metric_type: gauge\n        consumer-total-bytes:\n          alias: confluent.ksql.consumer_metrics.$attribute\n          metric_type: gauge\n        consumer-total-messages:\n          alias: confluent.ksql.consumer_metrics.$attribute\n          metric_type: gauge\n      bean: io.confluent.ksql.metrics:type=consumer-metrics\n      domain: io.confluent.ksql.metrics\n  - include:\n      attribute:\n        pull-query-requests-error-rate:\n          alias: confluent.ksql.pull_query_metrics.$attribute\n          metric_type: gauge\n        pull-query-requests-error-total:\n          alias: confluent.ksql.pull_query_metrics.$attribute\n          metric_type: gauge\n        pull-query-requests-latency-distribution-50:\n          alias: confluent.ksql.pull_query_metrics.$attribute\n          metric_type: gauge\n        pull-query-requests-latency-distribution-75:\n          alias: confluent.ksql.pull_query_metrics.$attribute\n          metric_type: gauge\n        pull-query-requests-latency-distribution-90:\n          alias: confluent.ksql.pull_query_metrics.$attribute\n          metric_type: gauge\n        pull-query-requests-latency-distribution-99:\n          alias: confluent.ksql.pull_query_metrics.$attribute\n          metric_type: gauge\n        pull-query-requests-latency-latency-avg:\n          alias: confluent.ksql.pull_query_metrics.$attribute\n          metric_type: gauge\n        pull-query-requests-latency-latency-max:\n          alias: confluent.ksql.pull_query_metrics.$attribute\n          metric_type: gauge\n        pull-query-requests-latency-latency-min:\n          alias: confluent.ksql.pull_query_metrics.$attribute\n          metric_type: gauge\n        pull-query-requests-local:\n          alias: confluent.ksql.pull_query_metrics.$attribute\n          metric_type: gauge\n        pull-query-requests-local-rate:\n          alias: confluent.ksql.pull_query_metrics.$attribute\n          metric_type: gauge\n        pull-query-requests-rate:\n          alias: confluent.ksql.pull_query_metrics.$attribute\n          metric_type: gauge\n        pull-query-requests-remote:\n          alias: confluent.ksql.pull_query_metrics.$attribute\n          metric_type: gauge\n        pull-query-requests-remote-rate:\n          alias: confluent.ksql.pull_query_metrics.$attribute\n          metric_type: gauge\n        pull-query-requests-total:\n          alias: confluent.ksql.pull_query_metrics.$attribute\n          metric_type: gauge\n      bean: io.confluent.ksql.metrics:type=_confluent-ksql-pull-query\n      domain: io.confluent.ksql.metrics\n  - include:\n      attribute:\n        block-cache-pinned-usage-max:\n          alias: confluent.ksql.ksql_rocksdb_aggregates.block_cache_pinned_usage_max\n          metric_type: gauge\n        block-cache-pinned-usage-total:\n          alias: confluent.ksql.ksql_rocksdb_aggregates.block_cache_pinned_usage_total\n          metric_type: gauge\n        block-cache-usage-max:\n          alias: confluent.ksql.ksql_rocksdb_aggregates.block_cache_usage_max\n          metric_type: gauge\n        block-cache-usage-total:\n          alias: confluent.ksql.ksql_rocksdb_aggregates.block_cache_usage_total\n          metric_type: gauge\n        compaction-pending-total:\n          alias: confluent.ksql.ksql_rocksdb_aggregates.compaction_pending_total\n          metric_type: gauge\n        cur-size-active-mem-table-total:\n          alias: confluent.ksql.ksql_rocksdb_aggregates.cur_size_active_mem_table_total\n          metric_type: gauge\n        cur-size-all-mem-tables-total:\n          alias: confluent.ksql.ksql_rocksdb_aggregates.cur_size_all_mem_tables_total\n          metric_type: gauge\n        estimate-num-keys-total:\n          alias: confluent.ksql.ksql_rocksdb_aggregates.estimate_num_keys_total\n          metric_type: gauge\n        estimate-pending-compaction-bytes-total:\n          alias: confluent.ksql.ksql_rocksdb_aggregates.estimate_pending_compaction_bytes_total\n          metric_type: gauge\n        estimate-table-readers-mem-total:\n          alias: confluent.ksql.ksql_rocksdb_aggregates.estimate_table_readers_mem_total\n          metric_type: gauge\n        live-sst-files-size-total:\n          alias: confluent.ksql.ksql_rocksdb_aggregates.live_sst_files_size_total\n          metric_type: gauge\n        mem-table-flush-pending-total:\n          alias: confluent.ksql.ksql_rocksdb_aggregates.mem_table_flush_pending_total\n          metric_type: gauge\n        num-deletes-active-mem-table-total:\n          alias: confluent.ksql.ksql_rocksdb_aggregates.num_deletes_active_mem_table_total\n          metric_type: gauge\n        num-deletes-imm-mem-tables-total:\n          alias: confluent.ksql.ksql_rocksdb_aggregates.num_deletes_imm_mem_tables_total\n          metric_type: gauge\n        num-entries-active-mem-table-total:\n          alias: confluent.ksql.ksql_rocksdb_aggregates.num_entries_active_mem_table_total\n          metric_type: gauge\n        num-entries-imm-mem-tables-total:\n          alias: confluent.ksql.ksql_rocksdb_aggregates.num_entries_imm_mem_tables_total\n          metric_type: gauge\n        num-immutable-mem-table-total:\n          alias: confluent.ksql.ksql_rocksdb_aggregates.num_immutable_mem_table_total\n          metric_type: gauge\n        num-running-compactions-total:\n          alias: confluent.ksql.ksql_rocksdb_aggregates.num_running_compactions_total\n          metric_type: gauge\n        num-running-flushes-total:\n          alias: confluent.ksql.ksql_rocksdb_aggregates.num_running_flushes_total\n          metric_type: gauge\n        size-all-mem-tables-total:\n          alias: confluent.ksql.ksql_rocksdb_aggregates.size_all_mem_tables_total\n          metric_type: gauge\n        total-sst-files-size-total:\n          alias: confluent.ksql.ksql_rocksdb_aggregates.total_sst_files_size_total\n          metric_type: gauge\n      bean: io.confluent.ksql.metrics:type=ksql-rocksdb-aggregates\n      domain: io.confluent.ksql.metrics\n  - include:\n      attribute:\n        blocked-time-ns-total:\n          alias: confluent.$domain.stream.$attribute\n          metric_type: gauge\n        commit-latency-avg:\n          alias: confluent.$domain.stream.$attribute\n          metric_type: gauge\n        commit-latency-max:\n          alias: confluent.$domain.stream.$attribute\n          metric_type: gauge\n        commit-rate:\n          alias: confluent.$domain.stream.$attribute\n          metric_type: gauge\n        commit-total:\n          alias: confluent.$domain.stream.$attribute\n          metric_type: gauge\n        poll-latency-avg:\n          alias: confluent.$domain.stream.$attribute\n          metric_type: gauge\n        poll-latency-max:\n          alias: confluent.$domain.stream.$attribute\n          metric_type: gauge\n        poll-rate:\n          alias: confluent.$domain.stream.$attribute\n          metric_type: gauge\n        poll-total:\n          alias: confluent.$domain.stream.$attribute\n          metric_type: gauge\n        process-latency-avg:\n          alias: confluent.$domain.stream.$attribute\n          metric_type: gauge\n        process-latency-max:\n          alias: confluent.$domain.stream.$attribute\n          metric_type: gauge\n        process-rate:\n          alias: confluent.$domain.stream.$attribute\n          metric_type: gauge\n        process-total:\n          alias: confluent.$domain.stream.$attribute\n          metric_type: gauge\n        punctuate-latency-avg:\n          alias: confluent.$domain.stream.$attribute\n          metric_type: gauge\n        punctuate-latency-max:\n          alias: confluent.$domain.stream.$attribute\n          metric_type: gauge\n        punctuate-rate:\n          alias: confluent.$domain.stream.$attribute\n          metric_type: gauge\n        punctuate-total:\n          alias: confluent.$domain.stream.$attribute\n          metric_type: gauge\n        skipped-records-rate:\n          alias: confluent.$domain.stream.$attribute\n          metric_type: gauge\n        skipped-records-total:\n          alias: confluent.$domain.stream.$attribute\n          metric_type: gauge\n        task-closed-rate:\n          alias: confluent.$domain.stream.$attribute\n          metric_type: gauge\n        task-closed-total:\n          alias: confluent.$domain.stream.$attribute\n          metric_type: gauge\n        task-created-rate:\n          alias: confluent.$domain.stream.$attribute\n          metric_type: gauge\n        task-created-total:\n          alias: confluent.$domain.stream.$attribute\n          metric_type: gauge\n      bean_regex: kafka\\.streams:type=stream-thread-metrics,thread-id=.*\n      domain: kafka.streams\n  - include:\n      attribute:\n        commit-latency-avg:\n          alias: confluent.$domain.stream.$attribute\n          metric_type: gauge\n        commit-latency-max:\n          alias: confluent.$domain.stream.$attribute\n          metric_type: gauge\n        commit-rate:\n          alias: confluent.$domain.stream.$attribute\n          metric_type: gauge\n        commit-total:\n          alias: confluent.$domain.stream.$attribute\n          metric_type: gauge\n        poll-latency-avg:\n          alias: confluent.$domain.stream.$attribute\n          metric_type: gauge\n        poll-latency-max:\n          alias: confluent.$domain.stream.$attribute\n          metric_type: gauge\n        poll-rate:\n          alias: confluent.$domain.stream.$attribute\n          metric_type: gauge\n        poll-total:\n          alias: confluent.$domain.stream.$attribute\n          metric_type: gauge\n        process-latency-avg:\n          alias: confluent.$domain.stream.$attribute\n          metric_type: gauge\n        process-latency-max:\n          alias: confluent.$domain.stream.$attribute\n          metric_type: gauge\n        process-rate:\n          alias: confluent.$domain.stream.$attribute\n          metric_type: gauge\n        process-total:\n          alias: confluent.$domain.stream.$attribute\n          metric_type: gauge\n        punctuate-latency-avg:\n          alias: confluent.$domain.stream.$attribute\n          metric_type: gauge\n        punctuate-latency-max:\n          alias: confluent.$domain.stream.$attribute\n          metric_type: gauge\n        punctuate-rate:\n          alias: confluent.$domain.stream.$attribute\n          metric_type: gauge\n        punctuate-total:\n          alias: confluent.$domain.stream.$attribute\n          metric_type: gauge\n        skipped-records-rate:\n          alias: confluent.$domain.stream.$attribute\n          metric_type: gauge\n        skipped-records-total:\n          alias: confluent.$domain.stream.$attribute\n          metric_type: gauge\n        task-closed-rate:\n          alias: confluent.$domain.stream.$attribute\n          metric_type: gauge\n        task-closed-total:\n          alias: confluent.$domain.stream.$attribute\n          metric_type: gauge\n        task-created-rate:\n          alias: confluent.$domain.stream.$attribute\n          metric_type: gauge\n        task-created-total:\n          alias: confluent.$domain.stream.$attribute\n          metric_type: gauge\n      bean_regex: kafka\\.streams:type=stream-metrics,client-id=.*\n      domain: kafka.streams\n  - include:\n      attribute:\n        commit-latency-avg:\n          alias: confluent.$domain.task.$attribute\n          metric_type: gauge\n        commit-rate:\n          alias: confluent.$domain.task.$attribute\n          metric_type: gauge\n        record-lateness-avg:\n          alias: confluent.$domain.task.$attribute\n          metric_type: gauge\n      bean_regex: kafka\\.streams:type=stream-task-metrics,.*\n      domain: kafka.streams\n  - include:\n      attribute:\n        forward-rate:\n          alias: confluent.$domain.processor_node.$attribute\n          metric_type: gauge\n        forward-total:\n          alias: confluent.$domain.processor_node.$attribute\n          metric_type: gauge\n        process-latency-avg:\n          alias: confluent.$domain.processor_node.$attribute\n          metric_type: gauge\n        process-rate:\n          alias: confluent.$domain.processor_node.$attribute\n          metric_type: gauge\n        process-total:\n          alias: confluent.$domain.processor_node.$attribute\n          metric_type: gauge\n        suppression-emit-rate:\n          alias: confluent.$domain.processor_node.$attribute\n          metric_type: gauge\n        suppression-emit-total:\n          alias: confluent.$domain.processor_node.$attribute\n          metric_type: gauge\n      bean_regex: kafka\\.streams:type=stream-processor-node-metrics,.*\n      domain: kafka.streams"
        },
        "/etc/datadog-agent/conf.d/consul.d/auto_conf.yaml": {
            "hash": "a9ca3584f86a051b93e170a3d23623378d2f7380f7d8c0269826c4f6c75d0834",
            "raw_config": "ad_identifiers:\n  - consul\ncel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\ninstances:\n  - catalog_checks: true\n    new_leader_checks: true\n    url: http://%%host%%:8500"
        },
        "/etc/datadog-agent/conf.d/container.d/conf.yaml.default": {
            "hash": "115386127ad74824e27bcb7b2f4585ad38b72799cad7c47bda6cf2471cceab0d",
            "raw_config": "ad_identifiers:\n  - _container\ncel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\ninstances:\n  - {}"
        },
        "/etc/datadog-agent/conf.d/container_image.d/conf.yaml.default": {
            "hash": "d8c6f390edd894b5b6fe118ba7c17010331d694ab32835bafb2dd2d28549dea5",
            "raw_config": "ad_identifiers:\n  - _container_image\ncel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\ninstances:\n  - {}"
        },
        "/etc/datadog-agent/conf.d/container_lifecycle.d/conf.yaml.default": {
            "hash": "d4869894b46d8b9ef83f7407a74538d12bdba0875b78f3c6c24d55e7b6ae11cc",
            "raw_config": "ad_identifiers:\n  - _container_lifecycle\ncel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\ninstances:\n  - {}"
        },
        "/etc/datadog-agent/conf.d/containerd.d/conf.yaml.default": {
            "hash": "50f11134621c8843e71ef57977d21065516043e1381bf0f7d33dac8831511843",
            "raw_config": "ad_identifiers:\n  - _containerd\ncel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\ninstances:\n  - collect_events: true\n    filters:\n      - topic==\"/containers/create\"\n      - topic==\"/containers/delete\"\n      - topic==\"/containers/update\"\n      - topic==\"/images/update\"\n      - topic==\"/images/create\"\n      - topic==\"/images/delete\"\n      - topic==\"/tasks/oom\"\n      - topic==\"/tasks/delete\""
        },
        "/etc/datadog-agent/conf.d/coredns.d/auto_conf.yaml": {
            "hash": "8368abaf5625909c7bac86c02f6fe12822c03f013e5412fe767029eed09c33c0",
            "raw_config": "ad_identifiers:\n  - coredns\ncel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\ninstances:\n  - prometheus_url: http://%%host%%:9153/metrics\n    tags:\n      - dns-pod:%%host%%"
        },
        "/etc/datadog-agent/conf.d/couch.d/auto_conf.yaml": {
            "hash": "bde2481fe4af486efb99c36baf4fc6600abe9c9dd302492a777d3bb7a22ffd2b",
            "raw_config": "ad_identifiers:\n  - couchdb\ncel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\ninstances:\n  - server: http://%%host%%:5984"
        },
        "/etc/datadog-agent/conf.d/couchbase.d/auto_conf.yaml": {
            "hash": "0750189b06f58b92f66bdb38ba172b325ffa30fac8f853166a08501e914997d4",
            "raw_config": "ad_identifiers:\n  - couchbase\ncel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\ninstances:\n  - server: http://%%host%%:8091"
        },
        "/etc/datadog-agent/conf.d/cpu.d/conf.yaml.default": {
            "hash": "943384e901b9f8abe4ad1c2405d3bc6f36204a7a2d8f7e5d79c10632607fac69",
            "raw_config": "cel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\ninstances:\n  - {}"
        },
        "/etc/datadog-agent/conf.d/cri.d/conf.yaml.default": {
            "hash": "a528552c6edf8203f37e8119c33a05450b4c374518691f0554a98d5534f1eb45",
            "raw_config": "ad_identifiers:\n  - _cri\ncel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\ninstances:\n  - {}"
        },
        "/etc/datadog-agent/conf.d/datadog_cluster_agent.d/auto_conf.yaml": {
            "hash": "cfe588883fcfec5f255f01a8f7c80a6b71b3e769d49c76c19c6e6f88b02fd178",
            "raw_config": "ad_identifiers:\n  - cluster-agent\ncel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\ninstances:\n  - prometheus_url: http://%%host%%:5000/metrics"
        },
        "/etc/datadog-agent/conf.d/datadog_csi_driver.d/auto_conf.yaml": {
            "hash": "e9e3b5744780967ae117d183cd22c4216ad62862b496e51fd0871a33936a7122",
            "raw_config": "ad_identifiers:\n  - csi-driver\ncel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\ninstances:\n  - openmetrics_endpoint: http://%%host%%:5000/metrics"
        },
        "/etc/datadog-agent/conf.d/discovery.d/conf.yaml.default": {
            "hash": "d54add7ce3ac4429a8c07d58c4a6f43dd4c7272e4c72095ce75c9561e04e2e61",
            "raw_config": "ad_identifiers:\n  - _discovery\ncel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\ninstances:\n  - {}"
        },
        "/etc/datadog-agent/conf.d/disk.d/conf.yaml.default": {
            "hash": "80ae53b8f912e8c040dcf1ca1cb74c6e962d84eccb1bd9f653f8ae06aa9a1d62",
            "raw_config": "cel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\ninstances:\n  - use_mount: false"
        },
        "/etc/datadog-agent/conf.d/docker.d/conf.yaml.default": {
            "hash": "b59a00bd125b25b7dacf4c714f93c9abd67c9df0bfe721afe778ac2be44d0a86",
            "raw_config": "ad_identifiers:\n  - _docker\ncel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\ninstances:\n  - collected_event_types:\n      - oom\n      - kill"
        },
        "/etc/datadog-agent/conf.d/ecs_fargate.d/conf.yaml.default": {
            "hash": "b020beaf20cee6ee09808ba805bdf35de84f40c485d674d348fba654ed3b65c3",
            "raw_config": "ad_identifiers:\n  - _ecs_fargate\ncel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\ninstances:\n  - min_collection_interval: 20"
        },
        "/etc/datadog-agent/conf.d/eks_fargate.d/conf.yaml.default": {
            "hash": "d9a1cac861ce5288d9dd11132154ec3c15627fb76591e3be435f9e402f969935",
            "raw_config": "ad_identifiers:\n  - _eks_fargate\ncel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\ninstances:\n  - {}"
        },
        "/etc/datadog-agent/conf.d/elastic.d/auto_conf.yaml": {
            "hash": "764577ae3e4911d03619c43c65eed82b268459cd58ef64b47e47d38333f4b76b",
            "raw_config": "ad_identifiers:\n  - elasticsearch\n  - elasticsearch-oss\ncel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\ninstances:\n  - url: http://%%host%%:9200"
        },
        "/etc/datadog-agent/conf.d/etcd.d/auto_conf.yaml": {
            "hash": "a5c1ce3fbcba979d4a7c23fffe1404d1440c5e9c0c4b1abf52e8dbc115fa5ceb",
            "raw_config": "ad_identifiers:\n  - etcd\ncel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\ninstances:\n  - possible_prometheus_urls:\n      - https://%%host%%:2379/metrics\n      - http://%%host%%:2379/metrics\n    prometheus_url: http://localhost:2379/metrics\n    ssl_verify: false"
        },
        "/etc/datadog-agent/conf.d/external_dns.d/auto_conf.yaml": {
            "hash": "9dd326cb11eefa5afdb50807df90a98c256c9f2d4fcc93a5fcd7a13ca22ac245",
            "raw_config": "ad_identifiers:\n  - external-dns\ncel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\ninstances:\n  - prometheus_url: http://%%host%%:7979/metrics\n    tags:\n      - externaldns-pod:%%host%%"
        },
        "/etc/datadog-agent/conf.d/file_handle.d/conf.yaml.default": {
            "hash": "943384e901b9f8abe4ad1c2405d3bc6f36204a7a2d8f7e5d79c10632607fac69",
            "raw_config": "cel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\ninstances:\n  - {}"
        },
        "/etc/datadog-agent/conf.d/gpu.d/conf.yaml.default": {
            "hash": "b2ccb2ebe3f5dc5d21b06a901f550db2744bd91782b4355dedaf2feb735e09a0",
            "raw_config": "ad_identifiers:\n  - _gpu\ncel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\ninstances:\n  - {}"
        },
        "/etc/datadog-agent/conf.d/harbor.d/auto_conf.yaml": {
            "hash": "d1883e4cb3b6cdc5c59d890fb5fe13c779f83ee9ad6105e196855a5548f9acb2",
            "raw_config": "ad_identifiers:\n  - nginx-photon\ncel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\ninstances:\n  - password: "********"
        },
        "/etc/datadog-agent/conf.d/hazelcast.d/metrics.yaml": {
            "hash": "210ff40d78b26f10c3c39e7de00ad8dd80399919a3166f3d2617ab911285b9d0",
            "raw_config": "cel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\njmx_metrics:\n  - include:\n      attribute:\n        LicenseExpirationTime:\n          alias: hazelcast.mc.license_expiration_time\n          metric_type: gauge\n      domain: ManagementCenter\n      exclude_tags:\n        - type\n  - include:\n      attribute:\n        clusterTime:\n          alias: hazelcast.instance.cluster_time\n          metric_type: gauge\n        memberCount:\n          alias: hazelcast.instance.member_count\n          metric_type: gauge\n        running:\n          alias: hazelcast.instance.running\n          metric_type: gauge\n        version:\n          alias: hazelcast.instance.version\n          metric_type: gauge\n      domain: com.hazelcast\n      exclude_tags:\n        - instance\n        - type\n      tags:\n        hazelcast_instance: $instance\n      type: HazelcastInstance\n  - include:\n      attribute:\n        activePartitionCount:\n          alias: hazelcast.instance.partition_service.active_partition_count\n          metric_type: gauge\n        isClusterSafe:\n          alias: hazelcast.instance.partition_service.is_cluster_safe\n          metric_type: gauge\n        isLocalMemberSafe:\n          alias: hazelcast.instance.partition_service.is_local_member_safe\n          metric_type: gauge\n        partitionCount:\n          alias: hazelcast.instance.partition_service.partition_count\n          metric_type: gauge\n      domain: com.hazelcast\n      exclude_tags:\n        - instance\n        - type\n      tags:\n        hazelcast_instance: $instance\n      type: HazelcastInstance.PartitionServiceMBean\n  - include:\n      attribute:\n        completedTaskCount:\n          alias: hazelcast.instance.managed_executor_service.completed_task_count\n          metric_type: gauge\n        isShutdown:\n          alias: hazelcast.instance.managed_executor_service.is_shutdown\n          metric_type: gauge\n        isTerminated:\n          alias: hazelcast.instance.managed_executor_service.is_terminated\n          metric_type: gauge\n        maximumPoolSize:\n          alias: hazelcast.instance.managed_executor_service.maximum_pool_size\n          metric_type: gauge\n        poolSize:\n          alias: hazelcast.instance.managed_executor_service.pool_size\n          metric_type: gauge\n        queueSize:\n          alias: hazelcast.instance.managed_executor_service.queue_size\n          metric_type: gauge\n        remainingQueueCapacity:\n          alias: hazelcast.instance.managed_executor_service.remaining_queue_capacity\n          metric_type: gauge\n      domain: com.hazelcast\n      exclude_tags:\n        - instance\n        - type\n      tags:\n        hazelcast_instance: $instance\n      type: HazelcastInstance.ManagedExecutorService\n  - include:\n      attribute:\n        localBackupCount:\n          alias: hazelcast.imap.local_backup_count\n          metric_type: gauge\n        localBackupEntryCount:\n          alias: hazelcast.imap.local_backup_entry_count\n          metric_type: gauge\n        localBackupEntryMemoryCost:\n          alias: hazelcast.imap.local_backup_entry_memory_cost\n          metric_type: gauge\n        localCreationTime:\n          alias: hazelcast.imap.local_creation_time\n          metric_type: gauge\n        localDirtyEntryCount:\n          alias: hazelcast.imap.local_dirty_entry_count\n          metric_type: gauge\n        localEventOperationCount:\n          alias: hazelcast.imap.local_event_operation_count\n          metric_type: gauge\n        localGetOperationCount:\n          alias: hazelcast.imap.local_get_operation_count\n          metric_type: gauge\n        localHeapCost:\n          alias: hazelcast.imap.local_heap_cost\n          metric_type: gauge\n        localHits:\n          alias: hazelcast.imap.local_hits\n          metric_type: gauge\n        localLastAccessTime:\n          alias: hazelcast.imap.local_last_access_time\n          metric_type: gauge\n        localLastUpdateTime:\n          alias: hazelcast.imap.local_last_update_time\n          metric_type: gauge\n        localLockedEntryCount:\n          alias: hazelcast.imap.local_locked_entry_count\n          metric_type: gauge\n        localMaxGetLatency:\n          alias: hazelcast.imap.local_max_get_latency\n          metric_type: gauge\n        localMaxPutLatency:\n          alias: hazelcast.imap.local_max_put_latency\n          metric_type: gauge\n        localMaxRemoveLatency:\n          alias: hazelcast.imap.local_max_remove_latency\n          metric_type: gauge\n        localOtherOperationCount:\n          alias: hazelcast.imap.local_other_operation_count\n          metric_type: gauge\n        localOwnedEntryCount:\n          alias: hazelcast.imap.local_owned_entry_count\n          metric_type: gauge\n        localOwnedEntryMemoryCost:\n          alias: hazelcast.imap.local_owned_entry_memory_cost\n          metric_type: gauge\n        localPutOperationCount:\n          alias: hazelcast.imap.local_put_operation_count\n          metric_type: gauge\n        localRemoveOperationCount:\n          alias: hazelcast.imap.local_remove_operation_count\n          metric_type: gauge\n        localTotal:\n          alias: hazelcast.imap.local_total\n          metric_type: gauge\n        localTotalGetLatency:\n          alias: hazelcast.imap.local_total_get_latency\n          metric_type: gauge\n        localTotalPutLatency:\n          alias: hazelcast.imap.local_total_put_latency\n          metric_type: gauge\n        localTotalRemoveLatency:\n          alias: hazelcast.imap.local_total_remove_latency\n          metric_type: gauge\n        size:\n          alias: hazelcast.imap.size\n          metric_type: gauge\n      domain: com.hazelcast\n      exclude_tags:\n        - instance\n        - type\n      tags:\n        hazelcast_instance: $instance\n      type: IMap\n  - include:\n      attribute:\n        localBackupCount:\n          alias: hazelcast.multimap.local_backup_count\n          metric_type: gauge\n        localBackupEntryCount:\n          alias: hazelcast.multimap.local_backup_entry_count\n          metric_type: gauge\n        localBackupEntryMemoryCost:\n          alias: hazelcast.multimap.local_backup_entry_memory_cost\n          metric_type: gauge\n        localCreationTime:\n          alias: hazelcast.multimap.local_creation_time\n          metric_type: gauge\n        localEventOperationCount:\n          alias: hazelcast.multimap.local_event_operation_count\n          metric_type: gauge\n        localGetOperationCount:\n          alias: hazelcast.multimap.local_get_operation_count\n          metric_type: gauge\n        localHits:\n          alias: hazelcast.multimap.local_hits\n          metric_type: gauge\n        localLastAccessTime:\n          alias: hazelcast.multimap.local_last_access_time\n          metric_type: gauge\n        localLastUpdateTime:\n          alias: hazelcast.multimap.local_last_update_time\n          metric_type: gauge\n        localLockedEntryCount:\n          alias: hazelcast.multimap.local_locked_entry_count\n          metric_type: gauge\n        localMaxGetLatency:\n          alias: hazelcast.multimap.local_max_get_latency\n          metric_type: gauge\n        localMaxPutLatency:\n          alias: hazelcast.multimap.local_max_put_latency\n          metric_type: gauge\n        localMaxRemoveLatency:\n          alias: hazelcast.multimap.local_max_remove_latency\n          metric_type: gauge\n        localOtherOperationCount:\n          alias: hazelcast.multimap.local_other_operation_count\n          metric_type: gauge\n        localOwnedEntryCount:\n          alias: hazelcast.multimap.local_owned_entry_count\n          metric_type: gauge\n        localOwnedEntryMemoryCost:\n          alias: hazelcast.multimap.local_owned_entry_memory_cost\n          metric_type: gauge\n        localPutOperationCount:\n          alias: hazelcast.multimap.local_put_operation_count\n          metric_type: gauge\n        localRemoveOperationCount:\n          alias: hazelcast.multimap.local_remove_operation_count\n          metric_type: gauge\n        localTotal:\n          alias: hazelcast.multimap.local_total\n          metric_type: gauge\n        localTotalGetLatency:\n          alias: hazelcast.multimap.local_total_get_latency\n          metric_type: gauge\n        localTotalPutLatency:\n          alias: hazelcast.multimap.local_total_put_latency\n          metric_type: gauge\n        localTotalRemoveLatency:\n          alias: hazelcast.multimap.local_total_remove_latency\n          metric_type: gauge\n        size:\n          alias: hazelcast.multimap.size\n          metric_type: gauge\n      domain: com.hazelcast\n      exclude_tags:\n        - instance\n        - type\n      tags:\n        hazelcast_instance: $instance\n      type: MultiMap\n  - include:\n      attribute:\n        localCreationTime:\n          alias: hazelcast.replicatedmap.local_creation_time\n          metric_type: gauge\n        localEventOperationCount:\n          alias: hazelcast.replicatedmap.local_event_operation_count\n          metric_type: gauge\n        localGetOperationCount:\n          alias: hazelcast.replicatedmap.local_get_operation_count\n          metric_type: gauge\n        localHits:\n          alias: hazelcast.replicatedmap.local_hits\n          metric_type: gauge\n        localLastAccessTime:\n          alias: hazelcast.replicatedmap.local_last_access_time\n          metric_type: gauge\n        localLastUpdateTime:\n          alias: hazelcast.replicatedmap.local_last_update_time\n          metric_type: gauge\n        localMaxGetLatency:\n          alias: hazelcast.replicatedmap.local_max_get_latency\n          metric_type: gauge\n        localMaxPutLatency:\n          alias: hazelcast.replicatedmap.local_max_put_latency\n          metric_type: gauge\n        localMaxRemoveLatency:\n          alias: hazelcast.replicatedmap.local_max_remove_latency\n          metric_type: gauge\n        localOtherOperationCount:\n          alias: hazelcast.replicatedmap.local_other_operation_count\n          metric_type: gauge\n        localOwnedEntryCount:\n          alias: hazelcast.replicatedmap.local_owned_entry_count\n          metric_type: gauge\n        localPutOperationCount:\n          alias: hazelcast.replicatedmap.local_put_operation_count\n          metric_type: gauge\n        localRemoveOperationCount:\n          alias: hazelcast.replicatedmap.local_remove_operation_count\n          metric_type: gauge\n        localTotal:\n          alias: hazelcast.replicatedmap.local_total\n          metric_type: gauge\n        localTotalGetLatency:\n          alias: hazelcast.replicatedmap.local_total_get_latency\n          metric_type: gauge\n        localTotalPutLatency:\n          alias: hazelcast.replicatedmap.local_total_put_latency\n          metric_type: gauge\n        localTotalRemoveLatency:\n          alias: hazelcast.replicatedmap.local_total_remove_latency\n          metric_type: gauge\n        size:\n          alias: hazelcast.replicatedmap.size\n          metric_type: gauge\n      domain: com.hazelcast\n      exclude_tags:\n        - instance\n        - type\n      tags:\n        hazelcast_instance: $instance\n      type: ReplicatedMap\n  - include:\n      attribute:\n        acceptedSocketCount:\n          alias: hazelcast.member.accepted_socket_count\n          metric_type: gauge\n        activeCount:\n          alias: hazelcast.member.active_count\n          metric_type: gauge\n        activeMembers:\n          alias: hazelcast.member.active_members\n          metric_type: gauge\n        activeMembersCommitIndex:\n          alias: hazelcast.member.active_members_commit_index\n          metric_type: gauge\n        asyncOperations:\n          alias: hazelcast.member.async_operations\n          metric_type: gauge\n        availableProcessors:\n          alias: hazelcast.member.available_processors\n          metric_type: gauge\n        backupTimeoutMillis:\n          alias: hazelcast.member.backup_timeout_millis\n          metric_type: gauge\n        backupTimeouts:\n          alias: hazelcast.member.backup_timeouts\n          metric_type: gauge\n        bytesRead:\n          alias: hazelcast.member.bytes_read\n          metric_type: gauge\n        bytesReceived:\n          alias: hazelcast.member.bytes_received\n          metric_type: gauge\n        bytesSend:\n          alias: hazelcast.member.bytes_send\n          metric_type: gauge\n        bytesTransceived:\n          alias: hazelcast.member.bytes_transceived\n          metric_type: gauge\n        bytesWritten:\n          alias: hazelcast.member.bytes_written\n          metric_type: gauge\n        callTimeoutCount:\n          alias: hazelcast.member.call_timeout_count\n          metric_type: gauge\n        clientCount:\n          alias: hazelcast.member.client_count\n          metric_type: gauge\n        closedCount:\n          alias: hazelcast.member.closed_count\n          metric_type: gauge\n        clusterStartTime:\n          alias: hazelcast.member.cluster_start_time\n          metric_type: gauge\n        clusterTime:\n          alias: hazelcast.member.cluster_time\n          metric_type: gauge\n        clusterTimeDiff:\n          alias: hazelcast.member.cluster_time_diff\n          metric_type: gauge\n        clusterUpTime:\n          alias: hazelcast.member.cluster_up_time\n          metric_type: gauge\n        commitCount:\n          alias: hazelcast.member.commit_count\n          metric_type: gauge\n        committedHeap:\n          alias: hazelcast.member.committed_heap\n          metric_type: gauge\n        committedNative:\n          alias: hazelcast.member.committed_native\n          metric_type: gauge\n        committedVirtualMemorySize:\n          alias: hazelcast.member.committed_virtual_memory_size\n          metric_type: gauge\n        completedCount:\n          alias: hazelcast.member.completed_count\n          metric_type: gauge\n        completedMigrations:\n          alias: hazelcast.member.completed_migrations\n          metric_type: gauge\n        completedOperationBatchCount:\n          alias: hazelcast.member.completed_operation_batch_count\n          metric_type: gauge\n        completedOperationCount:\n          alias: hazelcast.member.completed_operation_count\n          metric_type: gauge\n        completedPacketCount:\n          alias: hazelcast.member.completed_packet_count\n          metric_type: gauge\n        completedPartitionSpecificRunnableCount:\n          alias: hazelcast.member.completed_partition_specific_runnable_count\n          metric_type: gauge\n        completedRunnableCount:\n          alias: hazelcast.member.completed_runnable_count\n          metric_type: gauge\n        completedTaskCount:\n          alias: hazelcast.member.completed_task_count\n          metric_type: gauge\n        completedTasks:\n          alias: hazelcast.member.completed_tasks\n          metric_type: gauge\n        completedTotalCount:\n          alias: hazelcast.member.completed_total_count\n          metric_type: gauge\n        connectionListenerCount:\n          alias: hazelcast.member.connection_listener_count\n          metric_type: gauge\n        connectionType:\n          alias: hazelcast.member.connection_type\n          metric_type: gauge\n        count:\n          alias: hazelcast.member.count\n          metric_type: gauge\n        createdCount:\n          alias: hazelcast.member.created_count\n          metric_type: gauge\n        daemonThreadCount:\n          alias: hazelcast.member.daemon_thread_count\n          metric_type: gauge\n        delayedExecutionCount:\n          alias: hazelcast.member.delayed_execution_count\n          metric_type: gauge\n        destroyedCount:\n          alias: hazelcast.member.destroyed_count\n          metric_type: gauge\n        destroyedGroupIds:\n          alias: hazelcast.member.destroyed_group_ids\n          metric_type: gauge\n        elapsedDestinationCommitTime:\n          alias: hazelcast.member.elapsed_destination_commit_time\n          metric_type: gauge\n        elapsedMigrationOperationTime:\n          alias: hazelcast.member.elapsed_migration_operation_time\n          metric_type: gauge\n        elapsedMigrationTime:\n          alias: hazelcast.member.elapsed_migration_time\n          metric_type: gauge\n        errorCount:\n          alias: hazelcast.member.error_count\n          metric_type: gauge\n        eventCount:\n          alias: hazelcast.member.event_count\n          metric_type: gauge\n        eventQueueSize:\n          alias: hazelcast.member.event_queue_size\n          metric_type: gauge\n        eventsProcessed:\n          alias: hazelcast.member.events_processed\n          metric_type: gauge\n        exceptionCount:\n          alias: hazelcast.member.exception_count\n          metric_type: gauge\n        failedBackups:\n          alias: hazelcast.member.failed_backups\n          metric_type: gauge\n        framesTransceived:\n          alias: hazelcast.member.frames_transceived\n          metric_type: gauge\n        freeHeap:\n          alias: hazelcast.member.free_heap\n          metric_type: gauge\n        freeMemory:\n          alias: hazelcast.member.free_memory\n          metric_type: gauge\n        freeNative:\n          alias: hazelcast.member.free_native\n          metric_type: gauge\n        freePhysical:\n          alias: hazelcast.member.free_physical\n          metric_type: gauge\n        freePhysicalMemorySize:\n          alias: hazelcast.member.free_physical_memory_size\n          metric_type: gauge\n        freeSpace:\n          alias: hazelcast.member.free_space\n          metric_type: gauge\n        freeSwapSpaceSize:\n          alias: hazelcast.member.free_swap_space_size\n          metric_type: gauge\n        genericPriorityQueueSize:\n          alias: hazelcast.member.generic_priority_queue_size\n          metric_type: gauge\n        genericQueueSize:\n          alias: hazelcast.member.generic_queue_size\n          metric_type: gauge\n        genericThreadCount:\n          alias: hazelcast.member.generic_thread_count\n          metric_type: gauge\n        groups:\n          alias: hazelcast.member.groups\n          metric_type: gauge\n        heartbeatBroadcastPeriodMillis:\n          alias: hazelcast.member.heartbeat_broadcast_period_millis\n          metric_type: gauge\n        heartbeatPacketsReceived:\n          alias: hazelcast.member.heartbeat_packets_received\n          metric_type: gauge\n        heartbeatPacketsSent:\n          alias: hazelcast.member.heartbeat_packets_sent\n          metric_type: gauge\n        idleTimeMillis:\n          alias: hazelcast.member.idle_time_millis\n          metric_type: gauge\n        idleTimeMs:\n          alias: hazelcast.member.idle_time_ms\n          metric_type: gauge\n        imbalanceDetectedCount:\n          alias: hazelcast.member.imbalance_detected_count\n          metric_type: gauge\n        inProgressCount:\n          alias: hazelcast.member.in_progress_count\n          metric_type: gauge\n        invocationScanPeriodMillis:\n          alias: hazelcast.member.invocation_scan_period_millis\n          metric_type: gauge\n        invocationTimeoutMillis:\n          alias: hazelcast.member.invocation_timeout_millis\n          metric_type: gauge\n        invocations.lastCallId:\n          alias: hazelcast.member.invocations.last_call_id\n          metric_type: gauge\n        invocations.pending:\n          alias: hazelcast.member.invocations.pending\n          metric_type: gauge\n        invocations.usedPercentage:\n          alias: hazelcast.member.invocations.used_percentage\n          metric_type: gauge\n        ioThreadId:\n          alias: hazelcast.member.io_thread_id\n          metric_type: gauge\n        lastCallId:\n          alias: hazelcast.member.invocations.last_call_id\n          metric_type: gauge\n        lastHeartbeat:\n          alias: hazelcast.member.last_heartbeat\n          metric_type: gauge\n        lastRepartitionTime:\n          alias: hazelcast.member.last_repartition_time\n          metric_type: gauge\n        listenerCount:\n          alias: hazelcast.member.listener_count\n          metric_type: gauge\n        loadedClassesCount:\n          alias: hazelcast.member.loaded_classes_count\n          metric_type: gauge\n        localClockTime:\n          alias: hazelcast.member.local_clock_time\n          metric_type: gauge\n        localPartitionCount:\n          alias: hazelcast.member.local_partition_count\n          metric_type: gauge\n        majorCount:\n          alias: hazelcast.member.major_count\n          metric_type: gauge\n        majorTime:\n          alias: hazelcast.member.major_time\n          metric_type: gauge\n        maxBackupCount:\n          alias: hazelcast.member.max_backup_count\n          metric_type: gauge\n        maxClusterTimeDiff:\n          alias: hazelcast.member.max_cluster_time_diff\n          metric_type: gauge\n        maxFileDescriptorCount:\n          alias: hazelcast.member.max_file_descriptor_count\n          metric_type: gauge\n        maxHeap:\n          alias: hazelcast.member.max_heap\n          metric_type: gauge\n        maxMemory:\n          alias: hazelcast.member.max_memory\n          metric_type: gauge\n        maxMetadata:\n          alias: hazelcast.member.max_metadata\n          metric_type: gauge\n        maxNative:\n          alias: hazelcast.member.max_native\n          metric_type: gauge\n        maximumPoolSize:\n          alias: hazelcast.member.maximum_pool_size\n          metric_type: gauge\n        memberGroupsSize:\n          alias: hazelcast.member.member_groups_size\n          metric_type: gauge\n        migrationActive:\n          alias: hazelcast.member.migration_active\n          metric_type: gauge\n        migrationCompletedCount:\n          alias: hazelcast.member.migration_completed_count\n          metric_type: gauge\n        migrationQueueSize:\n          alias: hazelcast.member.migration_queue_size\n          metric_type: gauge\n        minorCount:\n          alias: hazelcast.member.minor_count\n          metric_type: gauge\n        minorTime:\n          alias: hazelcast.member.minor_time\n          metric_type: gauge\n        missingMembers:\n          alias: hazelcast.member.missing_members\n          metric_type: gauge\n        monitorCount:\n          alias: hazelcast.member.monitor_count\n          metric_type: gauge\n        nodes:\n          alias: hazelcast.member.nodes\n          metric_type: gauge\n        normalFramesRead:\n          alias: hazelcast.member.normal_frames_read\n          metric_type: gauge\n        normalFramesWritten:\n          alias: hazelcast.member.normal_frames_written\n          metric_type: gauge\n        normalPendingCount:\n          alias: hazelcast.member.normal_pending_count\n          metric_type: gauge\n        normalTimeouts:\n          alias: hazelcast.member.normal_timeouts\n          metric_type: gauge\n        openFileDescriptorCount:\n          alias: hazelcast.member.open_file_descriptor_count\n          metric_type: gauge\n        openedCount:\n          alias: hazelcast.member.opened_count\n          metric_type: gauge\n        operationTimeoutCount:\n          alias: hazelcast.member.operation_timeout_count\n          metric_type: gauge\n        ownerId:\n          alias: hazelcast.member.owner_id\n          metric_type: gauge\n        packetsReceived:\n          alias: hazelcast.member.packets_received\n          metric_type: gauge\n        packetsSend:\n          alias: hazelcast.member.packets_send\n          metric_type: gauge\n        parkQueueCount:\n          alias: hazelcast.member.park_queue_count\n          metric_type: gauge\n        partitionThreadCount:\n          alias: hazelcast.member.partition_thread_count\n          metric_type: gauge\n        peakThreadCount:\n          alias: hazelcast.member.peak_thread_count\n          metric_type: gauge\n        pending:\n          alias: hazelcast.member.invocations.pending\n          metric_type: gauge\n        plannedMigrations:\n          alias: hazelcast.member.planned_migrations\n          metric_type: gauge\n        poolSize:\n          alias: hazelcast.member.pool_size\n          metric_type: gauge\n        priorityFramesRead:\n          alias: hazelcast.member.priority_frames_read\n          metric_type: gauge\n        priorityFramesTransceived:\n          alias: hazelcast.member.priority_frames_transceived\n          metric_type: gauge\n        priorityFramesWritten:\n          alias: hazelcast.member.priority_frames_written\n          metric_type: gauge\n        priorityPendingCount:\n          alias: hazelcast.member.priority_pending_count\n          metric_type: gauge\n        priorityQueueSize:\n          alias: hazelcast.member.priority_queue_size\n          metric_type: gauge\n        priorityWriteQueueSize:\n          alias: hazelcast.member.priority_write_queue_size\n          metric_type: gauge\n        processCount:\n          alias: hazelcast.member.process_count\n          metric_type: gauge\n        processCpuLoad:\n          alias: hazelcast.member.process_cpu_load\n          metric_type: gauge\n        processCpuTime:\n          alias: hazelcast.member.process_cpu_time\n          metric_type: gauge\n        proxyCount:\n          alias: hazelcast.member.proxy_count\n          metric_type: gauge\n        publicationCount:\n          alias: hazelcast.member.publication_count\n          metric_type: gauge\n        queueCapacity:\n          alias: hazelcast.member.queue_capacity\n          metric_type: gauge\n        queueSize:\n          alias: hazelcast.member.queue_size\n          metric_type: gauge\n        rejectedCount:\n          alias: hazelcast.member.rejected_count\n          metric_type: gauge\n        remainingQueueCapacity:\n          alias: hazelcast.member.remaining_queue_capacity\n          metric_type: gauge\n        replicaSyncRequestsCounter:\n          alias: hazelcast.member.replica_sync_requests_counter\n          metric_type: gauge\n        replicaSyncSemaphore:\n          alias: hazelcast.member.replica_sync_semaphore\n          metric_type: gauge\n        responseQueueSize:\n          alias: hazelcast.member.response_queue_size\n          metric_type: gauge\n        responses.backupCount:\n          alias: hazelcast.member.responses.backup_count\n          metric_type: gauge\n        responses.errorCount:\n          alias: hazelcast.member.responses.error_count\n          metric_type: gauge\n        responses.missingCount:\n          alias: hazelcast.member.responses.missing_count\n          metric_type: gauge\n        responses.normalCount:\n          alias: hazelcast.member.responses.normal_count\n          metric_type: gauge\n        responses.timeoutCount:\n          alias: hazelcast.member.responses.timeout_count\n          metric_type: gauge\n        retryCount:\n          alias: hazelcast.member.retry_count\n          metric_type: gauge\n        rollbackCount:\n          alias: hazelcast.member.rollback_count\n          metric_type: gauge\n        runningCount:\n          alias: hazelcast.member.running_count\n          metric_type: gauge\n        runningGenericCount:\n          alias: hazelcast.member.running_generic_count\n          metric_type: gauge\n        runningPartitionCount:\n          alias: hazelcast.member.running_partition_count\n          metric_type: gauge\n        scheduled:\n          alias: hazelcast.member.scheduled\n          metric_type: gauge\n        selectorIOExceptionCount:\n          alias: hazelcast.member.selector_i_o_exception_count\n          metric_type: gauge\n        selectorRebuildCount:\n          alias: hazelcast.member.selector_rebuild_count\n          metric_type: gauge\n        selectorRecreateCount:\n          alias: hazelcast.member.selector_recreate_count\n          metric_type: gauge\n        size:\n          alias: hazelcast.member.size\n          metric_type: gauge\n        startCount:\n          alias: hazelcast.member.start_count\n          metric_type: gauge\n        startedMigrations:\n          alias: hazelcast.member.started_migrations\n          metric_type: gauge\n        stateVersion:\n          alias: hazelcast.member.state_version\n          metric_type: gauge\n        syncDeliveryFailureCount:\n          alias: hazelcast.member.sync_delivery_failure_count\n          metric_type: gauge\n        systemCpuLoad:\n          alias: hazelcast.member.system_cpu_load\n          metric_type: gauge\n        systemLoadAverage:\n          alias: hazelcast.member.system_load_average\n          metric_type: gauge\n        taskQueueSize:\n          alias: hazelcast.member.task_queue_size\n          metric_type: gauge\n        terminatedRaftNodeGroupIds:\n          alias: hazelcast.member.terminated_raft_node_group_ids\n          metric_type: gauge\n        textCount:\n          alias: hazelcast.member.text_count\n          metric_type: gauge\n        threadCount:\n          alias: hazelcast.member.thread_count\n          metric_type: gauge\n        totalCompletedMigrations:\n          alias: hazelcast.member.total_completed_migrations\n          metric_type: gauge\n        totalElapsedDestinationCommitTime:\n          alias: hazelcast.member.total_elapsed_destination_commit_time\n          metric_type: gauge\n        totalElapsedMigrationOperationTime:\n          alias: hazelcast.member.total_elapsed_migration_operation_time\n          metric_type: gauge\n        totalElapsedMigrationTime:\n          alias: hazelcast.member.total_elapsed_migration_time\n          metric_type: gauge\n        totalFailureCount:\n          alias: hazelcast.member.total_failure_count\n          metric_type: gauge\n        totalLoadedClassesCount:\n          alias: hazelcast.member.total_loaded_classes_count\n          metric_type: gauge\n        totalMemory:\n          alias: hazelcast.member.total_memory\n          metric_type: gauge\n        totalParkedOperationCount:\n          alias: hazelcast.member.total_parked_operation_count\n          metric_type: gauge\n        totalPhysical:\n          alias: hazelcast.member.total_physical\n          metric_type: gauge\n        totalPhysicalMemorySize:\n          alias: hazelcast.member.total_physical_memory_size\n          metric_type: gauge\n        totalRegistrations:\n          alias: hazelcast.member.total_registrations\n          metric_type: gauge\n        totalSpace:\n          alias: hazelcast.member.total_space\n          metric_type: gauge\n        totalStartedThreadCount:\n          alias: hazelcast.member.total_started_thread_count\n          metric_type: gauge\n        totalSwapSpaceSize:\n          alias: hazelcast.member.total_swap_space_size\n          metric_type: gauge\n        unknownCount:\n          alias: hazelcast.member.unknown_count\n          metric_type: gauge\n        unknownTime:\n          alias: hazelcast.member.unknown_time\n          metric_type: gauge\n        unknowsnCount:\n          alias: hazelcast.member.unknown_count\n          metric_type: gauge\n        unloadedClassesCount:\n          alias: hazelcast.member.unloaded_classes_count\n          metric_type: gauge\n        uptime:\n          alias: hazelcast.member.uptime\n          metric_type: gauge\n        usableSpace:\n          alias: hazelcast.member.usable_space\n          metric_type: gauge\n        usedHeap:\n          alias: hazelcast.member.used_heap\n          metric_type: gauge\n        usedMemory:\n          alias: hazelcast.member.used_memory\n          metric_type: gauge\n        usedMetadata:\n          alias: hazelcast.member.used_metadata\n          metric_type: gauge\n        usedNative:\n          alias: hazelcast.member.used_native\n          metric_type: gauge\n        usedPercentage:\n          alias: hazelcast.member.invocations.used_percentage\n          metric_type: gauge\n        writeQueueSize:\n          alias: hazelcast.member.write_queue_size\n          metric_type: gauge\n      domain: com.hazelcast\n      exclude_tags:\n        - instance\n        - type\n        - tag.*\n      tags:\n        hazelcast_instance: $instance\n      type: Metrics\n  - include:\n      attribute:\n        localAverageAge:\n          alias: hazelcast.iqueue.average_age\n          metric_type: gauge\n        localBackupItemCount:\n          alias: hazelcast.iqueue.backup_item_count\n          metric_type: gauge\n        localEmptyPollOperationCount:\n          alias: hazelcast.iqueue.empty_poll_operation_count\n          metric_type: gauge\n        localEventOperationCount:\n          alias: hazelcast.iqueue.event_operation_count\n          metric_type: gauge\n        localMaxAge:\n          alias: hazelcast.iqueue.maximum_age\n          metric_type: gauge\n        localMinAge:\n          alias: hazelcast.iqueue.minimum_age\n          metric_type: gauge\n        localOfferOperationCount:\n          alias: hazelcast.iqueue.offer_operation_count\n          metric_type: gauge\n        localOtherOperationsCount:\n          alias: hazelcast.iqueue.other_operation_count\n          metric_type: gauge\n        localOwnedItemCount:\n          alias: hazelcast.iqueue.owned_item_count\n          metric_type: gauge\n        localPollOperationCount:\n          alias: hazelcast.iqueue.poll_operation_count\n          metric_type: gauge\n        localRejectedOfferOperationCount:\n          alias: hazelcast.iqueue.rejected_offer_operation_count\n          metric_type: gauge\n      domain: com.hazelcast\n      exclude_tags:\n        - instance\n        - type\n      tags:\n        hazelcast_instance: $instance\n      type: IQueue\n  - include:\n      attribute:\n        localCreationTime:\n          alias: hazelcast.reliabletopic.creation_time\n          metric_type: gauge\n        localPublishOperationCount:\n          alias: hazelcast.reliabletopic.publish_operation_count\n          metric_type: gauge\n        localReceiveOperationCount:\n          alias: hazelcast.reliabletopic.receive_operation_count\n          metric_type: gauge\n      domain: com.hazelcast\n      exclude_tags:\n        - instance\n        - type\n      tags:\n        hazelcast_instance: $instance\n      type: ReliableTopic\n  - include:\n      attribute:\n        localCreationTime:\n          alias: hazelcast.topic.creation_time\n          metric_type: gauge\n        localPublishOperationCount:\n          alias: hazelcast.topic.publish_operation_count\n          metric_type: gauge\n        localReceiveOperationCount:\n          alias: hazelcast.topic.receive_operation_count\n          metric_type: gauge\n      domain: com.hazelcast\n      exclude_tags:\n        - instance\n        - type\n      tags:\n        hazelcast_instance: $instance\n      type: ITopic"
        },
        "/etc/datadog-agent/conf.d/hive.d/metrics.yaml": {
            "hash": "19120d2041ec55a01ddc18095b52dd73aa3b7666f6320fabeb4d124c796f2a8f",
            "raw_config": "cel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\njmx_metrics:\n  - include:\n      attribute:\n        Count:\n          alias: hive.server.open_operations\n          metric_type: gauge\n      bean: metrics:name=open_operations\n  - include:\n      attribute:\n        Value:\n          alias: hive.server.session.active\n          metric_type: gauge\n      bean: metrics:name=hs2_active_sessions\n  - include:\n      attribute:\n        Value:\n          alias: hive.server.session.active.time_mean\n          metric_type: gauge\n      bean: metrics:name=hs2_avg_active_session_time\n  - include:\n      attribute:\n        Value:\n          alias: hive.server.session.open\n          metric_type: gauge\n      bean: metrics:name=hs2_open_sessions\n  - include:\n      attribute:\n        Value:\n          alias: hive.server.session.open.time_mean\n          metric_type: gauge\n      bean: metrics:name=hs2_avg_open_session_time\n  - include:\n      attribute:\n        Count:\n          alias: hive.server.queries.submitted.active_call\n          metric_type: gauge\n      bean: metrics:name=active_calls_hs2_submitted_queries\n  - include:\n      attribute:\n        75thPercentile:\n          alias: hive.server.queries.submitted.75percentile\n          metric_type: gauge\n        95thPercentile:\n          alias: hive.server.queries.submitted.95percentile\n          metric_type: gauge\n        Count:\n          alias: hive.server.queries.submitted.count\n          metric_type: monotonic_count\n        Max:\n          alias: hive.server.queries.submitted.max\n          metric_type: gauge\n        Mean:\n          alias: hive.server.queries.submitted.mean\n          metric_type: gauge\n        MeanRate:\n          alias: hive.server.queries.submitted.meanrate\n          metric_type: rate\n        Min:\n          alias: hive.server.queries.submitted.min\n          metric_type: gauge\n      bean: metrics:name=hs2_submitted_queries\n  - include:\n      attribute:\n        Count:\n          alias: hive.server.queries.compiling.active_call\n          metric_type: gauge\n      bean: metrics:name=active_calls_hs2_compiling_queries\n  - include:\n      attribute:\n        75thPercentile:\n          alias: hive.server.queries.compiling.75percentile\n          metric_type: gauge\n        95thPercentile:\n          alias: hive.server.queries.compiling.95percentile\n          metric_type: gauge\n        Count:\n          alias: hive.server.queries.compiling.count\n          metric_type: monotonic_count\n        Max:\n          alias: hive.server.queries.compiling.max\n          metric_type: gauge\n        Mean:\n          alias: hive.server.queries.compiling.mean\n          metric_type: gauge\n        MeanRate:\n          alias: hive.server.queries.compiling.meanrate\n          metric_type: rate\n        Min:\n          alias: hive.server.queries.compiling.min\n          metric_type: gauge\n      bean: metrics:name=hs2_compiling_queries\n  - include:\n      attribute:\n        Count:\n          alias: hive.server.api.queries.executing.active_call\n          metric_type: gauge\n      bean: metrics:name=active_calls_hs2_executing_queries\n  - include:\n      attribute:\n        75thPercentile:\n          alias: hive.server.queries.executing.75percentile\n          metric_type: gauge\n        95thPercentile:\n          alias: hive.server.queries.executing.95percentile\n          metric_type: gauge\n        Count:\n          alias: hive.server.queries.executing.count\n          metric_type: monotonic_count\n        Max:\n          alias: hive.server.queries.executing.max\n          metric_type: gauge\n        Mean:\n          alias: hive.server.queries.executing.mean\n          metric_type: gauge\n        MeanRate:\n          alias: hive.server.queries.executing.meanrate\n          metric_type: rate\n        Min:\n          alias: hive.server.queries.executing.min\n          metric_type: gauge\n      bean: metrics:name=hs2_executing_queries\n  - include:\n      attribute:\n        Count:\n          alias: hive.server.queries.succeeded.count\n          type: monotonic_count\n        MeanRate:\n          alias: hive.server.queries.succeeded.meanrate\n          type: rate\n      bean: metrics:name=hs2_succeeded_queries\n  - include:\n      attribute:\n        Count:\n          alias: hive.server.api.sql_operation.pending.active_call\n          metric_type: gauge\n      bean: metrics:name=active_calls_api_hs2_sql_operation_PENDING\n  - include:\n      attribute:\n        75thPercentile:\n          alias: hive.server.api.sql_operation.pending.75percentile\n          metric_type: gauge\n        95thPercentile:\n          alias: hive.server.api.sql_operation.pending.95percentile\n          metric_type: gauge\n        Count:\n          alias: hive.server.api.sql_operation.pending.count\n          metric_type: monotonic_count\n        Max:\n          alias: hive.server.api.sql_operation.pending.max\n          metric_type: gauge\n        Mean:\n          alias: hive.server.api.sql_operation.pending.mean\n          metric_type: gauge\n        MeanRate:\n          alias: hive.server.api.sql_operation.pending.meanrate\n          metric_type: rate\n        Min:\n          alias: hive.server.api.sql_operation.pending.min\n          metric_type: gauge\n      bean: metrics:name=api_hs2_sql_operation_PENDING\n  - include:\n      attribute:\n        Count:\n          alias: hive.server.api.sql_operation.running.active_call\n          metric_type: gauge\n      bean: metrics:name=active_calls_api_hs2_sql_operation_RUNNING\n  - include:\n      attribute:\n        75thPercentile:\n          alias: hive.server.api.sql_operation.running.75percentile\n          metric_type: gauge\n        95thPercentile:\n          alias: hive.server.api.sql_operation.running.95percentile\n          metric_type: gauge\n        Count:\n          alias: hive.server.api.sql_operation.running.count\n          metric_type: monotonic_count\n        Max:\n          alias: hive.server.api.sql_operation.running.max\n          metric_type: gauge\n        Mean:\n          alias: hive.server.api.sql_operation.running.mean\n          metric_type: gauge\n        MeanRate:\n          alias: hive.server.api.sql_operation.running.meanrate\n          metric_type: rate\n        Min:\n          alias: hive.server.api.sql_operation.running.min\n          metric_type: gauge\n      bean: metrics:name=api_hs2_sql_operation_RUNNING\n  - include:\n      attribute:\n        Count:\n          alias: hive.server.sql_operation.completed.closed\n          metric_type: monotonic_count\n      bean: metrics:name=hs2_completed_sql_operation_CLOSED\n  - include:\n      attribute:\n        Count:\n          alias: hive.server.sql_operation.completed.finished\n          metric_type: monotonic_count\n      bean: metrics:name=hs2_completed_sql_operation_FINISHED\n  - include:\n      attribute:\n        Count:\n          alias: hive.server.sql_operation.user.active\n          metric_type: gauge\n      bean: metrics:name=hs2_sql_operation_active_user\n  - include:\n      attribute:\n        Count:\n          alias: hive.server.api.operation.initialized.active_call\n          metric_type: gauge\n      bean: metrics:name=active_calls_api_hs2_operation_INITIALIZED\n  - include:\n      attribute:\n        75thPercentile:\n          alias: hive.server.api.operation.initialized.75percentile\n          metric_type: gauge\n        95thPercentile:\n          alias: hive.server.api.operation.initialized.95percentile\n          metric_type: gauge\n        Count:\n          alias: hive.server.api.operation.initialized.count\n          metric_type: monotonic_count\n        Max:\n          alias: hive.server.api.operation.initialized.max\n          metric_type: gauge\n        Mean:\n          alias: hive.server.api.operation.initialized.mean\n          metric_type: gauge\n        MeanRate:\n          alias: hive.server.api.operation.initialized.meanrate\n          metric_type: rate\n        Min:\n          alias: hive.server.api.operation.initialized.min\n          metric_type: gauge\n      bean: metrics:name=api_hs2_operation_INITIALIZED\n  - include:\n      attribute:\n        Count:\n          alias: hive.server.api.operation.pending.active_call\n          metric_type: gauge\n      bean: metrics:name=active_calls_api_hs2_operation_PENDING\n  - include:\n      attribute:\n        75thPercentile:\n          alias: hive.server.api.operation.pending.75percentile\n          metric_type: gauge\n        95thPercentile:\n          alias: hive.server.api.operation.pending.95percentile\n          metric_type: gauge\n        Count:\n          alias: hive.server.api.operation.pending.count\n          metric_type: monotonic_count\n        Max:\n          alias: hive.server.api.operation.pending.max\n          metric_type: gauge\n        Mean:\n          alias: hive.server.api.operation.pending.mean\n          metric_type: gauge\n        MeanRate:\n          alias: hive.server.api.operation.pending.meanrate\n          metric_type: rate\n        Min:\n          alias: hive.server.api.operation.pending.min\n          metric_type: gauge\n      bean: metrics:name=api_hs2_operation_PENDING\n  - include:\n      attribute:\n        Count:\n          alias: hive.server.api.operation.running.active_call\n          metric_type: gauge\n      bean: metrics:name=active_calls_api_hs2_operation_RUNNING\n  - include:\n      attribute:\n        75thPercentile:\n          alias: hive.server.api.operation.running.75percentile\n          metric_type: gauge\n        95thPercentile:\n          alias: hive.server.api.operation.running.95percentile\n          metric_type: gauge\n        Count:\n          alias: hive.server.api.operation.running.count\n          metric_type: monotonic_count\n        Max:\n          alias: hive.server.api.operation.running.max\n          metric_type: gauge\n        Mean:\n          alias: hive.server.api.operation.running.mean\n          metric_type: gauge\n        MeanRate:\n          alias: hive.server.api.operation.running.meanrate\n          metric_type: rate\n        Min:\n          alias: hive.server.api.operation.running.min\n          metric_type: gauge\n      bean: metrics:name=api_hs2_operation_RUNNING\n  - include:\n      attribute:\n        Count:\n          alias: hive.server.operation.completed.finished\n          metric_type: monotonic_count\n      bean: metrics:name=hs2_completed_operation_FINISHED\n  - include:\n      attribute:\n        Count:\n          alias: hive.server.operation.completed.closed\n          metric_type: monotonic_count\n      bean: metrics:name=hs2_completed_operation_CLOSED\n  - include:\n      attribute:\n        Value:\n          alias: hive.server.memory.heap.init\n          metric_type: gauge\n      bean: metrics:name=memory.heap.init\n  - include:\n      attribute:\n        Value:\n          alias: hive.server.memory.heap.usage\n          metric_type: gauge\n      bean: metrics:name=memory.heap.usage\n  - include:\n      attribute:\n        Value:\n          alias: hive.server.memory.heap.used\n          metric_type: gauge\n      bean: metrics:name=memory.heap.used\n  - include:\n      attribute:\n        Value:\n          alias: hive.server.memory.heap.max\n          metric_type: gauge\n      bean: metrics:name=memory.heap.max\n  - include:\n      attribute:\n        Value:\n          alias: hive.server.memory.heap.committed\n          metric_type: gauge\n      bean: metrics:name=memory.heap.committed\n  - include:\n      attribute:\n        Value:\n          alias: hive.server.memory.non_heap.init\n          metric_type: gauge\n      bean: metrics:name=memory.non-heap.init\n  - include:\n      attribute:\n        Value:\n          alias: hive.server.memory.non_heap.used\n          metric_type: gauge\n      bean: metrics:name=memory.non-heap.used\n  - include:\n      attribute:\n        Value:\n          alias: hive.server.memory.non_heap.max\n          metric_type: gauge\n      bean: metrics:name=memory.non-heap.max\n  - include:\n      attribute:\n        Value:\n          alias: hive.server.memory.non_heap.committed\n          metric_type: gauge\n      bean: metrics:name=memory.non-heap.committed\n  - include:\n      attribute:\n        Value:\n          alias: hive.server.memory.total.init\n          metric_type: gauge\n      bean: metrics:name=memory.total.init\n  - include:\n      attribute:\n        Value:\n          alias: hive.server.memory.total.usage\n          metric_type: gauge\n      bean: metrics:name=memory.total.usage\n  - include:\n      attribute:\n        Value:\n          alias: hive.server.memory.total.used\n          metric_type: gauge\n      bean: metrics:name=memory.total.used\n  - include:\n      attribute:\n        Value:\n          alias: hive.server.memory.total.max\n          metric_type: gauge\n      bean: metrics:name=memory.total.max\n  - include:\n      attribute:\n        Value:\n          alias: hive.server.memory.total.committed\n          metric_type: gauge\n      bean: metrics:name=memory.total.committed\n  - include:\n      attribute:\n        Count:\n          alias: hive.metastore.open_connections\n          metric_type: gauge\n      bean: metrics:name=open_connections\n  - include:\n      attribute:\n        Count:\n          alias: hive.metastore.db.created\n          metric_type: monotonic_count\n      bean: metrics:name=create_total_count_dbs\n  - include:\n      attribute:\n        Count:\n          alias: hive.metastore.db.deleted\n          metric_type: monotonic_count\n      bean: metrics:name=delete_total_count_dbs\n  - include:\n      attribute:\n        Value:\n          alias: hive.metastore.db.init\n          metric_type: monotonic_count\n      bean: metrics:name=init_total_count_dbs\n  - include:\n      attribute:\n        Count:\n          alias: hive.metastore.table.created\n          metric_type: monotonic_count\n      bean: metrics:name=create_total_count_tables\n  - include:\n      attribute:\n        Count:\n          alias: hive.metastore.table.deleted\n          metric_type: monotonic_count\n      bean: metrics:name=delete_total_count_tables\n  - include:\n      attribute:\n        Value:\n          alias: hive.metastore.table.init\n          metric_type: monotonic_count\n      bean: metrics:name=init_total_count_tables\n  - include:\n      attribute:\n        Count:\n          alias: hive.metastore.partition.created\n          metric_type: monotonic_count\n      bean: metrics:name=create_total_count_partitions\n  - include:\n      attribute:\n        Count:\n          alias: hive.metastore.partition.deleted\n          metric_type: monotonic_count\n      bean: metrics:name=delete_total_count_partitions\n  - include:\n      attribute:\n        Value:\n          alias: hive.metastore.partition.init\n          metric_type: gauge\n      bean: metrics:name=init_total_count_partitions\n  - include:\n      attribute:\n        Count:\n          alias: hive.metastore.directsql_errors\n          metric_type: gauge\n      bean: metrics:name=directsql_errors\n  - include:\n      attribute:\n        Count:\n          alias: hive.metastore.api.create_table\n          metric_type: monotonic_count\n      bean: metrics:name=api_create_table\n  - include:\n      attribute:\n        Count:\n          alias: hive.metastore.api.create_table.active_call\n          metric_type: gauge\n      bean: metrics:name=active_calls_api_create_table\n  - include:\n      attribute:\n        Count:\n          alias: hive.metastore.api.get_table\n          metric_type: monotonic_count\n      bean: metrics:name=api_get_table\n  - include:\n      attribute:\n        Count:\n          alias: hive.metastore.api.get_table.active_call\n          metric_type: gauge\n      bean: metrics:name=active_calls_api_get_table\n  - include:\n      attribute:\n        Count:\n          alias: hive.metastore.api.drop_table\n          metric_type: monotonic_count\n      bean: metrics:name=api_drop_table\n  - include:\n      attribute:\n        Count:\n          alias: hive.metastore.api.drop_table.active_call\n          metric_type: gauge\n      bean: metrics:name=active_calls_api_drop_table\n  - include:\n      attribute:\n        Count:\n          alias: hive.metastore.api.init\n          metric_type: monotonic_count\n      bean: metrics:name=api_init\n  - include:\n      attribute:\n        Count:\n          alias: hive.metastore.api.init.active_call\n          metric_type: gauge\n      bean: metrics:name=active_calls_api_init\n  - include:\n      attribute:\n        Count:\n          alias: hive.metastore.api.get_all_databases\n          metric_type: monotonic_count\n      bean: metrics:name=api_get_all_databases\n  - include:\n      attribute:\n        Count:\n          alias: hive.metastore.api.get_all_databases.active_call\n          metric_type: gauge\n      bean: metrics:name=active_calls_api_get_all_databases\n  - include:\n      attribute:\n        Count:\n          alias: hive.metastore.api.get_database\n          metric_type: monotonic_count\n      bean: metrics:name=api_get_database\n  - include:\n      attribute:\n        Count:\n          alias: hive.metastore.api.get_database.active_call\n          metric_type: gauge\n      bean: metrics:name=active_calls_api_get_database\n  - include:\n      attribute:\n        Count:\n          alias: hive.metastore.api.get_all_tables\n          metric_type: monotonic_count\n      bean: metrics:name=api_get_all_tables\n  - include:\n      attribute:\n        Count:\n          alias: hive.metastore.api.get_all_tables.active_call\n          metric_type: gauge\n      bean: metrics:name=active_calls_api_get_all_tables\n  - include:\n      attribute:\n        Count:\n          alias: hive.metastore.api.shutdown\n          metric_type: monotonic_count\n      bean: metrics:name=api_shutdown\n  - include:\n      attribute:\n        Count:\n          alias: hive.metastore.api.shutdown.active_call\n          metric_type: gauge\n      bean: metrics:name=active_calls_api_shutdown\n  - include:\n      attribute:\n        Count:\n          alias: hive.metastore.api.flushcache\n          metric_type: monotonic_count\n      bean: metrics:name=api_flushCache\n  - include:\n      attribute:\n        Count:\n          alias: hive.metastore.api.flushcache.active_call\n          metric_type: gauge\n      bean: metrics:name=active_calls_api_flushCache\n  - include:\n      attribute:\n        Count:\n          alias: hive.metastore.api.alter_table\n          metric_type: monotonic_count\n      bean: metrics:name=api_alter_table\n  - include:\n      attribute:\n        Count:\n          alias: hive.metastore.api.alter_table.active_call\n          metric_type: gauge\n      bean: metrics:name=active_calls_api_alter_table\n  - include:\n      attribute:\n        Count:\n          alias: hive.metastore.api.get_all_functions\n          metric_type: monotonic_count\n      bean: metrics:name=api_get_all_functions\n  - include:\n      attribute:\n        Count:\n          alias: hive.metastore.api.get_all_functions.active_call\n          metric_type: gauge\n      bean: metrics:name=active_calls_api_get_all_functions\n  - include:\n      attribute:\n        Count:\n          alias: hive.metastore.api.get_table_req\n          metric_type: monotonic_count\n      bean: metrics:name=api_get_table_req\n  - include:\n      attribute:\n        Count:\n          alias: hive.metastore.api.get_table_req.active_call\n          metric_type: gauge\n      bean: metrics:name=active_calls_api_get_table_req"
        },
        "/etc/datadog-agent/conf.d/hivemq.d/metrics.yaml": {
            "hash": "4ebac7f19026fa8bd305d9ba0b4ad8ea698e0d26964dfeabc560f4ea834377bb",
            "raw_config": "cel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\njmx_metrics:\n  - include:\n      attribute:\n        Value:\n          alias: hivemq.$1\n          metric_type: gauge\n      bean_regex:\n        - metrics:name=com\\.hivemq\\.(cache\\.payload-persistence\\.average-load-penalty|cache\\.payload-persistence\\.eviction-count|cache\\.payload-persistence\\.hit-count|cache\\.payload-persistence\\.hit-rate|cache\\.payload-persistence\\.load-count|cache\\.payload-persistence\\.load-exception-count|cache\\.payload-persistence\\.load-exception-rate|cache\\.payload-persistence\\.load-success-count|cache\\.payload-persistence\\.miss-count|cache\\.payload-persistence\\.miss-rate|cache\\.payload-persistence\\.request-count|cache\\.payload-persistence\\.total-load-time|cache\\.shared-subscription\\.average-load-penalty|cache\\.shared-subscription\\.eviction-count|cache\\.shared-subscription\\.hit-count|cache\\.shared-subscription\\.hit-rate|cache\\.shared-subscription\\.load-count|cache\\.shared-subscription\\.load-exception-count|cache\\.shared-subscription\\.load-exception-rate|cache\\.shared-subscription\\.load-success-count|cache\\.shared-subscription\\.miss-count|cache\\.shared-subscription\\.miss-rate|cache\\.shared-subscription\\.request-count|cache\\.shared-subscription\\.total-load-time|cpu-cores\\.licensed|cpu-cores\\.used|messages\\.pending\\.qos-0\\.count|messages\\.pending\\.total\\.count|messages\\.queued\\.count|messages\\.retained\\.current|messages\\.retained\\.pending\\.total\\.count|messages\\.retained\\.queued\\.count|networking\\.bytes\\.read\\.current|networking\\.bytes\\.read\\.total|networking\\.bytes\\.write\\.current|networking\\.bytes\\.write\\.total|networking\\.connections\\.current|overload-protection\\.clients\\.average-credits|overload-protection\\.clients\\.backpressure-active|overload-protection\\.clients\\.using-credits|overload-protection\\.credits\\.per-tick|overload-protection\\.level|persistence\\.executor\\.client-session\\.tasks|persistence\\.executor\\.noempty-queues|persistence\\.executor\\.outgoing-message-flow\\.tasks|persistence\\.executor\\.queued-messages\\.tasks|persistence\\.executor\\.request-event-bus\\.tasks|persistence\\.executor\\.retained-messages\\.tasks|persistence\\.executor\\.running\\.threads|persistence\\.executor\\.subscription\\.tasks|persistence\\.executor\\.total\\.tasks|persistence\\.payload-entries\\.count|persistence\\.removable-entries\\.count|qos-0-memory\\.exceeded\\.per-client|qos-0-memory\\.max|qos-0-memory\\.used|sessions\\.overall\\.current|system\\.max-file-descriptor|system\\.open-file-descriptor|system\\.os\\.file-descriptors\\.max|system\\.os\\.file-descriptors\\.open|system\\.os\\.global\\.memory\\.available|system\\.os\\.global\\.memory\\.swap\\.total|system\\.os\\.global\\.memory\\.swap\\.used|system\\.os\\.global\\.memory\\.total|system\\.os\\.global\\.uptime|system\\.os\\.process\\.disk\\.bytes-read|system\\.os\\.process\\.disk\\.bytes-written|system\\.os\\.process\\.memory\\.resident-set-size|system\\.os\\.process\\.memory\\.virtual|system\\.os\\.process\\.threads\\.count|system\\.os\\.process\\.time-spent\\.kernel|system\\.os\\.process\\.time-spent\\.user|system\\.physical-memory\\.free|system\\.physical-memory\\.total|system\\.process-cpu\\.load|system\\.process-cpu\\.time|system\\.swap-space\\.free|system\\.swap-space\\.total|system\\.system-cpu\\.load|topic-alias\\.count\\.total|topic-alias\\.memory\\.usage)\n      domain: metrics\n      exclude_tags:\n        - name\n  - include:\n      attribute:\n        Count:\n          alias: hivemq.$1\n          metric_type: monotonic_count\n      bean_regex:\n        - metrics:name=com\\.hivemq\\.(cluster\\.name-request\\.retry\\.count|extension\\.managed-executor\\.running|extension\\.managed-executor\\.scheduled\\.overrun|extension\\.services\\.publish-service-publishes|extension\\.services\\.publish-service-publishes-to-client|extension\\.services\\.rate-limit-exceeded\\.count|keep-alive\\.disconnect\\.count|messages\\.dropped\\.count|messages\\.dropped\\.internal-error\\.count|messages\\.dropped\\.message-too-large\\.count|messages\\.dropped\\.mqtt-packet-too-large\\.count|messages\\.dropped\\.not-writable\\.count|messages\\.dropped\\.publish-inbound-intercepted\\.count|messages\\.dropped\\.qos-0-memory-exceeded\\.count|messages\\.dropped\\.queue-full\\.count|messages\\.expired-messages|messages\\.incoming\\.auth\\.count|messages\\.incoming\\.connect\\.count|messages\\.incoming\\.connect\\.mqtt3\\.count|messages\\.incoming\\.connect\\.mqtt5\\.count|messages\\.incoming\\.disconnect\\.count|messages\\.incoming\\.pingreq\\.count|messages\\.incoming\\.puback\\.count|messages\\.incoming\\.pubcomp\\.count|messages\\.incoming\\.publish\\.count|messages\\.incoming\\.pubrec\\.count|messages\\.incoming\\.pubrel\\.count|messages\\.incoming\\.subscribe\\.count|messages\\.incoming\\.total\\.count|messages\\.incoming\\.unsubscribe\\.count|messages\\.outgoing\\.auth\\.count|messages\\.outgoing\\.connack\\.count|messages\\.outgoing\\.disconnect\\.count|messages\\.outgoing\\.pingresp\\.count|messages\\.outgoing\\.puback\\.count|messages\\.outgoing\\.pubcomp\\.count|messages\\.outgoing\\.publish\\.count|messages\\.outgoing\\.pubrec\\.count|messages\\.outgoing\\.pubrel\\.count|messages\\.outgoing\\.suback\\.count|messages\\.outgoing\\.total\\.count|messages\\.outgoing\\.unsuback\\.count|networking\\.connections-closed\\.graceful\\.count|networking\\.connections-closed\\.total\\.count|networking\\.connections-closed\\.ungraceful\\.count|payload-persistence\\.cleanup-executor\\.running|payload-persistence\\.cleanup-executor\\.scheduled\\.overrun|persistence-executor\\.running|persistence-scheduled-executor\\.running|persistence-scheduled-executor\\.scheduled\\.overrun|persistence\\.executor\\.queue-misses|publish\\.without-matching-subscribers|sessions\\.persistent\\.active|single-writer-executor\\.running|subscriptions\\.overall\\.current)\n      domain: metrics\n      exclude_tags:\n        - name\n  - include:\n      attribute:\n        50thPercentile:\n          alias: hivemq.$1.50th_percentile\n          metric_type: gauge\n        75thPercentile:\n          alias: hivemq.$1.75th_percentile\n          metric_type: gauge\n        95thPercentile:\n          alias: hivemq.$1.95th_percentile\n          metric_type: gauge\n        98thPercentile:\n          alias: hivemq.$1.98th_percentile\n          metric_type: gauge\n        99thPercentile:\n          alias: hivemq.$1.99th_percentile\n          metric_type: gauge\n        999thPercentile:\n          alias: hivemq.$1.999th_percentile\n          metric_type: gauge\n        Count:\n          alias: hivemq.$1.count\n          metric_type: monotonic_count\n        Max:\n          alias: hivemq.$1.max\n          metric_type: gauge\n        Mean:\n          alias: hivemq.$1.mean\n          metric_type: gauge\n        Min:\n          alias: hivemq.$1.min\n          metric_type: gauge\n        SnapshotSize:\n          alias: hivemq.$1.snapshot_size\n          metric_type: gauge\n        StdDev:\n          alias: hivemq.$1.std_dev\n          metric_type: gauge\n      bean_regex:\n        - metrics:name=com\\.hivemq\\.(extension\\.managed-executor\\.scheduled\\.percent-of-period|messages\\.incoming\\.publish\\.bytes|messages\\.incoming\\.total\\.bytes|messages\\.outgoing\\.publish\\.bytes|messages\\.outgoing\\.total\\.bytes|messages\\.retained\\.mean|networking\\.connections\\.mean|payload-persistence\\.cleanup-executor\\.scheduled\\.percent-of-period|persistence-scheduled-executor\\.scheduled\\.percent-of-period)\n      domain: metrics\n      exclude_tags:\n        - name"
        },
        "/etc/datadog-agent/conf.d/hudi.d/metrics.yaml": {
            "hash": "8c3ad990e78e5161aa36a6c9656b7f522185f47b0e30eeb5a43fad6b76e05a3b",
            "raw_config": "cel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\njmx_metrics:\n  - include:\n      attribute:\n        Value:\n          alias: hudi.action.create_time\n          metric_type: monotonic_count\n      bean_regex:\n        - metrics:name=(.*?)\\.(commit|deltacommit|replacecommit|compaction)\\.totalCreateTime,type=gauges\n      domain: metrics\n      exclude_tags:\n        - name\n      tags:\n        action: $2\n        table_name: $1\n  - include:\n      attribute:\n        Value:\n          alias: hudi.action.commit_time\n          metric_type: gauge\n      bean_regex:\n        - metrics:name=(.*?)\\.(commit|deltacommit|replacecommit|compaction)\\.commitTime,type=gauges\n      domain: metrics\n      exclude_tags:\n        - name\n      tags:\n        action: $2\n        table_name: $1\n  - include:\n      attribute:\n        Value:\n          alias: hudi.action.duration\n          metric_type: gauge\n      bean_regex:\n        - metrics:name=(.*?)\\.(commit|deltacommit|replacecommit|compaction)\\.duration,type=gauges\n      domain: metrics\n      exclude_tags:\n        - name\n      tags:\n        action: $2\n        table_name: $1\n  - include:\n      attribute:\n        Value:\n          alias: hudi.action.bytes_written\n          metric_type: monotonic_count\n      bean_regex:\n        - metrics:name=(.*?)\\.(commit|deltacommit|replacecommit|compaction)\\.totalBytesWritten,type=gauges\n      domain: metrics\n      exclude_tags:\n        - name\n      tags:\n        action: $2\n        table_name: $1\n  - include:\n      attribute:\n        Value:\n          alias: hudi.action.compacted_records_updated\n          metric_type: monotonic_count\n      bean_regex:\n        - metrics:name=(.*?)\\.(commit|deltacommit|replacecommit|compaction)\\.totalCompactedRecordsUpdated,type=gauges\n      domain: metrics\n      exclude_tags:\n        - name\n      tags:\n        action: $2\n        table_name: $1\n  - include:\n      attribute:\n        Value:\n          alias: hudi.action.create_time\n          metric_type: monotonic_count\n      bean_regex:\n        - metrics:name=(.*?)\\.(commit|deltacommit|replacecommit|compaction)\\.totalCreateTime,type=gauges\n      domain: metrics\n      exclude_tags:\n        - name\n      tags:\n        action: $2\n        table_name: $1\n  - include:\n      attribute:\n        Value:\n          alias: hudi.action.files_inserted\n          metric_type: monotonic_count\n      bean_regex:\n        - metrics:name=(.*?)\\.(commit|deltacommit|replacecommit|compaction)\\.totalFilesInsert,type=gauges\n      domain: metrics\n      exclude_tags:\n        - name\n      tags:\n        action: $2\n        table_name: $1\n  - include:\n      attribute:\n        Value:\n          alias: hudi.action.files_updated\n          metric_type: monotonic_count\n      bean_regex:\n        - metrics:name=(.*?)\\.(commit|deltacommit|replacecommit|compaction)\\.totalFilesUpdate,type=gauges\n      domain: metrics\n      exclude_tags:\n        - name\n      tags:\n        action: $2\n        table_name: $1\n  - include:\n      attribute:\n        Value:\n          alias: hudi.action.insert_records_written\n          metric_type: monotonic_count\n      bean_regex:\n        - metrics:name=(.*?)\\.(commit|deltacommit|replacecommit|compaction)\\.totalInsertRecordsWritten,type=gauges\n      domain: metrics\n      exclude_tags:\n        - name\n      tags:\n        action: $2\n        table_name: $1\n  - include:\n      attribute:\n        Value:\n          alias: hudi.action.log_files_compacted\n          metric_type: monotonic_count\n      bean_regex:\n        - metrics:name=(.*?)\\.(commit|deltacommit|replacecommit|compaction)\\.totalLogFilesCompacted,type=gauges\n      domain: metrics\n      exclude_tags:\n        - name\n      tags:\n        action: $2\n        table_name: $1\n  - include:\n      attribute:\n        Value:\n          alias: hudi.action.log_files_size\n          metric_type: monotonic_count\n      bean_regex:\n        - metrics:name=(.*?)\\.(commit|deltacommit|replacecommit|compaction)\\.totalLogFilesSize,type=gauges\n      domain: metrics\n      exclude_tags:\n        - name\n      tags:\n        action: $2\n        table_name: $1\n  - include:\n      attribute:\n        Value:\n          alias: hudi.action.partitions_written\n          metric_type: monotonic_count\n      bean_regex:\n        - metrics:name=(.*?)\\.(commit|deltacommit|replacecommit|compaction)\\.totalPartitionsWritten,type=gauges\n      domain: metrics\n      exclude_tags:\n        - name\n      tags:\n        action: $2\n        table_name: $1\n  - include:\n      attribute:\n        Value:\n          alias: hudi.action.records_written\n          metric_type: monotonic_count\n      bean_regex:\n        - metrics:name=(.*?)\\.(commit|deltacommit|replacecommit|compaction)\\.totalRecordsWritten,type=gauges\n      domain: metrics\n      exclude_tags:\n        - name\n      tags:\n        action: $2\n        table_name: $1\n  - include:\n      attribute:\n        Value:\n          alias: hudi.action.scan_time\n          metric_type: monotonic_count\n      bean_regex:\n        - metrics:name=(.*?)\\.(commit|deltacommit|replacecommit|compaction)\\.totalScanTime,type=gauges\n      domain: metrics\n      exclude_tags:\n        - name\n      tags:\n        action: $2\n        table_name: $1\n  - include:\n      attribute:\n        Value:\n          alias: hudi.action.update_records_written\n          metric_type: monotonic_count\n      bean_regex:\n        - metrics:name=(.*?)\\.(commit|deltacommit|replacecommit|compaction)\\.totalUpdateRecordsWritten,type=gauges\n      domain: metrics\n      exclude_tags:\n        - name\n      tags:\n        action: $2\n        table_name: $1\n  - include:\n      attribute:\n        Value:\n          alias: hudi.action.upsert_time\n          metric_type: monotonic_count\n      bean_regex:\n        - metrics:name=(.*?)\\.(commit|deltacommit|replacecommit|compaction)\\.totalUpsertTime,type=gauges\n      domain: metrics\n      exclude_tags:\n        - name\n      tags:\n        action: $2\n        table_name: $1\n  - include:\n      attribute:\n        Value:\n          alias: hudi.index.command.duration\n          metric_type: gauge\n      bean_regex:\n        - metrics:name=(.*?)\\.index\\.(.*?)\\.duration,type=gauges\n      domain: metrics\n      exclude_tags:\n        - name\n      tags:\n        command: $2\n        table_name: $1\n  - include:\n      attribute:\n        Value:\n          alias: hudi.$2.duration\n          metric_type: gauge\n      bean_regex:\n        - metrics:name=(.*?)\\.(clean|finalize|rollback)\\.duration,type=gauges\n      domain: metrics\n      exclude_tags:\n        - name\n      tags:\n        action: $2\n        table_name: $1\n  - include:\n      attribute:\n        Value:\n          alias: hudi.action.files_deleted\n          metric_type: gauge\n      bean_regex:\n        - metrics:name=(.*?)\\.(clean|rollback)\\.numFilesDeleted,type=gauges\n      domain: metrics\n      exclude_tags:\n        - name\n      tags:\n        table_name: $1\n  - include:\n      attribute:\n        Value:\n          alias: hudi.finalize.files_finalized\n          metric_type: gauge\n      bean_regex:\n        - metrics:name=(.*?)\\.finalize\\.numFilesFinalized,type=gauges\n      domain: metrics\n      exclude_tags:\n        - name\n      tags:\n        table_name: $1\n  - include:\n      attribute:\n        50thPercentile:\n          alias: hudi.action.time.50th_percentile\n          metric_type: gauge\n        75thPercentile:\n          alias: hudi.action.time.75th_percentile\n          metric_type: gauge\n        95thPercentile:\n          alias: hudi.action.time.95th_percentile\n          metric_type: gauge\n        98thPercentile:\n          alias: hudi.action.time.98th_percentile\n          metric_type: gauge\n        99thPercentile:\n          alias: hudi.action.time.99th_percentile\n          metric_type: gauge\n        999thPercentile:\n          alias: hudi.action.time.999th_percentile\n          metric_type: gauge\n        Count:\n          alias: hudi.action.time.count\n          metric_type: monotonic_count\n        Max:\n          alias: hudi.action.time.max\n          metric_type: gauge\n        Mean:\n          alias: hudi.action.time.mean\n          metric_type: gauge\n        Min:\n          alias: hudi.action.time.min\n          metric_type: gauge\n        StdDev:\n          alias: hudi.action.time.std_dev\n          metric_type: gauge\n      bean_regex:\n        - metrics:name=(.*?)\\.timer\\.(.*?),type=timers\n      domain: metrics\n      exclude_tags:\n        - name\n      tags:\n        action: $2\n        table_name: $1"
        },
        "/etc/datadog-agent/conf.d/ignite.d/metrics.yaml": {
            "hash": "47cd7014de772838fffafce22c0435ad29397629000b2a039f38741cd1860ebd",
            "raw_config": "cel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\njmx_metrics:\n  - include:\n      attribute:\n        ActiveCount:\n          alias: ignite.threads.active\n          metric_type: gauge\n        CompletedTaskCount:\n          alias: ignite.threads.completed_tasks\n          metric_type: monotonic_count\n        CorePoolSize:\n          alias: ignite.threads.core_pool_size\n          metric_type: gauge\n        LargestPoolSize:\n          alias: ignite.threads.largest_size\n          metric_type: gauge\n        MaximumPoolSize:\n          alias: ignite.threads.maximum_pool_size\n          metric_type: gauge\n        PoolSize:\n          alias: ignite.threads.pool_size\n          metric_type: gauge\n        QueueSize:\n          alias: ignite.threads.queue_size\n          metric_type: gauge\n        TaskCount:\n          alias: ignite.threads.tasks\n          metric_type: monotonic_count\n      bean_regex:\n        - org\\.apache:clsLdr=(.*),group=\"Thread Pools\",name=(.*)\n      domain: org.apache\n      exclude_tags:\n        - name\n        - clsLdr\n        - group\n      tags:\n        executor: $2\n  - include:\n      attribute:\n        AllocationRate:\n          alias: ignite.allocation_rate\n          metric_type: gauge\n        CheckpointBufferSize:\n          alias: ignite.check_point_buffer_size\n          metric_type: gauge\n        DirtyPages:\n          alias: ignite.dirty_pages\n          metric_type: gauge\n        EvictionRate:\n          alias: ignite.eviction_rate\n          metric_type: gauge\n        InitialSize:\n          alias: ignite.initial_memory_size\n          metric_type: gauge\n        LargeEntriesPagesPercentage:\n          alias: ignite.large_entries_pages_percentage\n          metric_type: gauge\n        MaxSize:\n          alias: ignite.max_memory_size\n          metric_type: gauge\n        OffHeapSize:\n          alias: ignite.offheap_size\n          metric_type: gauge\n        OffheapUsedSize:\n          alias: ignite.offheap_used_size\n          metric_type: gauge\n        PagesFillFactor:\n          alias: ignite.pages_fill_factor\n          metric_type: gauge\n        PagesRead:\n          alias: ignite.pages_read\n          metric_type: monotonic_count\n        PagesReplaceAge:\n          alias: ignite.pages_replace_age\n          metric_type: gauge\n        PagesReplaceRate:\n          alias: ignite.pages_replace_rate\n          metric_type: gauge\n        PagesReplaced:\n          alias: ignite.pages_replaced\n          metric_type: monotonic_count\n        PagesWritten:\n          alias: ignite.pages_written\n          metric_type: monotonic_count\n        PhysicalMemoryPages:\n          alias: ignite.physical_memory_pages\n          metric_type: gauge\n        TotalAllocatedPages:\n          alias: ignite.total_allocated_pages\n          metric_type: gauge\n        TotalAllocatedSize:\n          alias: ignite.total_allocated_size\n          metric_type: gauge\n        UsedCheckpointBufferPages:\n          alias: ignite.used_checkpoint_buffer_pages\n          metric_type: gauge\n        UsedCheckpointBufferSize:\n          alias: ignite.used_checkpoint_buffer_size\n          metric_type: gauge\n      bean_regex:\n        - org\\.apache:clsLdr=(.*),group=DataRegionMetrics,name=(.*)\n      domain: org.apache\n      exclude_tags:\n        - name\n        - clsLdr\n        - group\n      tags:\n        region: $2\n  - include:\n      attribute:\n        ActiveBaselineNodes:\n          alias: ignite.active_baseline_nodes\n          metric_type: gauge\n        AverageActiveJobs:\n          alias: ignite.jobs.active.average\n          metric_type: gauge\n        AverageCancelledJobs:\n          alias: ignite.jobs.cancelled.average\n          metric_type: gauge\n        AverageCpuLoad:\n          alias: ignite.average_cpu_load\n          metric_type: gauge\n        AverageJobExecuteTime:\n          alias: ignite.jobs.execute_time.average\n          metric_type: gauge\n        AverageJobWaitTime:\n          alias: ignite.jobs.wait_time.average\n          metric_type: gauge\n        AverageRejectedJobs:\n          alias: ignite.jobs.rejected.average\n          metric_type: gauge\n        AverageWaitingJobs:\n          alias: ignite.jobs.waiting.average\n          metric_type: gauge\n        BusyTimePercentage:\n          alias: ignite.busy_time_percentage\n          metric_type: gauge\n        CurrentActiveJobs:\n          alias: ignite.jobs.active.current\n          metric_type: gauge\n        CurrentCancelledJobs:\n          alias: ignite.jobs.cancelled.current\n          metric_type: gauge\n        CurrentCpuLoad:\n          alias: ignite.current_cpu_load\n          metric_type: gauge\n        CurrentDaemonThreadCount:\n          alias: ignite.current_daemon_thread_count\n          metric_type: gauge\n        CurrentGcCpuLoad:\n          alias: ignite.current_gc_load\n          metric_type: gauge\n        CurrentIdleTime:\n          alias: ignite.current_idle_time\n          metric_type: gauge\n        CurrentJobExecuteTime:\n          alias: ignite.jobs.execute_time.current\n          metric_type: gauge\n        CurrentJobWaitTime:\n          alias: ignite.jobs.wait_time.current\n          metric_type: gauge\n        CurrentRejectedJobs:\n          alias: ignite.jobs.rejected.current\n          metric_type: gauge\n        CurrentThreadCount:\n          alias: ignite.current_thread_count\n          metric_type: gauge\n        CurrentWaitingJobs:\n          alias: ignite.jobs.waiting.current\n          metric_type: gauge\n        HeapMemoryCommitted:\n          alias: ignite.heap_memory_committed\n          metric_type: gauge\n        HeapMemoryInitialized:\n          alias: ignite.heap_memory_initialized\n          metric_type: gauge\n        HeapMemoryMaximum:\n          alias: ignite.heap_memory_maximum\n          metric_type: gauge\n        HeapMemoryTotal:\n          alias: ignite.heap_memory_total\n          metric_type: gauge\n        HeapMemoryUsed:\n          alias: ignite.heap_memory_used\n          metric_type: gauge\n        IdleTimePercentage:\n          alias: ignite.idle_time_percentage\n          metric_type: gauge\n        MaximumActiveJobs:\n          alias: ignite.jobs.active.maximum\n          metric_type: gauge\n        MaximumCancelledJobs:\n          alias: ignite.jobs.cancelled.maximum\n          metric_type: gauge\n        MaximumJobExecuteTime:\n          alias: ignite.jobs.execute_time.maximum\n          metric_type: gauge\n        MaximumJobWaitTime:\n          alias: ignite.jobs.wait_time.maximum\n          metric_type: gauge\n        MaximumRejectedJobs:\n          alias: ignite.jobs.rejected.maximum\n          metric_type: gauge\n        MaximumThreadCount:\n          alias: ignite.maximum_thread_count\n          metric_type: gauge\n        MaximumWaitingJobs:\n          alias: ignite.jobs.waiting.maximum\n          metric_type: gauge\n        NonHeapMemoryCommitted:\n          alias: ignite.non_heap_memory_committed\n          metric_type: gauge\n        NonHeapMemoryInitialized:\n          alias: ignite.non_heap_memory_initialized\n          metric_type: gauge\n        NonHeapMemoryMaximum:\n          alias: ignite.non_heap_memory_maximum\n          metric_type: gauge\n        NonHeapMemoryTotal:\n          alias: ignite.non_heap_memory_total\n          metric_type: gauge\n        NonHeapMemoryUsed:\n          alias: ignite.non_heap_memory_used\n          metric_type: gauge\n        OutboundMessagesQueueSize:\n          alias: ignite.oubound_messages_queue_size\n          metric_type: gauge\n        ReceivedBytesCount:\n          alias: ignite.received_bytes\n          metric_type: monotonic_count\n        ReceivedMessagesCount:\n          alias: ignite.received_messages\n          metric_type: monotonic_count\n        SentBytesCount:\n          alias: ignite.sent_bytes\n          metric_type: monotonic_count\n        SentMessagesCount:\n          alias: ignite.sent_messages\n          metric_type: monotonic_count\n        TotalBaselineNodes:\n          alias: ignite.total_baseline_nodes\n          metric_type: gauge\n        TotalBusyTime:\n          alias: ignite.total_busy_time\n          metric_type: gauge\n        TotalCancelledJobs:\n          alias: ignite.jobs.cancelled.total\n          metric_type: monotonic_count\n        TotalClientNodes:\n          alias: ignite.total_client_nodes\n          metric_type: gauge\n        TotalCpus:\n          alias: ignite.total_cpus\n          metric_type: gauge\n        TotalExecutedJobs:\n          alias: ignite.jobs.executed.total\n          metric_type: monotonic_count\n        TotalExecutedTasks:\n          alias: ignite.total_executed_tasks\n          metric_type: monotonic_count\n        TotalIdleTime:\n          alias: ignite.total_idle_time\n          metric_type: gauge\n        TotalJobsExecutionTime:\n          alias: ignite.jobs.execution_time.total\n          metric_type: monotonic_count\n        TotalNodes:\n          alias: ignite.total_nodes\n          metric_type: gauge\n        TotalRejectedJobs:\n          alias: ignite.jobs.rejected.total\n          metric_type: monotonic_count\n        TotalServerNodes:\n          alias: ignite.total_server_nodes\n          metric_type: gauge\n        TotalStartedThreadCount:\n          alias: ignite.total_started_threads\n          metric_type: monotonic_count\n      bean_regex:\n        - org\\.apache:clsLdr=(.*),group=Kernal,name=ClusterMetricsMXBeanImpl\n      domain: org.apache\n      exclude_tags:\n        - name\n        - clsLdr\n        - group\n  - include:\n      attribute:\n        MaximumFailoverAttempts:\n          alias: ignite.jobs.maximum_failover\n          metric_type: gauge\n        TotalFailoverJobsCount:\n          alias: ignite.jobs.total_failover\n          metric_type: monotonic_count\n      bean_regex:\n        - org\\.apache:clsLdr=(.*),group=SPIs,name=AlwaysFailoverSpi\n      domain: org.apache\n      exclude_tags:\n        - name\n        - clsLdr\n        - group\n  - include:\n      attribute:\n        AvgMessageProcessingTime:\n          alias: ignite.discovery.average_message_processing_time\n          metric_type: gauge\n        MaxMessageProcessingTime:\n          alias: ignite.discovery.max_message_processing_time\n          metric_type: gauge\n        MessageWorkerQueueSize:\n          alias: ignite.discovery.message_worker_queue_size\n          metric_type: gauge\n        NodesFailed:\n          alias: ignite.discovery.nodes_failed\n          metric_type: monotonic_count\n        NodesJoined:\n          alias: ignite.discovery.nodes_joined\n          metric_type: monotonic_count\n        NodesLeft:\n          alias: ignite.discovery.nodes_left\n          metric_type: monotonic_count\n        PendingMessagesDiscarded:\n          alias: ignite.discovery.pending_messages_discarded\n          metric_type: gauge\n        PendingMessagesRegistered:\n          alias: ignite.discovery.pending_messages_registered\n          metric_type: gauge\n        TotalProcessedMessages:\n          alias: ignite.discovery.total_processed_messages\n          metric_type: monotonic_count\n        TotalReceivedMessages:\n          alias: ignite.discovery.total_received_messages\n          metric_type: monotonic_count\n      bean_regex:\n        - org\\.apache:clsLdr=(.*),group=SPIs,name=TcpDiscoverySpi\n      domain: org.apache\n      exclude_tags:\n        - name\n        - clsLdr\n        - group\n  - include:\n      attribute:\n        LockedKeysNumber:\n          alias: ignite.transaction.locked_keys\n          metric_type: gauge\n        OwnerTransactionsNumber:\n          alias: ignite.transaction.owner\n          metric_type: gauge\n        TransactionsCommittedNumber:\n          alias: ignite.transaction.committed\n          metric_type: monotonic_count\n        TransactionsHoldingLockNumber:\n          alias: ignite.transaction.holding_lock\n          metric_type: gauge\n        TransactionsRolledBackNumber:\n          alias: ignite.transaction.rolledback\n          metric_type: monotonic_count\n      bean_regex:\n        - org\\.apache:clsLdr=(.*),group=TransactionMetrics,name=TransactionMetricsMxBeanImpl\n      domain: org.apache\n      exclude_tags:\n        - name\n        - clsLdr\n        - group\n  - include:\n      attribute:\n        CheckpointTotalTime:\n          alias: ignite.checkpoint.total_time\n          metric_type: gauge\n        LastCheckpointCopiedOnWritePagesNumber:\n          alias: ignite.checkpoint.last_copied_on_write_pages\n          metric_type: gauge\n        LastCheckpointDataPagesNumber:\n          alias: ignite.checkpoint.last_data_pages\n          metric_type: gauge\n        LastCheckpointDuration:\n          alias: ignite.checkpoint.last_duration\n          metric_type: gauge\n        LastCheckpointFsyncDuration:\n          alias: ignite.checkpoint.last_fsync_duration\n          metric_type: gauge\n        LastCheckpointLockWaitDuration:\n          alias: ignite.checkpoint.last_lock_wait_duration\n          metric_type: gauge\n        LastCheckpointMarkDuration:\n          alias: ignite.checkpoint.last_mark_duration\n          metric_type: gauge\n        LastCheckpointPagesWriteDuration:\n          alias: ignite.checkpoint.last_pages_write_duration\n          metric_type: gauge\n        LastCheckpointTotalPagesNumber:\n          alias: ignite.checkpoint.last_total_pages\n          metric_type: gauge\n        WalArchiveSegments:\n          alias: ignite.wal.archive_segments\n          metric_type: gauge\n        WalBuffPollSpinsRate:\n          alias: ignite.wal.buffer_poll_spin\n          metric_type: gauge\n        WalFsyncTimeAverage:\n          alias: ignite.wal.fsync_average\n          metric_type: gauge\n        WalLastRollOverTime:\n          alias: ignite.wal.last_rollover\n          metric_type: gauge\n        WalLoggingRate:\n          alias: ignite.wal.logging_rate\n          metric_type: gauge\n        WalTotalSize:\n          alias: ignite.wal.total_size\n          metric_type: gauge\n        WalWritingRate:\n          alias: ignite.wal.writing_rate\n          metric_type: gauge\n      bean_regex:\n        - org\\.apache:clsLdr=(.*),group=\"Persistent Store\",name=DataStorageMetrics\n      domain: org.apache\n      exclude_tags:\n        - name\n        - clsLdr\n        - group\n  - include:\n      attribute:\n        Backups:\n          alias: ignite.cache.backups\n          metric_type: gauge\n        ClusterMovingPartitionsCount:\n          alias: ignite.cache.cluster_moving_partitions\n          metric_type: gauge\n        ClusterOwningPartitionsCount:\n          alias: ignite.cache.cluster_owning_partitions\n          metric_type: gauge\n        LocalNodeMovingPartitionsCount:\n          alias: ignite.cache.local_moving_partitions\n          metric_type: gauge\n        LocalNodeOwningPartitionsCount:\n          alias: ignite.cache.local_owning_partitions\n          metric_type: gauge\n        LocalNodeRentingEntriesCount:\n          alias: ignite.cache.local_renting_entries\n          metric_type: gauge\n        LocalNodeRentingPartitionsCount:\n          alias: ignite.cache.local_renting_partitions\n          metric_type: gauge\n        MaximumNumberOfPartitionCopies:\n          alias: ignite.cache.maximum_partition_copies\n          metric_type: gauge\n        MinimumNumberOfPartitionCopies:\n          alias: ignite.cache.minimum_partition_copies\n          metric_type: gauge\n        Partitions:\n          alias: ignite.cache.partitions\n          metric_type: gauge\n      bean_regex:\n        - org\\.apache:clsLdr=(.*),group=\"Cache groups\",name=(.*)\n      domain: org.apache\n      exclude_tags:\n        - name\n        - clsLdr\n        - group\n      tags:\n        cache: $2\n  - include:\n      attribute:\n        AverageGetTime:\n          alias: ignite.cache.average_get_time\n          metric_type: gauge\n        AveragePutTime:\n          alias: ignite.cache.average_put_time\n          metric_type: gauge\n        AverageRemoveTime:\n          alias: ignite.cache.average_remove_time\n          metric_type: gauge\n        AverageTxCommitTime:\n          alias: ignite.cache.average_commit_time\n          metric_type: gauge\n        AverageTxRollbackTime:\n          alias: ignite.cache.average_rollback_time\n          metric_type: gauge\n        CacheEvictions:\n          alias: ignite.cache.evictions\n          metric_type: monotonic_count\n        CacheGets:\n          alias: ignite.cache.gets\n          metric_type: monotonic_count\n        CacheHitPercentage:\n          alias: ignite.cache.hit_percentage\n          metric_type: gauge\n        CacheHits:\n          alias: ignite.cache.hits\n          metric_type: monotonic_count\n        CacheMissPercentage:\n          alias: ignite.cache.miss_percentage\n          metric_type: gauge\n        CacheMisses:\n          alias: ignite.cache.misses\n          metric_type: monotonic_count\n        CachePuts:\n          alias: ignite.cache.puts\n          metric_type: monotonic_count\n        CacheRemovals:\n          alias: ignite.cache.removals\n          metric_type: monotonic_count\n        CacheSize:\n          alias: ignite.cache.size\n          metric_type: gauge\n        CacheTxCommits:\n          alias: ignite.cache.commits\n          metric_type: monotonic_count\n        CacheTxRollbacks:\n          alias: ignite.cache.rollbacks\n          metric_type: monotonic_count\n        DhtEvictQueueCurrentSize:\n          alias: ignite.cache.evict_queue_size\n          metric_type: gauge\n        EntryProcessorAverageInvocationTime:\n          alias: ignite.cache.entry_processor.average_invocation_time\n          metric_type: gauge\n        EntryProcessorHitPercentage:\n          alias: ignite.cache.entry_processor.hit_percentage\n          metric_type: gauge\n        EntryProcessorHits:\n          alias: ignite.cache.entry_processor.hits\n          metric_type: monotonic_count\n        EntryProcessorInvocations:\n          alias: ignite.cache.entry_processor.invocations\n          metric_type: monotonic_count\n        EntryProcessorMaxInvocationTime:\n          alias: ignite.cache.entry_processor.maximum_invocation_time\n          metric_type: gauge\n        EntryProcessorMinInvocationTime:\n          alias: ignite.cache.entry_processor.minimum_invocation_time\n          metric_type: gauge\n        EntryProcessorMissPercentage:\n          alias: ignite.cache.entry_processor.miss_percentage\n          metric_type: gauge\n        EntryProcessorMisses:\n          alias: ignite.cache.entry_processor.misses\n          metric_type: monotonic_count\n        EntryProcessorPuts:\n          alias: ignite.cache.entry_processor.puts\n          metric_type: monotonic_count\n        EntryProcessorReadOnlyInvocations:\n          alias: ignite.cache.entry_processor.read_only_invocations\n          metric_type: monotonic_count\n        EntryProcessorRemovals:\n          alias: ignite.cache.entry_processor.removals\n          metric_type: monotonic_count\n        EstimatedRebalancingKeys:\n          alias: ignite.cache.estimated_rebalancing_keys\n          metric_type: gauge\n        HeapEntriesCount:\n          alias: ignite.cache.heap_entries\n          metric_type: gauge\n        KeysToRebalanceLeft:\n          alias: ignite.cache.keys_to_rebalance\n          metric_type: gauge\n        OffHeapAllocatedSize:\n          alias: ignite.cache.offheap_allocated_size\n          metric_type: gauge\n        OffHeapBackupEntriesCount:\n          alias: ignite.cache.offheap_backup_entries\n          metric_type: gauge\n        OffHeapEntriesCount:\n          alias: ignite.cache.offheap_entries\n          metric_type: gauge\n        OffHeapEvictions:\n          alias: ignite.cache.offheap_evictions\n          metric_type: monotonic_count\n        OffHeapGets:\n          alias: ignite.cache.offheap_gets\n          metric_type: monotonic_count\n        OffHeapHitPercentage:\n          alias: ignite.cache.offheap_hit_percentage\n          metric_type: gauge\n        OffHeapHits:\n          alias: ignite.cache.offheap_hits\n          metric_type: monotonic_count\n        OffHeapMissPercentage:\n          alias: ignite.cache.offheap_miss_percentage\n          metric_type: gauge\n        OffHeapMisses:\n          alias: ignite.cache.offheap_misses\n          metric_type: monotonic_count\n        OffHeapPrimaryEntriesCount:\n          alias: ignite.cache.offheap_primary_entries\n          metric_type: gauge\n        OffHeapPuts:\n          alias: ignite.cache.offheap_puts\n          metric_type: monotonic_count\n        OffHeapRemovals:\n          alias: ignite.cache.offheap_removals\n          metric_type: monotonic_count\n        RebalanceClearingPartitionsLeft:\n          alias: ignite.cache.rebalance_clearing_partitions\n          metric_type: gauge\n        RebalancedKeys:\n          alias: ignite.cache.rebalanced_keys\n          metric_type: gauge\n        RebalancingBytesRate:\n          alias: ignite.cache.rebalancing_bytes_rate\n          metric_type: gauge\n        RebalancingKeysRate:\n          alias: ignite.cache.rebalancing_keys_rate\n          metric_type: gauge\n        RebalancingPartitionsCount:\n          alias: ignite.cache.rebalancing_partitions\n          metric_type: gauge\n        TotalPartitionsCount:\n          alias: ignite.cache.total_partitions\n          metric_type: gauge\n        TxCommitQueueSize:\n          alias: ignite.cache.commit_queue_size\n          metric_type: gauge\n        TxCommittedVersionsSize:\n          alias: ignite.cache.committed_versions_size\n          metric_type: gauge\n        TxDhtCommitQueueSize:\n          alias: ignite.cache.dht_commit_queue_size\n          metric_type: gauge\n        TxDhtCommittedVersionsSize:\n          alias: ignite.cache.dht_committed_versions_size\n          metric_type: gauge\n        TxDhtPrepareQueueSize:\n          alias: ignite.cache.dht_prepare_queue_size\n          metric_type: gauge\n        TxDhtRolledbackVersionsSize:\n          alias: ignite.cache.dht_rolledback_versions_size\n          metric_type: gauge\n        TxDhtStartVersionCountsSize:\n          alias: ignite.cache.dht_start_version_counts_size\n          metric_type: gauge\n        TxDhtThreadMapSize:\n          alias: ignite.cache.dht_thread_map_size\n          metric_type: gauge\n        TxDhtXidMapSize:\n          alias: ignite.cache.dht_xid_map_size\n          metric_type: gauge\n        TxPrepareQueueSize:\n          alias: ignite.cache.prepare_queue_size\n          metric_type: gauge\n        TxRolledbackVersionsSize:\n          alias: ignite.cache.rolledback_versions_size\n          metric_type: gauge\n        TxStartVersionCountsSize:\n          alias: ignite.cache.start_version_counts_size\n          metric_type: gauge\n        TxThreadMapSize:\n          alias: ignite.cache.thread_map_size\n          metric_type: gauge\n        TxXidMapSize:\n          alias: ignite.cache.xid_map_size\n          metric_type: gauge\n        WriteBehindBufferSize:\n          alias: ignite.cache.write_behind_buffer_size\n          metric_type: gauge\n        WriteBehindCriticalOverflowCount:\n          alias: ignite.cache.write_behind_overflow\n          metric_type: gauge\n        WriteBehindErrorRetryCount:\n          alias: ignite.cache.write_behind_retries\n          metric_type: gauge\n        WriteBehindStoreBatchSize:\n          alias: ignite.cache.write_behind_store_batch_size\n          metric_type: gauge\n        WriteBehindTotalCriticalOverflowCount:\n          alias: ignite.cache.write_behind_overflow_total\n          metric_type: monotonic_count\n      bean_regex:\n        - org\\.apache:clsLdr=(.*),group=default,name=\"org.apache.ignite.internal.processors.cache.CacheClusterMetricsMXBeanImpl\"\n      domain: org.apache\n      exclude_tags:\n        - name\n        - clsLdr\n        - group"
        },
        "/etc/datadog-agent/conf.d/io.d/conf.yaml.default": {
            "hash": "943384e901b9f8abe4ad1c2405d3bc6f36204a7a2d8f7e5d79c10632607fac69",
            "raw_config": "cel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\ninstances:\n  - {}"
        },
        "/etc/datadog-agent/conf.d/istio.d/auto_conf.yaml": {
            "hash": "56a270bbb27d4008cbf3a2df666139253050163d240a609137fc9281c2a10852",
            "raw_config": "ad_identifiers:\n  - proxyv2\n  - proxyv2-rhel8\ncel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\ninstances:\n  - istio_mesh_endpoint: http://%%host%%:15020/stats/prometheus\n    send_histograms_buckets: true\n    tag_by_endpoint: false"
        },
        "/etc/datadog-agent/conf.d/jboss_wildfly.d/metrics.yaml": {
            "hash": "ee21862af44e45c4b321af2ab1389e84e938c0d23ebc38854b041618761cdbba",
            "raw_config": "cel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\njmx_metrics:\n  - include:\n      attribute:\n        ActiveCount:\n          alias: jboss.jdbc_connections.count\n          metric_type: gauge\n        IdleCount:\n          alias: jboss.jdbc_connections.idle\n          metric_type: gauge\n        InUseCount:\n          alias: jboss.jdbc_connections.active\n          metric_type: gauge\n        PreparedStatementCacheCurrentSize:\n          alias: jboss.jdbc_preparedstatementcache.size\n          metric_type: gauge\n        PreparedStatementCacheHitCount:\n          alias: jboss.jdbc_preparedstatementcache.hit\n          metric_type: monotonic_count\n        PreparedStatementCacheMissCount:\n          alias: jboss.jdbc_preparedstatementcache.miss\n          metric_type: monotonic_count\n        WaitCount:\n          alias: jboss.jdbc_connections.request_wait\n          metric_type: monotonic_count\n        XACommitCount:\n          alias: jboss.jdbc_xacommit.count\n          metric_type: monotonic_count\n        XARecoverCount:\n          alias: jboss.jdbc_xarecover.count\n          metric_type: monotonic_count\n        XARollbackCount:\n          alias: jboss.jdbc_xarollback.count\n          metric_type: monotonic_count\n      bean_regex:\n        - jboss\\.as:subsystem=datasources,(?:xa-)*data-source=(.*),statistics=(.*)\n      domain: jboss.as\n      tags:\n        datasource: $1\n        statistics: $2\n  - include:\n      attribute:\n        numberOfAbortedTransactions:\n          alias: jboss.transactions.aborted\n          metric_type: monotonic_count\n        numberOfApplicationRollbacks:\n          alias: jboss.transactions.application_rollbacks\n          metric_type: monotonic_count\n        numberOfCommittedTransactions:\n          alias: jboss.transactions.committed\n          metric_type: monotonic_count\n        numberOfHeuristics:\n          alias: jboss.transactions.heuristics\n          metric_type: monotonic_count\n        numberOfInflightTransactions:\n          alias: jboss.transactions.inflight\n          metric_type: gauge\n        numberOfNestedTransactions:\n          alias: jboss.transactions.nested\n          metric_type: monotonic_count\n        numberOfResourceRollbacks:\n          alias: jboss.transactions.resource_rollbacks\n          metric_type: monotonic_count\n        numberOfSystemRollbacks:\n          alias: jboss.transactions.system_rollbacks\n          metric_type: monotonic_count\n        numberOfTimedOutTransactions:\n          alias: jboss.transactions.timed_out\n          metric_type: monotonic_count\n        numberOfTransactions:\n          alias: jboss.transactions.count\n          metric_type: monotonic_count\n      bean:\n        - jboss.as:subsystem=transactions\n  - include:\n      attribute:\n        bytesReceived:\n          alias: jboss.undertow_listener.bytes_received\n          metric_type: monotonic_count\n        bytesSent:\n          alias: jboss.undertow_listener.bytes_sent\n          metric_type: monotonic_count\n        errorCount:\n          alias: jboss.undertow_listener.error_count\n          metric_type: monotonic_count\n        processingTime:\n          alias: jboss.undertow_listener.processing_time\n          metric_type: gauge\n        requestCount:\n          alias: jboss.undertow_listener.request_count\n          metric_type: monotonic_count\n      bean_regex:\n        - jboss\\.as:subsystem=undertow,server=.*,http-listener=.*\n      domain: jboss.as\n  - include:\n      attribute:\n        activeSessions:\n          alias: jboss.undertow_session.active\n          metric_type: gauge\n        expiredSessions:\n          alias: jboss.undertow_session.expired\n          metric_type: monotonic_count\n        rejectedSessions:\n          alias: jboss.undertow_session.rejected\n          metric_type: monotonic_count\n        sessionAvgAliveTime:\n          alias: jboss.undertow_session.alivetime_avg\n          metric_type: gauge\n        sessionMaxAliveTime:\n          alias: jboss.undertow_session.alivetime_max\n          metric_type: gauge\n        sessionsCreated:\n          alias: jboss.undertow_session.created\n          metric_type: monotonic_count\n      bean_regex:\n        - jboss\\.as\\.expr:deployment=(.*),subsystem=undertow\n      domain: jboss.as\n      tags:\n        deployment: $1"
        },
        "/etc/datadog-agent/conf.d/kafka.d/metrics.yaml": {
            "hash": "a46cd40beaabb4359d634dfc9e97c4432131efee7af7500bc24173d5b3febda4",
            "raw_config": "cel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\njmx_metrics:\n  - include:\n      attribute:\n        Count:\n          alias: kafka.producer.request_rate\n          metric_type: rate\n      bean_regex: kafka\\.producer:type=ProducerRequestMetrics,name=ProducerRequestRateAndTimeMs,clientId=.*\n      domain: kafka.producer\n  - include:\n      attribute:\n        Mean:\n          alias: kafka.producer.request_latency_avg\n          metric_type: gauge\n      bean_regex: kafka\\.producer:type=ProducerRequestMetrics,name=ProducerRequestRateAndTimeMs,clientId=.*\n      domain: kafka.producer\n  - include:\n      attribute:\n        Count:\n          alias: kafka.producer.bytes_out\n          metric_type: rate\n      bean_regex: kafka\\.producer:type=ProducerTopicMetrics,name=BytesPerSec,clientId=.*\n      domain: kafka.producer\n  - include:\n      attribute:\n        Count:\n          alias: kafka.producer.message_rate\n          metric_type: rate\n      bean_regex: kafka\\.producer:type=ProducerTopicMetrics,name=MessagesPerSec,clientId=.*\n      domain: kafka.producer\n  - include:\n      attribute:\n        response-rate:\n          alias: kafka.producer.response_rate\n          metric_type: gauge\n      bean_regex: kafka\\.producer:type=producer-metrics,client-id=.*\n      domain: kafka.producer\n  - include:\n      attribute:\n        request-rate:\n          alias: kafka.producer.request_rate\n          metric_type: gauge\n      bean_regex: kafka\\.producer:type=producer-metrics,client-id=.*\n      domain: kafka.producer\n  - include:\n      attribute:\n        request-latency-avg:\n          alias: kafka.producer.request_latency_avg\n          metric_type: gauge\n      bean_regex: kafka\\.producer:type=producer-metrics,client-id=.*\n      domain: kafka.producer\n  - include:\n      attribute:\n        outgoing-byte-rate:\n          alias: kafka.producer.bytes_out\n          metric_type: gauge\n      bean_regex: kafka\\.producer:type=producer-metrics,client-id=.*\n      domain: kafka.producer\n  - include:\n      attribute:\n        io-wait-time-ns-avg:\n          alias: kafka.producer.io_wait\n          metric_type: gauge\n      bean_regex: kafka\\.producer:type=producer-metrics,client-id=.*\n      domain: kafka.producer\n  - include:\n      attribute:\n        batch-size-avg:\n          alias: kafka.producer.batch_size_avg\n          metric_type: gauge\n        batch-size-max:\n          alias: kafka.producer.batch_size_max\n          metric_type: gauge\n        buffer-available-bytes:\n          alias: kafka.producer.available_buffer_bytes\n          metric_type: gauge\n        buffer-total-bytes:\n          alias: kafka.producer.buffer_bytes_total\n          metric_type: gauge\n        bufferpool-wait-ratio:\n          alias: kafka.producer.bufferpool_wait_ratio\n          metric_type: gauge\n        bufferpool-wait-time:\n          alias: kafka.producer.bufferpool_wait_time\n          metric_type: gauge\n        bufferpool-wait-time-ns-total:\n          alias: kafka.producer.bufferpool_wait_time_ns_total\n          metric_type: gauge\n        compression-rate-avg:\n          alias: kafka.producer.compression_rate_avg\n          metric_type: gauge\n        metadata-age:\n          alias: kafka.producer.metadata_age\n          metric_type: gauge\n        produce-throttle-time-avg:\n          alias: kafka.producer.throttle_time_avg\n          metric_type: gauge\n        produce-throttle-time-max:\n          alias: kafka.producer.throttle_time_max\n          metric_type: gauge\n        record-error-rate:\n          alias: kafka.producer.record_error_rate\n          metric_type: gauge\n        record-queue-time-avg:\n          alias: kafka.producer.record_queue_time_avg\n          metric_type: gauge\n        record-queue-time-max:\n          alias: kafka.producer.record_queue_time_max\n          metric_type: gauge\n        record-retry-rate:\n          alias: kafka.producer.record_retry_rate\n          metric_type: gauge\n        record-send-rate:\n          alias: kafka.producer.records_send_rate\n          metric_type: gauge\n        record-size-avg:\n          alias: kafka.producer.record_size_avg\n          metric_type: gauge\n        record-size-max:\n          alias: kafka.producer.record_size_max\n          metric_type: gauge\n        records-per-request-avg:\n          alias: kafka.producer.records_per_request\n          metric_type: gauge\n        request-latency-avg:\n          alias: kafka.producer.request_latency_avg\n          metric_type: gauge\n        request-latency-max:\n          alias: kafka.producer.request_latency_max\n          metric_type: gauge\n        requests-in-flight:\n          alias: kafka.producer.requests_in_flight\n          metric_type: gauge\n        waiting-threads:\n          alias: kafka.producer.waiting_threads\n          metric_type: gauge\n      bean_regex: kafka\\.producer:type=producer-metrics,client-id=([-.\\w]+)\n      domain: kafka.producer\n  - include:\n      attribute:\n        byte-rate:\n          alias: kafka.producer.bytes_out\n          metric_type: gauge\n      bean_regex: kafka\\.producer:type=producer-topic-metrics,client-id=(.*?),topic=(.*?)(?:,|$)\n      domain: kafka.producer\n      tags:\n        client: $1\n        topic: $2\n  - include:\n      attribute:\n        record-send-rate:\n          alias: kafka.producer.record_send_rate\n          metric_type: gauge\n      bean_regex: kafka\\.producer:type=producer-topic-metrics,client-id=(.*?),topic=(.*?)(?:,|$)\n      domain: kafka.producer\n      tags:\n        client: $1\n        topic: $2\n  - include:\n      attribute:\n        compression-rate:\n          alias: kafka.producer.compression_rate\n          metric_type: gauge\n      bean_regex: kafka\\.producer:type=producer-topic-metrics,client-id=(.*?),topic=(.*?)(?:,|$)\n      domain: kafka.producer\n      tags:\n        client: $1\n        topic: $2\n  - include:\n      attribute:\n        record-retry-rate:\n          alias: kafka.producer.record_retry_rate\n          metric_type: gauge\n      bean_regex: kafka\\.producer:type=producer-topic-metrics,client-id=(.*?),topic=(.*?)(?:,|$)\n      domain: kafka.producer\n      tags:\n        client: $1\n        topic: $2\n  - include:\n      attribute:\n        record-error-rate:\n          alias: kafka.producer.record_error_rate\n          metric_type: gauge\n      bean_regex: kafka\\.producer:type=producer-topic-metrics,client-id=(.*?),topic=(.*?)(?:,|$)\n      domain: kafka.producer\n      tags:\n        client: $1\n        topic: $2\n  - include:\n      attribute:\n        Value:\n          alias: kafka.consumer.max_lag\n          metric_type: gauge\n      bean_regex: kafka\\.consumer:type=ConsumerFetcherManager,name=MaxLag,clientId=.*\n      domain: kafka.consumer\n  - include:\n      attribute:\n        Value:\n          alias: kafka.consumer.fetch_rate\n          metric_type: gauge\n      bean_regex: kafka\\.consumer:type=ConsumerFetcherManager,name=MinFetchRate,clientId=.*\n      domain: kafka.consumer\n  - include:\n      attribute:\n        Count:\n          alias: kafka.consumer.bytes_in\n          metric_type: rate\n      bean_regex: kafka\\.consumer:type=ConsumerTopicMetrics,name=BytesPerSec,clientId=.*\n      domain: kafka.consumer\n  - include:\n      attribute:\n        Count:\n          alias: kafka.consumer.messages_in\n          metric_type: rate\n      bean_regex: kafka\\.consumer:type=ConsumerTopicMetrics,name=MessagesPerSec,clientId=.*\n      domain: kafka.consumer\n  - include:\n      attribute:\n        Count:\n          alias: kafka.consumer.zookeeper_commits\n          metric_type: rate\n      bean_regex: kafka\\.consumer:type=ZookeeperConsumerConnector,name=ZooKeeperCommitsPerSec,clientId=.*\n      domain: kafka.consumer\n  - include:\n      attribute:\n        Count:\n          alias: kafka.consumer.kafka_commits\n          metric_type: rate\n      bean_regex: kafka\\.consumer:type=ZookeeperConsumerConnector,name=KafkaCommitsPerSec,clientId=.*\n      domain: kafka.consumer\n  - include:\n      attribute:\n        bytes-consumed-rate:\n          alias: kafka.consumer.bytes_in\n          metric_type: gauge\n      bean_regex: kafka\\.consumer:type=consumer-fetch-manager-metrics,client-id=.*\n      domain: kafka.consumer\n  - include:\n      attribute:\n        records-consumed-rate:\n          alias: kafka.consumer.messages_in\n          metric_type: gauge\n      bean_regex: kafka\\.consumer:type=consumer-fetch-manager-metrics,client-id=.*\n      domain: kafka.consumer\n  - include:\n      attribute:\n        fetch-size-avg:\n          alias: kafka.consumer.fetch_size_avg\n          metric_type: gauge\n      bean_regex: kafka\\.consumer:type=consumer-fetch-manager-metrics,client-id=(.*?),topic=(.*?)(?:,|$)\n      domain: kafka.consumer\n      tags:\n        client: $1\n        topic: $2\n  - include:\n      attribute:\n        fetch-size-max:\n          alias: kafka.consumer.fetch_size_max\n          metric_type: gauge\n      bean_regex: kafka\\.consumer:type=consumer-fetch-manager-metrics,client-id=(.*?),topic=(.*?)(?:,|$)\n      domain: kafka.consumer\n      tags:\n        client: $1\n        topic: $2\n  - include:\n      attribute:\n        fetch-rate:\n          alias: kafka.consumer.fetch_rate\n          metric_type: gauge\n      bean_regex: kafka\\.consumer:type=consumer-fetch-manager-metrics,client-id=(.*?)\n      domain: kafka.consumer\n  - include:\n      attribute:\n        bytes-consumed-rate:\n          alias: kafka.consumer.bytes_consumed\n          metric_type: gauge\n      bean_regex: kafka\\.consumer:type=consumer-fetch-manager-metrics,client-id=(.*?),topic=(.*?)(?:,|$)\n      domain: kafka.consumer\n      tags:\n        client: $1\n        topic: $2\n  - include:\n      attribute:\n        records-per-request-avg:\n          alias: kafka.consumer.records_per_request_avg\n          metric_type: gauge\n      bean_regex: kafka\\.consumer:type=consumer-fetch-manager-metrics,client-id=(.*?),topic=(.*?)(?:,|$)\n      domain: kafka.consumer\n      tags:\n        client: $1\n        topic: $2\n  - include:\n      attribute:\n        records-consumed-rate:\n          alias: kafka.consumer.records_consumed\n          metric_type: gauge\n      bean_regex: kafka\\.consumer:type=consumer-fetch-manager-metrics,client-id=(.*?),topic=(.*?)(?:,|$)\n      domain: kafka.consumer\n      tags:\n        client: $1\n        topic: $2\n  - dynamic_tags:\n      - attribute: Value\n        bean_name: kafka.server:type=KafkaServer,name=ClusterId\n        tag_name: kafka_cluster_id\n    include:\n      attribute:\n        Count:\n          alias: kafka.net.bytes_out.rate\n          metric_type: rate\n      bean: kafka.server:type=BrokerTopicMetrics,name=BytesOutPerSec\n      domain: kafka.server\n  - dynamic_tags:\n      - attribute: Value\n        bean_name: kafka.server:type=KafkaServer,name=ClusterId\n        tag_name: kafka_cluster_id\n    include:\n      attribute:\n        Count:\n          alias: kafka.net.bytes_in.rate\n          metric_type: rate\n      bean: kafka.server:type=BrokerTopicMetrics,name=BytesInPerSec\n      domain: kafka.server\n  - dynamic_tags:\n      - attribute: Value\n        bean_name: kafka.server:type=KafkaServer,name=ClusterId\n        tag_name: kafka_cluster_id\n    include:\n      attribute:\n        Count:\n          alias: kafka.messages_in.rate\n          metric_type: rate\n      bean: kafka.server:type=BrokerTopicMetrics,name=MessagesInPerSec\n      domain: kafka.server\n  - dynamic_tags:\n      - attribute: Value\n        bean_name: kafka.server:type=KafkaServer,name=ClusterId\n        tag_name: kafka_cluster_id\n    include:\n      attribute:\n        Count:\n          alias: kafka.net.bytes_rejected.rate\n          metric_type: rate\n      bean: kafka.server:type=BrokerTopicMetrics,name=BytesRejectedPerSec\n      domain: kafka.server\n  - dynamic_tags:\n      - attribute: Value\n        bean_name: kafka.server:type=KafkaServer,name=ClusterId\n        tag_name: kafka_cluster_id\n    include:\n      attribute:\n        Count:\n          alias: kafka.topic.messages_in.rate\n          metric_type: rate\n      bean_regex: '\"kafka.server\":type=\"BrokerTopicMetrics\",name=\"(.*?)-MessagesInPerSec\"'\n      domain: '\"kafka.server\"'\n      tags:\n        topic: $1\n  - dynamic_tags:\n      - attribute: Value\n        bean_name: kafka.server:type=KafkaServer,name=ClusterId\n        tag_name: kafka_cluster_id\n    include:\n      attribute:\n        Count:\n          alias: kafka.topic.messages_in.rate\n          metric_type: rate\n      bean_regex: kafka\\.server:type=BrokerTopicMetrics,name=MessagesInPerSec,topic=.*\n      domain: kafka.server\n  - dynamic_tags:\n      - attribute: Value\n        bean_name: kafka.server:type=KafkaServer,name=ClusterId\n        tag_name: kafka_cluster_id\n    include:\n      attribute:\n        Count:\n          alias: kafka.topic.net.bytes_out.rate\n          metric_type: rate\n      bean_regex: kafka\\.server:type=BrokerTopicMetrics,name=BytesOutPerSec,topic=.*\n      domain: kafka.server\n  - dynamic_tags:\n      - attribute: Value\n        bean_name: kafka.server:type=KafkaServer,name=ClusterId\n        tag_name: kafka_cluster_id\n    include:\n      attribute:\n        Count:\n          alias: kafka.topic.net.bytes_in.rate\n          metric_type: rate\n      bean_regex: kafka\\.server:type=BrokerTopicMetrics,name=BytesInPerSec,topic=.*\n      domain: kafka.server\n  - dynamic_tags:\n      - attribute: Value\n        bean_name: kafka.server:type=KafkaServer,name=ClusterId\n        tag_name: kafka_cluster_id\n    include:\n      attribute:\n        Count:\n          alias: kafka.topic.net.bytes_rejected.rate\n          metric_type: rate\n      bean_regex: kafka\\.server:type=BrokerTopicMetrics,name=BytesRejectedPerSec,topic=.*\n      domain: kafka.server\n  - dynamic_tags:\n      - attribute: Value\n        bean_name: kafka.server:type=KafkaServer,name=ClusterId\n        tag_name: kafka_cluster_id\n    include:\n      attribute:\n        Count:\n          alias: kafka.request.fetch.failed.rate\n          metric_type: rate\n      bean: kafka.server:type=BrokerTopicMetrics,name=FailedFetchRequestsPerSec\n      domain: kafka.server\n  - dynamic_tags:\n      - attribute: Value\n        bean_name: kafka.server:type=KafkaServer,name=ClusterId\n        tag_name: kafka_cluster_id\n    include:\n      attribute:\n        Count:\n          alias: kafka.request.produce.failed.rate\n          metric_type: rate\n      bean: kafka.server:type=BrokerTopicMetrics,name=FailedProduceRequestsPerSec\n      domain: kafka.server\n  - dynamic_tags:\n      - attribute: Value\n        bean_name: kafka.server:type=KafkaServer,name=ClusterId\n        tag_name: kafka_cluster_id\n    include:\n      attribute:\n        Count:\n          alias: kafka.request.produce.rate\n          metric_type: rate\n      bean_regex: kafka.network:type=RequestMetrics,name=RequestsPerSec,request=Produce(?:,version=.*)?\n      domain: kafka.network\n  - dynamic_tags:\n      - attribute: Value\n        bean_name: kafka.server:type=KafkaServer,name=ClusterId\n        tag_name: kafka_cluster_id\n    include:\n      attribute:\n        99thPercentile:\n          alias: kafka.request.produce.time.99percentile\n          metric_type: gauge\n        Mean:\n          alias: kafka.request.produce.time.avg\n          metric_type: gauge\n      bean: kafka.network:type=RequestMetrics,name=TotalTimeMs,request=Produce\n      domain: kafka.network\n  - dynamic_tags:\n      - attribute: Value\n        bean_name: kafka.server:type=KafkaServer,name=ClusterId\n        tag_name: kafka_cluster_id\n    include:\n      attribute:\n        Count:\n          alias: kafka.request.fetch_consumer.rate\n          metric_type: rate\n      bean_regex: kafka.network:type=RequestMetrics,name=RequestsPerSec,request=FetchConsumer(?:,version=.*)?\n      domain: kafka.network\n  - dynamic_tags:\n      - attribute: Value\n        bean_name: kafka.server:type=KafkaServer,name=ClusterId\n        tag_name: kafka_cluster_id\n    include:\n      attribute:\n        Count:\n          alias: kafka.request.fetch_follower.rate\n          metric_type: rate\n      bean_regex: kafka.network:type=RequestMetrics,name=RequestsPerSec,request=FetchFollower(?:,version=.*)?\n      domain: kafka.network\n  - dynamic_tags:\n      - attribute: Value\n        bean_name: kafka.server:type=KafkaServer,name=ClusterId\n        tag_name: kafka_cluster_id\n    include:\n      attribute:\n        99thPercentile:\n          alias: kafka.request.fetch_consumer.time.99percentile\n          metric_type: gauge\n        Mean:\n          alias: kafka.request.fetch_consumer.time.avg\n          metric_type: gauge\n      bean: kafka.network:type=RequestMetrics,name=TotalTimeMs,request=FetchConsumer\n      domain: kafka.network\n  - dynamic_tags:\n      - attribute: Value\n        bean_name: kafka.server:type=KafkaServer,name=ClusterId\n        tag_name: kafka_cluster_id\n    include:\n      attribute:\n        99thPercentile:\n          alias: kafka.request.fetch_follower.time.99percentile\n          metric_type: gauge\n        Mean:\n          alias: kafka.request.fetch_follower.time.avg\n          metric_type: gauge\n      bean: kafka.network:type=RequestMetrics,name=TotalTimeMs,request=FetchFollower\n      domain: kafka.network\n  - dynamic_tags:\n      - attribute: Value\n        bean_name: kafka.server:type=KafkaServer,name=ClusterId\n        tag_name: kafka_cluster_id\n    include:\n      attribute:\n        99thPercentile:\n          alias: kafka.request.update_metadata.time.99percentile\n          metric_type: gauge\n        Mean:\n          alias: kafka.request.update_metadata.time.avg\n          metric_type: gauge\n      bean: kafka.network:type=RequestMetrics,name=TotalTimeMs,request=UpdateMetadata\n      domain: kafka.network\n  - dynamic_tags:\n      - attribute: Value\n        bean_name: kafka.server:type=KafkaServer,name=ClusterId\n        tag_name: kafka_cluster_id\n    include:\n      attribute:\n        99thPercentile:\n          alias: kafka.request.metadata.time.99percentile\n          metric_type: gauge\n        Mean:\n          alias: kafka.request.metadata.time.avg\n          metric_type: gauge\n      bean: kafka.network:type=RequestMetrics,name=TotalTimeMs,request=Metadata\n      domain: kafka.network\n  - dynamic_tags:\n      - attribute: Value\n        bean_name: kafka.server:type=KafkaServer,name=ClusterId\n        tag_name: kafka_cluster_id\n    include:\n      attribute:\n        99thPercentile:\n          alias: kafka.request.offsets.time.99percentile\n          metric_type: gauge\n        Mean:\n          alias: kafka.request.offsets.time.avg\n          metric_type: gauge\n      bean: kafka.network:type=RequestMetrics,name=TotalTimeMs,request=Offsets\n      domain: kafka.network\n  - dynamic_tags:\n      - attribute: Value\n        bean_name: kafka.server:type=KafkaServer,name=ClusterId\n        tag_name: kafka_cluster_id\n    include:\n      attribute:\n        Value:\n          alias: kafka.request.channel.queue.size\n          metric_type: gauge\n      bean: kafka.network:type=RequestChannel,name=RequestQueueSize\n      domain: kafka.network\n  - dynamic_tags:\n      - attribute: Value\n        bean_name: kafka.server:type=KafkaServer,name=ClusterId\n        tag_name: kafka_cluster_id\n    include:\n      attribute:\n        Value:\n          alias: kafka.net.processor.avg.idle.pct.rate\n          metric_type: gauge\n      bean: kafka.network:type=SocketServer,name=NetworkProcessorAvgIdlePercent\n      domain: kafka.network\n  - dynamic_tags:\n      - attribute: Value\n        bean_name: kafka.server:type=KafkaServer,name=ClusterId\n        tag_name: kafka_cluster_id\n    include:\n      attribute:\n        OneMinuteRate:\n          alias: kafka.request.handler.avg.idle.pct.rate\n          metric_type: gauge\n      bean: kafka.server:type=KafkaRequestHandlerPool,name=RequestHandlerAvgIdlePercent\n      domain: kafka.server\n  - dynamic_tags:\n      - attribute: Value\n        bean_name: kafka.server:type=KafkaServer,name=ClusterId\n        tag_name: kafka_cluster_id\n    include:\n      attribute:\n        Value:\n          alias: kafka.request.producer_request_purgatory.size\n          metric_type: gauge\n      bean: kafka.server:type=ProducerRequestPurgatory,name=PurgatorySize\n      domain: kafka.server\n  - dynamic_tags:\n      - attribute: Value\n        bean_name: kafka.server:type=KafkaServer,name=ClusterId\n        tag_name: kafka_cluster_id\n    include:\n      attribute:\n        Value:\n          alias: kafka.request.fetch_request_purgatory.size\n          metric_type: gauge\n      bean: kafka.server:type=FetchRequestPurgatory,name=PurgatorySize\n      domain: kafka.server\n  - dynamic_tags:\n      - attribute: Value\n        bean_name: kafka.server:type=KafkaServer,name=ClusterId\n        tag_name: kafka_cluster_id\n    include:\n      attribute:\n        Value:\n          alias: kafka.request.producer_request_purgatory.size\n          metric_type: gauge\n      bean: kafka.server:type=DelayedOperationPurgatory,name=PurgatorySize,delayedOperation=Produce\n      domain: kafka.server\n  - dynamic_tags:\n      - attribute: Value\n        bean_name: kafka.server:type=KafkaServer,name=ClusterId\n        tag_name: kafka_cluster_id\n    include:\n      attribute:\n        Value:\n          alias: kafka.request.fetch_request_purgatory.size\n          metric_type: gauge\n      bean: kafka.server:type=DelayedOperationPurgatory,name=PurgatorySize,delayedOperation=Fetch\n      domain: kafka.server\n  - dynamic_tags:\n      - attribute: Value\n        bean_name: kafka.server:type=KafkaServer,name=ClusterId\n        tag_name: kafka_cluster_id\n    include:\n      attribute:\n        Value:\n          alias: kafka.replication.under_replicated_partitions\n          metric_type: gauge\n      bean: kafka.server:type=ReplicaManager,name=UnderReplicatedPartitions\n      domain: kafka.server\n  - dynamic_tags:\n      - attribute: Value\n        bean_name: kafka.server:type=KafkaServer,name=ClusterId\n        tag_name: kafka_cluster_id\n    include:\n      attribute:\n        Value:\n          alias: kafka.replication.under_min_isr_partition_count\n          metric_type: gauge\n      bean: kafka.server:type=ReplicaManager,name=UnderMinIsrPartitionCount\n      domain: kafka.server\n  - dynamic_tags:\n      - attribute: Value\n        bean_name: kafka.server:type=KafkaServer,name=ClusterId\n        tag_name: kafka_cluster_id\n    include:\n      attribute:\n        Count:\n          alias: kafka.replication.isr_shrinks.rate\n          metric_type: rate\n      bean: kafka.server:type=ReplicaManager,name=IsrShrinksPerSec\n      domain: kafka.server\n  - dynamic_tags:\n      - attribute: Value\n        bean_name: kafka.server:type=KafkaServer,name=ClusterId\n        tag_name: kafka_cluster_id\n    include:\n      attribute:\n        Count:\n          alias: kafka.replication.isr_expands.rate\n          metric_type: rate\n      bean: kafka.server:type=ReplicaManager,name=IsrExpandsPerSec\n      domain: kafka.server\n  - dynamic_tags:\n      - attribute: Value\n        bean_name: kafka.server:type=KafkaServer,name=ClusterId\n        tag_name: kafka_cluster_id\n    include:\n      attribute:\n        Count:\n          alias: kafka.replication.leader_elections.rate\n          metric_type: rate\n      bean: kafka.controller:type=ControllerStats,name=LeaderElectionRateAndTimeMs\n      domain: kafka.controller\n  - dynamic_tags:\n      - attribute: Value\n        bean_name: kafka.server:type=KafkaServer,name=ClusterId\n        tag_name: kafka_cluster_id\n    include:\n      attribute:\n        Count:\n          alias: kafka.replication.unclean_leader_elections.rate\n          metric_type: rate\n      bean: kafka.controller:type=ControllerStats,name=UncleanLeaderElectionsPerSec\n      domain: kafka.controller\n  - dynamic_tags:\n      - attribute: Value\n        bean_name: kafka.server:type=KafkaServer,name=ClusterId\n        tag_name: kafka_cluster_id\n    include:\n      attribute:\n        Value:\n          alias: kafka.replication.offline_partitions_count\n          metric_type: gauge\n      bean: kafka.controller:type=KafkaController,name=OfflinePartitionsCount\n      domain: kafka.controller\n  - dynamic_tags:\n      - attribute: Value\n        bean_name: kafka.server:type=KafkaServer,name=ClusterId\n        tag_name: kafka_cluster_id\n    include:\n      attribute:\n        Value:\n          alias: kafka.replication.active_controller_count\n          metric_type: gauge\n      bean: kafka.controller:type=KafkaController,name=ActiveControllerCount\n      domain: kafka.controller\n  - dynamic_tags:\n      - attribute: Value\n        bean_name: kafka.server:type=KafkaServer,name=ClusterId\n        tag_name: kafka_cluster_id\n    include:\n      attribute:\n        Value:\n          alias: kafka.replication.partition_count\n          metric_type: gauge\n      bean: kafka.server:type=ReplicaManager,name=PartitionCount\n      domain: kafka.server\n  - dynamic_tags:\n      - attribute: Value\n        bean_name: kafka.server:type=KafkaServer,name=ClusterId\n        tag_name: kafka_cluster_id\n    include:\n      attribute:\n        Value:\n          alias: kafka.replication.leader_count\n          metric_type: gauge\n      bean: kafka.server:type=ReplicaManager,name=LeaderCount\n      domain: kafka.server\n  - dynamic_tags:\n      - attribute: Value\n        bean_name: kafka.server:type=KafkaServer,name=ClusterId\n        tag_name: kafka_cluster_id\n    include:\n      attribute:\n        Value:\n          alias: kafka.replication.max_lag\n          metric_type: gauge\n      bean: kafka.server:type=ReplicaFetcherManager,name=MaxLag,clientId=Replica\n      domain: kafka.server\n  - dynamic_tags:\n      - attribute: Value\n        bean_name: kafka.server:type=KafkaServer,name=ClusterId\n        tag_name: kafka_cluster_id\n    include:\n      attribute:\n        Count:\n          alias: kafka.log.flush_rate.rate\n          metric_type: rate\n      bean: kafka.log:type=LogFlushStats,name=LogFlushRateAndTimeMs\n      domain: kafka.log\n  - dynamic_tags:\n      - attribute: Value\n        bean_name: kafka.server:type=KafkaServer,name=ClusterId\n        tag_name: kafka_cluster_id\n    include:\n      attribute:\n        Count:\n          alias: kafka.session.zookeeper.disconnect.rate\n          metric_type: rate\n      bean: kafka.server:type=SessionExpireListener,name=ZooKeeperDisconnectsPerSec\n      domain: kafka.server\n  - dynamic_tags:\n      - attribute: Value\n        bean_name: kafka.server:type=KafkaServer,name=ClusterId\n        tag_name: kafka_cluster_id\n    include:\n      attribute:\n        Count:\n          alias: kafka.session.zookeeper.expire.rate\n          metric_type: rate\n      bean: kafka.server:type=SessionExpireListener,name=ZooKeeperExpiresPerSec\n      domain: kafka.server\n  - dynamic_tags:\n      - attribute: Value\n        bean_name: kafka.server:type=KafkaServer,name=ClusterId\n        tag_name: kafka_cluster_id\n    include:\n      attribute:\n        Count:\n          alias: kafka.session.zookeeper.readonly.rate\n          metric_type: rate\n      bean: kafka.server:type=SessionExpireListener,name=ZooKeeperReadOnlyConnectsPerSec\n      domain: kafka.server\n  - dynamic_tags:\n      - attribute: Value\n        bean_name: kafka.server:type=KafkaServer,name=ClusterId\n        tag_name: kafka_cluster_id\n    include:\n      attribute:\n        Count:\n          alias: kafka.session.zookeeper.sync.rate\n          metric_type: rate\n      bean: kafka.server:type=SessionExpireListener,name=ZooKeeperSyncConnectsPerSec\n      domain: kafka.server\n  - dynamic_tags:\n      - attribute: Value\n        bean_name: kafka.server:type=KafkaServer,name=ClusterId\n        tag_name: kafka_cluster_id\n    include:\n      attribute:\n        Value:\n          alias: kafka.session.fetch.count\n          metric_type: gauge\n      bean: kafka.server:type=FetchSessionCache,name=NumIncrementalFetchSessions\n      domain: kafka.server\n  - dynamic_tags:\n      - attribute: Value\n        bean_name: kafka.server:type=KafkaServer,name=ClusterId\n        tag_name: kafka_cluster_id\n    include:\n      attribute:\n        Count:\n          alias: kafka.session.fetch.eviction\n          metric_type: rate\n      bean: kafka.server:type=FetchSessionCache,name=IncrementalFetchSessionEvictionsPerSec\n      domain: kafka.server\n  - dynamic_tags:\n      - attribute: Value\n        bean_name: kafka.server:type=KafkaServer,name=ClusterId\n        tag_name: kafka_cluster_id\n    include:\n      attribute:\n        connection-count:\n          alias: kafka.server.socket.connection_count\n          metric_type: gauge\n      bean_regex: kafka\\.server:type=socket-server-metrics,listener=(.*?),networkProcessor=.*\n      domain: kafka.server\n      tags:\n        listener: $1"
        },
        "/etc/datadog-agent/conf.d/kube_apiserver_metrics.d/auto_conf.yaml": {
            "hash": "3ea3f8508a9cc80c3a1072f2c3a90ba984ecc0dc1a9f3f67e3242d66c9f12b7a",
            "raw_config": "ad_identifiers:\n  - kube-apiserver\ncel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\ninstances:\n  - bearer_token_auth: tls_only\n    possible_prometheus_urls:\n      - https://%%host%%:6443/metrics\n      - https://%%host%%:8443/metrics\n    tags:\n      - apiserver:%%host%%"
        },
        "/etc/datadog-agent/conf.d/kube_controller_manager.d/auto_conf.yaml": {
            "hash": "5d2f0f054acbf7d052caa6d2756e7f0488ce33b72d09eb1c04c37ebbf20511bd",
            "raw_config": "ad_identifiers:\n  - kube-controller-manager\ncel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\ninstances:\n  - bearer_token_auth: tls_only\n    possible_prometheus_urls:\n      - https://%%host%%:10257/metrics\n      - https://localhost:10257/metrics\n      - http://%%host%%:10252/metrics\n      - http://localhost:10252/metrics\n    ssl_verify: false"
        },
        "/etc/datadog-agent/conf.d/kube_dns.d/auto_conf.yaml": {
            "hash": "115d7b9fb778f2e2b2daa702f8d6e06c119d14d73a3cc36d9cc7182708310e1b",
            "raw_config": "ad_identifiers:\n  - kubedns-amd64\n  - k8s-dns-kube-dns-amd64\n  - k8s-dns-kube-dns\ncel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\ninstances:\n  - prometheus_endpoint: http://%%host%%:10055/metrics\n    tags:\n      - dns-pod:%%host%%"
        },
        "/etc/datadog-agent/conf.d/kube_scheduler.d/auto_conf.yaml": {
            "hash": "3959a98109ae5994a2270b2d8b75c0a36226314c9e02d99f843e9786119a0a5c",
            "raw_config": "ad_identifiers:\n  - kube-scheduler\ncel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\ninstances:\n  - bearer_token_auth: tls_only\n    possible_prometheus_urls:\n      - https://%%host%%:10259/metrics\n      - https://localhost:10259/metrics\n      - http://%%host%%:10251/metrics\n      - http://localhost:10251/metrics\n    ssl_verify: false"
        },
        "/etc/datadog-agent/conf.d/kubelet.d/conf.yaml.default": {
            "hash": "e1777eb7fed2fb9944a1329d4415bf1d48dec42ac0b0f02fe9e452016851a96c",
            "raw_config": "ad_identifiers:\n  - _kubelet\ncel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\ninstances:\n  - min_collection_interval: 20"
        },
        "/etc/datadog-agent/conf.d/kyototycoon.d/auto_conf.yaml": {
            "hash": "d91ad087261c8aa2eaa71e31261a51901712c7479c883f2720446820c7d67dd1",
            "raw_config": "ad_identifiers:\n  - kyototycoon\ncel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\ninstances:\n  - report_url: http://%%host%%:1978/rpc/report"
        },
        "/etc/datadog-agent/conf.d/load.d/conf.yaml.default": {
            "hash": "943384e901b9f8abe4ad1c2405d3bc6f36204a7a2d8f7e5d79c10632607fac69",
            "raw_config": "cel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\ninstances:\n  - {}"
        },
        "/etc/datadog-agent/conf.d/mcache.d/auto_conf.yaml": {
            "hash": "505feb1420c188cefc9673463f9b6ed4fc4a1d2289760f19a09c74f1dab03b5d",
            "raw_config": "ad_identifiers:\n  - memcached\ncel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\ninstances:\n  - port: 11211\n    url: '%%host%%'"
        },
        "/etc/datadog-agent/conf.d/memory.d/conf.yaml.default": {
            "hash": "943384e901b9f8abe4ad1c2405d3bc6f36204a7a2d8f7e5d79c10632607fac69",
            "raw_config": "cel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\ninstances:\n  - {}"
        },
        "/etc/datadog-agent/conf.d/network.d/conf.yaml.default": {
            "hash": "943384e901b9f8abe4ad1c2405d3bc6f36204a7a2d8f7e5d79c10632607fac69",
            "raw_config": "cel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\ninstances:\n  - {}"
        },
        "/etc/datadog-agent/conf.d/ntp.d/conf.yaml.default": {
            "hash": "943384e901b9f8abe4ad1c2405d3bc6f36204a7a2d8f7e5d79c10632607fac69",
            "raw_config": "cel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\ninstances:\n  - {}"
        },
        "/etc/datadog-agent/conf.d/openmetrics.yaml": {
            "hash": "8d37dd9726c724bc6c25822fd52f67f674c7adb93810730c36db48c476fe4b3b",
            "raw_config": "cel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\ncluster_check: true\ninstances:\n  - metrics:\n      - .*\n    openmetrics_endpoint: http://prometheus-example-service.default.svc.cluster.local:9090/metrics"
        },
        "/etc/datadog-agent/conf.d/orchestrator_ecs.d/conf.yaml.default": {
            "hash": "e869db19de8a2006daf2a5ac0a35c70ab52cbd1d8d1887ea31fb6f88fd70e838",
            "raw_config": "ad_identifiers:\n  - _ecs_orchestrator\ncel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\ninstances:\n  - {}"
        },
        "/etc/datadog-agent/conf.d/orchestrator_kubelet_config.d/conf.yaml.default": {
            "hash": "d746c9d26f736a13e535f7e1390ec0f42711f0143c382788da1904a4ad373f1e",
            "raw_config": "ad_identifiers:\n  - _kubelet_config_orchestrator\ncel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\ninstances:\n  - {}"
        },
        "/etc/datadog-agent/conf.d/orchestrator_pod.d/conf.yaml.default": {
            "hash": "88235849bc0fbe22e76f57f6e341936d9cd12d8a1c4072913f3c56d44762dcf0",
            "raw_config": "ad_identifiers:\n  - _kube_orchestrator\ncel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\ninstances:\n  - {}"
        },
        "/etc/datadog-agent/conf.d/presto.d/auto_conf.yaml": {
            "hash": "3986a058f1a4731fba380d46e22f6db7a63007fcdbde832705d44d3d2910744b",
            "raw_config": "ad_identifiers:\n  - presto\ncel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\ninit_config:\n  collect_default_metrics: true\n  is_jmx: true\ninstances:\n  - host: '%%host%%'\n    port: '%%port%%'"
        },
        "/etc/datadog-agent/conf.d/presto.d/metrics.yaml": {
            "hash": "5ca8f41b9a6c3d250b3e07a78c493329db9291bf1da89657a9778629c4275ebe",
            "raw_config": "cel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\njmx_metrics:\n  - include:\n      attribute:\n        AbandonedQueries.OneMinute.Count:\n          alias: presto.execution.abandoned_queries.one_minute.count\n        AbandonedQueries.OneMinute.Rate:\n          alias: presto.execution.abandoned_queries.one_minute.rate\n        AbandonedQueries.TotalCount:\n          alias: presto.execution.abandoned_queries.total_count\n        CanceledQueries.OneMinute.Count:\n          alias: presto.execution.canceled_queries.one_minute.count\n        CanceledQueries.OneMinute.Rate:\n          alias: presto.execution.canceled_queries.one_minute.rate\n        CanceledQueries.TotalCount:\n          alias: presto.execution.canceled_queries.total_count\n        CompletedQueries.OneMinute.Count:\n          alias: presto.execution.completed_queries.one_minute.count\n        CompletedQueries.OneMinute.Rate:\n          alias: presto.execution.completed_queries.one_minute.rate\n        CompletedQueries.TotalCount:\n          alias: presto.execution.completed_queries.total_count\n        ConsumedCpuTimeSecs.OneMinute.Count:\n          alias: presto.execution.consumed_cpu_time_secs.one_minute.count\n        ConsumedCpuTimeSecs.OneMinute.Rate:\n          alias: presto.execution.consumed_cpu_time_secs.one_minute.rate\n        ConsumedCpuTimeSecs.TotalCount:\n          alias: presto.execution.consumed_cpu_time_secs.total_count\n        CpuInputByteRate.AllTime.Avg:\n          alias: presto.execution.cpu_input_byte_rate.all_time.avg\n        CpuInputByteRate.AllTime.P75:\n          alias: presto.execution.cpu_input_byte_rate.all_time.p75\n        CpuInputByteRate.AllTime.P95:\n          alias: presto.execution.cpu_input_byte_rate.all_time.p95\n        CpuInputByteRate.OneMinute.Avg:\n          alias: presto.execution.cpu_input_byte_rate.one_minute.avg\n        CpuInputByteRate.OneMinute.Count:\n          alias: presto.execution.cpu_input_byte_rate.one_minute.count\n        CpuInputByteRate.OneMinute.Max:\n          alias: presto.execution.cpu_input_byte_rate.one_minute.max\n        CpuInputByteRate.OneMinute.Min:\n          alias: presto.execution.cpu_input_byte_rate.one_minute.min\n        CpuInputByteRate.OneMinute.P75:\n          alias: presto.execution.cpu_input_byte_rate.one_minute.p75\n        CpuInputByteRate.OneMinute.P95:\n          alias: presto.execution.cpu_input_byte_rate.one_minute.p95\n        CpuInputByteRate.OneMinute.Total:\n          alias: presto.execution.cpu_input_byte_rate.one_minute.total\n        ExecutionTime.AllTime.Avg:\n          alias: presto.execution.execution_time.all_time.avg\n        ExecutionTime.AllTime.Count:\n          alias: presto.execution.execution_time.all_time.count\n        ExecutionTime.AllTime.Max:\n          alias: presto.execution.execution_time.all_time.max\n        ExecutionTime.AllTime.Min:\n          alias: presto.execution.execution_time.all_time.min\n        ExecutionTime.AllTime.P75:\n          alias: presto.execution.execution_time.all_time.p75\n        ExecutionTime.AllTime.P95:\n          alias: presto.execution.execution_time.all_time.p95\n        ExecutionTime.OneMinute.Avg:\n          alias: presto.execution.execution_time.one_minute.avg\n        ExecutionTime.OneMinute.Max:\n          alias: presto.execution.execution_time.one_minute.max\n        ExecutionTime.OneMinute.Min:\n          alias: presto.execution.execution_time.one_minute.min\n        ExecutionTime.OneMinute.P75:\n          alias: presto.execution.execution_time.one_minute.p75\n        ExecutionTime.OneMinute.P95:\n          alias: presto.execution.execution_time.one_minute.p95\n        Executor.ActiveCount:\n          alias: presto.execution.executor.active_count\n        Executor.CompletedTaskCount:\n          alias: presto.execution.executor.completed_task_count\n        Executor.CorePoolSize:\n          alias: presto.execution.executor.core_pool_size\n        Executor.PoolSize:\n          alias: presto.execution.executor.pool_size\n        Executor.QueuedTaskCount:\n          alias: presto.execution.executor.queued_task_count\n        Executor.TaskCount:\n          alias: presto.execution.executor.task_count\n        ExternalFailures.OneMinute.Count:\n          alias: presto.execution.external_failures.one_minute.count\n        ExternalFailures.OneMinute.Rate:\n          alias: presto.execution.external_failures.one_minute.rate\n        ExternalFailures.TotalCount:\n          alias: presto.execution.external_failures.total_count\n        FailedQueries.OneMinute.Count:\n          alias: presto.execution.failed_queries.one_minute.count\n        FailedQueries.OneMinute.Rate:\n          alias: presto.execution.failed_queries.one_minute.rate\n        FailedQueries.TotalCount:\n          alias: presto.execution.failed_queries.total_count\n        InsufficientResourcesFailures.OneMinute.Count:\n          alias: presto.execution.insufficient_resources_failures.one_minute.count\n        InsufficientResourcesFailures.OneMinute.Rate:\n          alias: presto.execution.insufficient_resources_failures.one_minute.rate\n        InsufficientResourcesFailures.TotalCount:\n          alias: presto.execution.insufficient_resources_failures.total_count\n        InternalFailures.OneMinute.Count:\n          alias: presto.execution.internal_failures.one_minute.count\n        InternalFailures.OneMinute.Rate:\n          alias: presto.execution.internal_failures.one_minute.rate\n        InternalFailures.TotalCount:\n          alias: presto.execution.internal_failures.total_count\n        ManagementExecutor.ActiveCount:\n          alias: presto.execution.management_executor.active_count\n        ManagementExecutor.CompletedTaskCount:\n          alias: presto.execution.management_executor.completed_task_count\n        ManagementExecutor.QueuedTaskCount:\n          alias: presto.execution.management_executor.queued_task_count\n        RunningQueries:\n          alias: presto.execution.running_queries\n        StartedQueries.OneMinute.Count:\n          alias: presto.execution.started_queries.one_minute.count\n        StartedQueries.OneMinute.Rate:\n          alias: presto.execution.started_queries.one_minute.rate\n        StartedQueries.TotalCount:\n          alias: presto.execution.started_queries.total_count\n        UserErrorFailures.OneMinute.Count:\n          alias: presto.execution.user_error_failures.one_minute.count\n        UserErrorFailures.OneMinute.Rate:\n          alias: presto.execution.user_error_failures.one_minute.rate\n        UserErrorFailures.TotalCount:\n          alias: presto.execution.user_error_failures.total_count\n        WallInputBytesRate.OneMinute.Avg:\n          alias: presto.execution.wall_input_bytes_rate.one_minute.avg\n        WallInputBytesRate.OneMinute.Max:\n          alias: presto.execution.wall_input_bytes_rate.one_minute.max\n        WallInputBytesRate.OneMinute.Min:\n          alias: presto.execution.wall_input_bytes_rate.one_minute.min\n        WallInputBytesRate.OneMinute.P75:\n          alias: presto.execution.wall_input_bytes_rate.one_minute.p75\n        WallInputBytesRate.OneMinute.P95:\n          alias: presto.execution.wall_input_bytes_rate.one_minute.p95\n      bean: presto.execution:name=QueryManager\n  - include:\n      attribute:\n        BlockedSplits:\n          alias: presto.execution.executor.blocked_splits\n        ProcessorExecutor.QueuedTaskCount:\n          alias: presto.execution.executor.processor_executor.queued_task_count\n        RunningSplits:\n          alias: presto.execution.executor.running_splits\n        TotalSplits:\n          alias: presto.execution.executor.total_splits\n        WaitingSplits:\n          alias: presto.execution.executor.waiting_splits\n      bean: presto.execution.executor:name=TaskExecutor\n  - include:\n      attribute:\n        InputDataSize.OneMinute.Count:\n          alias: presto.execution.input_data_size.one_minute.count\n        InputDataSize.OneMinute.Rate:\n          alias: presto.execution.input_data_size.one_minute.rate\n        InputDataSize.TotalCount:\n          alias: presto.execution.input_data_size.total_count\n        InputPositions.OneMinute.Count:\n          alias: presto.execution.input_positions.one_minute.count\n        InputPositions.OneMinute.Rate:\n          alias: presto.execution.input_positions.one_minute.rate\n        InputPositions.TotalCount:\n          alias: presto.execution.input_positions.total_count\n        OutputDataSize.OneMinute.Count:\n          alias: presto.execution.output_data_size.one_minute.count\n        OutputDataSize.OneMinute.Rate:\n          alias: presto.execution.output_data_size.one_minute.rate\n        OutputDataSize.TotalCount:\n          alias: presto.execution.output_data_size.total_count\n        OutputPositions.OneMinute.Count:\n          alias: presto.execution.output_positions.one_minute.count\n        OutputPositions.OneMinute.Rate:\n          alias: presto.execution.output_positions.one_minute.rate\n        OutputPositions.TotalCount:\n          alias: presto.execution.output_positions.total_count\n        TaskNotificationExecutor.ActiveCount:\n          alias: presto.execution.task_notification_executor.active_count\n        TaskNotificationExecutor.CompletedTaskCount:\n          alias: presto.execution.task_notification_executor.completed_task_count\n        TaskNotificationExecutor.PoolSize:\n          alias: presto.execution.task_notification_executor.pool_size\n        TaskNotificationExecutor.QueuedTaskCount:\n          alias: presto.execution.task_notification_executor.queued_task_count\n      bean: presto.execution:name=TaskManager\n  - include:\n      attribute:\n        ActiveCount:\n          alias: presto.failure_detector.active_count\n      bean:\n        - presto.failureDetector:name=HeartbeatFailureDetector\n  - include:\n      attribute:\n        AssignedQueries:\n          alias: presto.memory.assigned_queries\n        BlockedNodes:\n          alias: presto.memory.blocked_nodes\n        ClusterMemoryBytes:\n          alias: presto.memory.cluster_memory_bytes\n        FreeBytes:\n          alias: presto.memory.free_bytes\n        FreeDistributedBytes:\n          alias: presto.memory.free_distributed_bytes\n        MaxBytes:\n          alias: presto.memory.max_bytes\n        Nodes:\n          alias: presto.memory.nodes\n        ReservedBytes:\n          alias: presto.memory.reserved_bytes\n        ReservedDistributedBytes:\n          alias: presto.memory.reserved_distributed_bytes\n        ReservedRevocableBytes:\n          alias: presto.memory.reserved_revocable_bytes\n        ReservedRevocableDistributedBytes:\n          alias: presto.memory.reserved_revocable_distributed_bytes\n        TotalDistributedBytes:\n          alias: presto.memory.total_distributed_bytes\n      domain: presto.memory"
        },
        "/etc/datadog-agent/conf.d/rabbitmq.d/auto_conf.yaml": {
            "hash": "8c84d6fafa5b7de07943325bec4ee5f441ae8b1cb509e79d02357f72791457a3",
            "raw_config": "ad_identifiers:\n  - rabbitmq\ncel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\ninstances:\n  - prometheus_plugin:\n      url: http://%%host%%:15692"
        },
        "/etc/datadog-agent/conf.d/redisdb.d/auto_conf.yaml": {
            "hash": "0ea1555a1fe3fc35c2f476f51bcd1726d2ec009856bb223184cd143b21fd2b49",
            "raw_config": "ad_identifiers:\n  - redis\ncel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\ninstances:\n  - host: '%%host%%'\n    port: 6379"
        },
        "/etc/datadog-agent/conf.d/riak.d/auto_conf.yaml": {
            "hash": "74d62766e16565a05145468ce0472ec0afc6ed71cbc2f2a0c82a0174c193a865",
            "raw_config": "ad_identifiers:\n  - riak\ncel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\ninstances:\n  - url: http://%%host%%:8098/stats"
        },
        "/etc/datadog-agent/conf.d/sbom.d/conf.yaml.default": {
            "hash": "b6e22be0f034510a93bcb230ffc7f16ec4ddd2c51b70ca1c0e472165e0befff3",
            "raw_config": "ad_identifiers:\n  - _sbom\ncel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\ninstances:\n  - {}"
        },
        "/etc/datadog-agent/conf.d/snmp.d/auto_conf.yaml": {
            "hash": "6035083c71899c94bf921e0df5d7a9084b1fdf37e1cba822027dfafd6f12c918",
            "raw_config": "ad_identifiers:\n  - snmp\ncel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\ninit_config:\n  use_remote_config_profiles: '%%extra_use_remote_config_profiles%%'\ninstances:\n  - authKey: "********"
        },
        "/etc/datadog-agent/conf.d/solr.d/metrics.yaml": {
            "hash": "e90d93c3e07a52b6debc656bbd01ee83c86586ab30e4b7c7f5bf339d2f910915",
            "raw_config": "cel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\njmx_metrics:\n  - include:\n      attribute:\n        Value:\n          alias: solr.searcher.numdocs\n          metric_type: gauge\n      category: SEARCHER\n      domain: solr\n      name:\n        - numDocs\n      scope:\n        - searcher\n  - include:\n      attribute:\n        Value:\n          alias: solr.searcher.maxdocs\n          metric_type: gauge\n      category: SEARCHER\n      domain: solr\n      name: maxDoc\n      scope:\n        - searcher\n  - include:\n      attribute:\n        Value:\n          alias: solr.searcher.warmup\n          metric_type: gauge\n      category: SEARCHER\n      domain: solr\n      name: warmupTime\n      scope:\n        - searcher\n  - include:\n      attribute:\n        cumulative_evictions:\n          alias: solr.document_cache.evictions\n          metric_type: counter\n        cumulative_hits:\n          alias: solr.document_cache.hits\n          metric_type: counter\n        cumulative_inserts:\n          alias: solr.document_cache.inserts\n          metric_type: counter\n        cumulative_lookups:\n          alias: solr.document_cache.lookups\n          metric_type: counter\n      category: CACHE\n      domain: solr\n      name: documentCache\n      scope:\n        - searcher\n  - include:\n      attribute:\n        cumulative_evictions:\n          alias: solr.query_result_cache.evictions\n          metric_type: counter\n        cumulative_hits:\n          alias: solr.query_result_cache.hits\n          metric_type: counter\n        cumulative_inserts:\n          alias: solr.query_result_cache.inserts\n          metric_type: counter\n        cumulative_lookups:\n          alias: solr.query_result_cache.lookups\n          metric_type: counter\n      category: CACHE\n      domain: solr\n      name: queryResultCache\n      scope:\n        - searcher\n  - include:\n      attribute:\n        cumulative_evictions:\n          alias: solr.filter_cache.evictions\n          metric_type: counter\n        cumulative_hits:\n          alias: solr.filter_cache.hits\n          metric_type: counter\n        cumulative_inserts:\n          alias: solr.filter_cache.inserts\n          metric_type: counter\n        cumulative_lookups:\n          alias: solr.filter_cache.lookups\n          metric_type: counter\n      category: CACHE\n      domain: solr\n      name: filterCache\n      scope:\n        - searcher\n  - include:\n      attribute:\n        Count:\n          alias: solr.search_handler.requests\n          metric_type: counter\n      category: QUERY\n      domain: solr\n      name: requests\n  - include:\n      attribute:\n        Count:\n          alias: solr.search_handler.timeouts\n          metric_type: counter\n      category: QUERY\n      domain: solr\n      name: timeouts\n  - include:\n      attribute:\n        Count:\n          alias: solr.search_handler.errors\n          metric_type: counter\n      category: QUERY\n      domain: solr\n      name: errors\n  - include:\n      attribute:\n        Count:\n          alias: solr.search_handler.time\n          metric_type: counter\n      category: QUERY\n      domain: solr\n      name: totalTime\n  - include:\n      attribute:\n        50thPercentile:\n          alias: solr.search_handler.request_times.50percentile\n          metric_type: gauge\n        75thPercentile:\n          alias: solr.search_handler.request_times.75percentile\n          metric_type: gauge\n        95thPercentile:\n          alias: solr.search_handler.request_times.95percentile\n          metric_type: gauge\n        98thPercentile:\n          alias: solr.search_handler.request_times.98percentile\n          metric_type: gauge\n        99thPercentile:\n          alias: solr.search_handler.request_times.99percentile\n          metric_type: gauge\n        999thPercentile:\n          alias: solr.search_handler.request_times.999percentile\n          metric_type: gauge\n        Mean:\n          alias: solr.search_handler.request_times.mean\n          metric_type: gauge\n        MeanRate:\n          alias: solr.search_handler.request_times.mean_rate\n          metric_type: gauge\n        OneMinuteRate:\n          alias: solr.search_handler.request_times.one_minute_rate\n          metric_type: gauge\n      category: QUERY\n      domain: solr\n      name: requestTimes\n  - include:\n      attribute:\n        maxDoc:\n          alias: solr.searcher.maxdoc\n          metric_type: gauge\n        numDocs:\n          alias: solr.searcher.numdocs\n          metric_type: gauge\n        warmupTime:\n          alias: solr.searcher.warmup\n          metric_type: gauge\n      domain: solr/gettingstarted\n      type: searcher\n  - include:\n      attribute:\n        cumulative_evictions:\n          alias: solr.cache.evictions\n          metric_type: counter\n        cumulative_hits:\n          alias: solr.cache.hits\n          metric_type: counter\n        cumulative_inserts:\n          alias: solr.cache.inserts\n          metric_type: counter\n        cumulative_lookups:\n          alias: solr.cache.lookups\n          metric_type: counter\n      domain: solr/gettingstarted\n      id: org.apache.solr.search.FastLRUCache\n  - include:\n      attribute:\n        cumulative_evictions:\n          alias: solr.cache.evictions\n          metric_type: counter\n        cumulative_hits:\n          alias: solr.cache.hits\n          metric_type: counter\n        cumulative_inserts:\n          alias: solr.cache.inserts\n          metric_type: counter\n        cumulative_lookups:\n          alias: solr.cache.lookups\n          metric_type: counter\n      domain: solr/gettingstarted\n      id: org.apache.solr.search.LRUCache\n  - include:\n      attribute:\n        avgRequestsPerSecond:\n          alias: solr.search_handler.avg_requests_per_sec\n          metric_type: gauge\n        avgTimePerRequest:\n          alias: solr.search_handler.avg_time_per_req\n          metric_type: gauge\n        errors:\n          alias: solr.search_handler.errors\n          metric_type: counter\n        requests:\n          alias: solr.search_handler.requests\n          metric_type: counter\n        timeouts:\n          alias: solr.search_handler.timeouts\n          metric_type: counter\n        totalTime:\n          alias: solr.search_handler.time\n          metric_type: counter\n      domain: solr/gettingstarted\n      id: org.apache.solr.handler.component.SearchHandler"
        },
        "/etc/datadog-agent/conf.d/sonarqube.d/metrics.yaml": {
            "hash": "2227d911cfff3d1a7e01fbca2661498a2b0981802e1d06e8004b845421b7f21d",
            "raw_config": "cel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\njmx_metrics:\n  - include:\n      attribute:\n        PoolActiveConnections:\n          alias: sonarqube.server.database.pool_active_connections\n          metric_type: gauge\n        PoolIdleConnections:\n          alias: sonarqube.server.database.pool_idle_connections\n          metric_type: gauge\n        PoolInitialSize:\n          alias: sonarqube.server.database.pool_initial_size\n          metric_type: gauge\n        PoolMaxActiveConnections:\n          alias: sonarqube.server.database.pool_max_active_connections\n          metric_type: gauge\n        PoolMaxIdleConnections:\n          alias: sonarqube.server.database.pool_max_idle_connections\n          metric_type: gauge\n        PoolMaxWaitMillis:\n          alias: sonarqube.server.database.pool_max_wait_millis\n          metric_type: gauge\n        PoolMinIdleConnections:\n          alias: sonarqube.server.database.pool_min_idle_connections\n          metric_type: gauge\n        PoolRemoveAbandonedTimeoutSeconds:\n          alias: sonarqube.server.database.pool_remove_abandoned_timeout_seconds\n          metric_type: gauge\n      domain: SonarQube\n      exclude_tags:\n        - name\n      name: Database\n  - include:\n      attribute:\n        ErrorCount:\n          alias: sonarqube.server.compute_engine_tasks.error_count\n          metric_type: monotonic_count\n        InProgressCount:\n          alias: sonarqube.server.compute_engine_tasks.in_progress_count\n          metric_type: gauge\n        LongestTimePending:\n          alias: sonarqube.server.compute_engine_tasks.longest_pending_time\n          metric_type: gauge\n        PendingCount:\n          alias: sonarqube.server.compute_engine_tasks.pending_count\n          metric_type: monotonic_count\n        ProcessingTime:\n          alias: sonarqube.server.compute_engine_tasks.processing_time\n          metric_type: gauge\n        SuccessCount:\n          alias: sonarqube.server.compute_engine_tasks.success_count\n          metric_type: monotonic_count\n        WorkerCount:\n          alias: sonarqube.server.compute_engine_tasks.worker_count\n          metric_type: gauge\n        WorkerMaxCount:\n          alias: sonarqube.server.compute_engine_tasks.worker_max_count\n          metric_type: gauge\n      domain: SonarQube\n      exclude_tags:\n        - name\n      name: ComputeEngineTasks\n  - include:\n      attribute:\n        LargestWorkerCount:\n          alias: sonarqube.server.async_execution.largest_worker_count\n          metric_type: gauge\n        QueueSize:\n          alias: sonarqube.server.async_execution.queue_size\n          metric_type: gauge\n        WorkerCount:\n          alias: sonarqube.server.async_execution.worker_count\n          metric_type: gauge\n      domain: SonarQube\n      exclude_tags:\n        - name\n      name: AsyncExecution"
        },
        "/etc/datadog-agent/conf.d/telemetry.d/conf.yaml.default": {
            "hash": "943384e901b9f8abe4ad1c2405d3bc6f36204a7a2d8f7e5d79c10632607fac69",
            "raw_config": "cel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\ninstances:\n  - {}"
        },
        "/etc/datadog-agent/conf.d/tomcat.d/auto_conf.yaml": {
            "hash": "73835039377524cd9ce6fb05ac08ad7051625c459192ea6370cc5a0ebea8095a",
            "raw_config": "ad_identifiers:\n  - tomcat\ncel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\ninit_config:\n  collect_default_metrics: true\n  is_jmx: true\ninstances:\n  - host: '%%host%%'\n    port: \"9012\""
        },
        "/etc/datadog-agent/conf.d/tomcat.d/metrics.yaml": {
            "hash": "2e4c3f1fe52d74e1f9d23c712b5c8408c2731bec185c69663d6a5083e74c1ee4",
            "raw_config": "cel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\njmx_metrics:\n  - include:\n      attribute:\n        currentThreadCount:\n          alias: tomcat.threads.count\n          metric_type: gauge\n        currentThreadsBusy:\n          alias: tomcat.threads.busy\n          metric_type: gauge\n        maxThreads:\n          alias: tomcat.threads.max\n          metric_type: gauge\n        minSpareThreads:\n          alias: tomcat.threads.min\n          metric_type: gauge\n      domain_regex: Catalina|Tomcat\n      type: ThreadPool\n  - include:\n      attribute:\n        bytesReceived:\n          alias: tomcat.bytes_rcvd\n          metric_type: counter\n        bytesSent:\n          alias: tomcat.bytes_sent\n          metric_type: counter\n        errorCount:\n          alias: tomcat.error_count\n          metric_type: counter\n        maxTime:\n          alias: tomcat.max_time\n          metric_type: gauge\n        minTime:\n          alias: tomcat.min_time\n          metric_type: gauge\n        processingTime:\n          alias: tomcat.processing_time\n          metric_type: counter\n        requestCount:\n          alias: tomcat.request_count\n          metric_type: counter\n      domain_regex: Catalina|Tomcat\n      type: GlobalRequestProcessor\n  - include:\n      attribute:\n        errorCount:\n          alias: tomcat.servlet.error_count\n          metric_type: counter\n        maxTime:\n          alias: tomcat.servlet.max_time\n          metric_type: gauge\n        minTime:\n          alias: tomcat.servlet.min_time\n          metric_type: gauge\n        processingTime:\n          alias: tomcat.servlet.processing_time\n          metric_type: counter\n        requestCount:\n          alias: tomcat.servlet.request_count\n          metric_type: counter\n      domain_regex: Catalina|Tomcat\n      j2eeType: Servlet\n  - include:\n      attribute:\n        accessCount:\n          alias: tomcat.string_cache.access_count\n          metric_type: counter\n        hitCount:\n          alias: tomcat.string_cache.hit_count\n          metric_type: counter\n        maxSize:\n          alias: tomcat.string_cache.max_size\n          metric_type: gauge\n        size:\n          alias: tomcat.string_cache.size\n          metric_type: gauge\n      domain_regex: Catalina|Tomcat\n      type: StringCache\n  - include:\n      attribute:\n        hitCount:\n          alias: tomcat.web.cache.hit_count\n          metric_type: counter\n        lookupCount:\n          alias: tomcat.web.cache.lookup_count\n          metric_type: counter\n      domain_regex: Catalina|Tomcat\n      name: Cache\n      type: WebResourceRoot\n  - include:\n      attribute:\n        jspCount:\n          alias: tomcat.jsp.count\n          metric_type: counter\n        jspReloadCount:\n          alias: tomcat.jsp.reload_count\n          metric_type: counter\n      domain_regex: Catalina|Tomcat\n      type: JspMonitor\n  - include:\n      attribute:\n        active:\n          alias: tomcat.jdbc.connection_pool.active\n          metric_type: gauge\n        idle:\n          alias: tomcat.jdbc.connection_pool.idle\n          metric_type: gauge\n        maxActive:\n          alias: tomcat.jdbc.connection_pool.max_active\n          metric_type: gauge\n        maxIdle:\n          alias: tomcat.jdbc.connection_pool.max_idle\n          metric_type: gauge\n        minIdle:\n          alias: tomcat.jdbc.connection_pool.min_idle\n          metric_type: gauge\n        size:\n          alias: tomcat.jdbc.connection_pool.size\n          metric_type: gauge\n      domain_regex: Catalina|Tomcat\n      type: DataSource"
        },
        "/etc/datadog-agent/conf.d/uptime.d/conf.yaml.default": {
            "hash": "943384e901b9f8abe4ad1c2405d3bc6f36204a7a2d8f7e5d79c10632607fac69",
            "raw_config": "cel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\ninstances:\n  - {}"
        },
        "/etc/datadog-agent/conf.d/weblogic.d/metrics.yaml": {
            "hash": "dd14e9940e8684e86f5c13259402bdeb17d581fe6e7873f44f88a04f6cb7d85d",
            "raw_config": "cel_selector:\n  containers: []\n  kube_endpoints: []\n  kube_services: []\n  pods: []\n  processes: []\njmx_metrics:\n  - include:\n      attribute:\n        OpenSocketsCurrentCount:\n          alias: weblogic.server_runtime.open_sockets\n      bean_regex: com.bea:Name=([-/.\\w]+),Type=ServerRuntime\n      domain: com.bea\n  - include:\n      attribute:\n        MaxOpenSockCount:\n          alias: weblogic.server.max_open_sockets\n        ThreadPoolPercentSocketReaders:\n          alias: weblogic.server.threadpool_socket_readers_percent\n      bean_regex: com.bea:Name=([-/.\\w]+),Type=Server\n      domain: com.bea\n  - include:\n      attribute:\n        CompletedRequestCount:\n          alias: weblogic.threadpool_runtime.completed_requests\n          metric_type: monotonic_count\n        ExecuteThreadIdleCount:\n          alias: weblogic.threadpool_runtime.execute_threads_idle\n          metric_type: gauge\n        ExecuteThreadTotalCount:\n          alias: weblogic.threadpool_runtime.execute_threads_total\n        HoggingThreadCount:\n          alias: weblogic.threadpool_runtime.threads_hogging\n        OverloadRejectedRequestsCount:\n          alias: weblogic.threadpool_runtime.overload_rejected_requests\n        PendingUserRequestCount:\n          alias: weblogic.threadpool_runtime.user_requests_pending\n          metric_type: gauge\n        QueueLength:\n          alias: weblogic.threadpool_runtime.queue_length\n        SharedCapacityForWorkManagers:\n          alias: weblogic.threadpool_runtime.shared_capacity_work_managers\n        StandbyThreadCount:\n          alias: weblogic.threadpool_runtime.threads_standby\n        StuckThreadCount:\n          alias: weblogic.threadpool_runtime.threads_stuck\n        Throughput:\n          alias: weblogic.threadpool_runtime.throughput\n      bean_regex: com.bea:ServerRuntime=([-.\\w]+),Name=ThreadPoolRuntime,Type=ThreadPoolRuntime\n      domain: com.bea\n  - include:\n      attribute:\n        HeapFreeCurrent:\n          alias: weblogic.jvm_runtime.heap_free\n        HeapFreePercent:\n          alias: weblogic.jvm_runtime.heap_free_percent\n        HeapSizeCurrent:\n          alias: weblogic.jvm_runtime.heap_size\n        HeapSizeMax:\n          alias: weblogic.jvm_runtime.heap_size_max\n      bean_regex: com.bea:ServerRuntime=([-.\\w]+),Name=([-/.\\w]+),Type=JVMRuntime\n      domain: com.bea\n  - include:\n      attribute:\n        ActiveConnectionsCurrentCount:\n          alias: weblogic.connector_connection_pool_runtime.connections_active\n        ConnectionsCreatedTotalCount:\n          alias: weblogic.connector_connection_pool_runtime.connections_created_total\n          metric_type: monotonic_count\n        FreeConnectionsCurrentCount:\n          alias: weblogic.connector_connection_pool_runtime.connections_free\n      bean_regex: com.bea:ServerRuntime=([-.\\w]+),Name=([-/.\\w]+),ApplicationRuntime=([-.\\w]+),Type=ConnectorConnectionPoolRuntime,ConnectorComponentRuntime=([-.\\w]+)\n      domain: com.bea\n  - include:\n      attribute:\n        ConnectionsCurrentCount:\n          alias: weblogic.jms_runtime.connections_current\n        ConnectionsTotalCount:\n          alias: weblogic.jms_runtime.connections_total\n          metric_type: monotonic_count\n        JMSServersCurrentCount:\n          alias: weblogic.jms_runtime.jms_servers\n        JMSServersTotalCount:\n          alias: weblogic.jms_runtime.jms_servers_total\n          metric_type: monotonic_count\n      bean_regex: com.bea:ServerRuntime=([-.\\w]+),Name=([-/.\\w]+),Type=JMSRuntime\n      domain: com.bea\n  - include:\n      attribute:\n        CompletedRequests:\n          alias: weblogic.work_manager_runtime.requests_completed\n          metric_type: monotonic_count\n        PendingRequests:\n          alias: weblogic.work_manager_runtime.requests_pending\n        StuckThreadCount:\n          alias: weblogic.work_manager_runtime.threads_stuck\n      bean_regex: com.bea:ServerRuntime=([-.\\w]+),Name=([-/.\\w]+),ApplicationRuntime=([-_.\\w]+),Type=WorkManagerRuntime\n      domain: com.bea\n  - include:\n      attribute:\n        AcceptCount:\n          alias: weblogic.server_channel_runtime.sockets_accepted\n          metric_type: monotonic_count\n        BytesReceivedCount:\n          alias: weblogic.server_channel_runtime.bytes_received\n          metric_type: monotonic_count\n        BytesSentCount:\n          alias: weblogic.server_channel_runtime.bytes_sent\n          metric_type: monotonic_count\n        ConnectionsCount:\n          alias: weblogic.server_channel_runtime.connections_active\n        MessagesReceivedCount:\n          alias: weblogic.server_channel_runtime.messages_received\n          metric_type: monotonic_count\n        MessagesSentCount:\n          alias: weblogic.server_channel_runtime.messages_sent\n          metric_type: monotonic_count\n      bean_regex: com.bea:ServerRuntime=([-_.\\w]+),Name=([\\[\\-_/.\\]\\w]+),Type=ServerChannelRuntime\n      domain: com.bea\n  - include:\n      attribute:\n        ExecutionTimeHigh:\n          alias: weblogic.servlet_runtime.exec_time_high\n          metric_type: monotonic_count\n        ExecutionTimeLow:\n          alias: weblogic.servlet_runtime.exec_time_low\n        ExecutionTimeTotal:\n          alias: weblogic.servlet_runtime.exec_time_total\n          metric_type: monotonic_count\n        PoolMaxCapacity:\n          alias: weblogic.servlet_runtime.pool_max_capacity\n        ReloadTotalCount:\n          alias: weblogic.servlet_runtime.reloads_total\n      bean_regex: com.bea:ServerRuntime=([-_.\\w]+),Name=([\\[\\-_/.\\]\\w]+),ApplicationRuntime=([-_.\\w]+),Type=ServletRuntime,WebAppComponentRuntime=([-_/.\\w]+)\n      domain: com.bea\n  - include:\n      attribute:\n        OpenSessionsCurrentCount:\n          alias: weblogic.webapp_component_runtime.sessions_current\n      bean_regex: com.bea:ServerRuntime=([-_.\\w]+),Name=([\\[\\-_/.\\]\\w]+),ApplicationRuntime=([-_.\\w]+),Type=WebAppComponentRuntime\n      domain: com.bea"
        }
    },
    "uuid": "9fa8865e-3751-4433-92c2-24835d1b1250"
}